[
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7db"
    },
    "model_benchmark_id": 1,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.062949+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.7099,
    "score": 0.7099,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.062949+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7dd"
    },
    "model_benchmark_id": 157,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:11.401017+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.401017+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7df"
    },
    "model_benchmark_id": 32,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.149067+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.149067+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7e1"
    },
    "model_benchmark_id": 56,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.202939+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.757,
    "score": 0.757,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.202939+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7e3"
    },
    "model_benchmark_id": 131,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.341733+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.563,
    "score": 0.563,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.341733+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7e5"
    },
    "model_benchmark_id": 147,
    "analysis_method": "Standardized Evaluation",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.378573+00:00",
    "is_self_reported": true,
    "model_id": "command-r-plus-04-2024",
    "normalized_score": 0.854,
    "score": 0.854,
    "self_reported_source_link": "https://huggingface.co/CohereForAI/c4ai-command-r-plus",
    "updated_at": "2025-07-19T19:56:11.378573+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7e7"
    },
    "model_benchmark_id": 434,
    "analysis_method": "EM",
    "benchmark_id": "c-eval",
    "benchmark_name": "C-Eval",
    "created_at": "2025-07-19T19:56:11.920573+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.925,
    "score": 0.925,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.920573+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7e9"
    },
    "model_benchmark_id": 440,
    "analysis_method": "Correct",
    "benchmark_id": "csimpleqa",
    "benchmark_name": "CSimpleQA",
    "created_at": "2025-07-19T19:56:11.934566+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.934566+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7eb"
    },
    "model_benchmark_id": 369,
    "analysis_method": "Pass@1",
    "benchmark_id": "evalplus",
    "benchmark_name": "EvalPlus",
    "created_at": "2025-07-19T19:56:11.796250+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.803,
    "score": 0.803,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.796250+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7ed"
    },
    "model_benchmark_id": 256,
    "analysis_method": "Diamond Avg@8",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.591508+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.481,
    "score": 0.481,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.591508+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7ef"
    },
    "model_benchmark_id": 158,
    "analysis_method": "EM",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:11.403308+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.921,
    "score": 0.921,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.403308+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7f1"
    },
    "model_benchmark_id": 367,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-07-19T19:56:11.789592+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.263,
    "score": 0.263,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.789592+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7f3"
    },
    "model_benchmark_id": 373,
    "analysis_method": "EM",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.808795+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.808795+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7f5"
    },
    "model_benchmark_id": 57,
    "analysis_method": "EM",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.205746+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.205746+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7f7"
    },
    "model_benchmark_id": 161,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.410852+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.410852+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7f9"
    },
    "model_benchmark_id": 221,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-redux-2.0",
    "benchmark_name": "MMLU-redux-2.0",
    "created_at": "2025-07-19T19:56:11.520883+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.520883+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7fb"
    },
    "model_benchmark_id": 222,
    "analysis_method": "Correct",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.524097+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.353,
    "score": 0.353,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.524097+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7fd"
    },
    "model_benchmark_id": 364,
    "analysis_method": "EM",
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-07-19T19:56:11.781413+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.447,
    "score": 0.447,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.781413+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa7ff"
    },
    "model_benchmark_id": 243,
    "analysis_method": "EM",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.566226+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-base",
    "normalized_score": 0.851,
    "score": 0.851,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-K2",
    "updated_at": "2025-07-19T19:56:11.566226+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa801"
    },
    "model_benchmark_id": 444,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.945090+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.775,
    "score": 0.775,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:11.945090+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa803"
    },
    "model_benchmark_id": 435,
    "analysis_method": "Exact Match",
    "benchmark_id": "c-eval",
    "benchmark_name": "C-Eval",
    "created_at": "2025-07-19T19:56:11.922484+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.883,
    "score": 0.883,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:11.922484+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa805"
    },
    "model_benchmark_id": 599,
    "analysis_method": "Exact Match",
    "benchmark_id": "cluewsc",
    "benchmark_name": "CLUEWSC",
    "created_at": "2025-07-19T19:56:12.236097+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.914,
    "score": 0.914,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.236097+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa807"
    },
    "model_benchmark_id": 602,
    "analysis_method": "Exact Match",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.244895+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.872,
    "score": 0.872,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.244895+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa809"
    },
    "model_benchmark_id": 514,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v5-24.12-25.2",
    "benchmark_name": "LiveCodeBench v5 24.12-25.2",
    "created_at": "2025-07-19T19:56:12.068737+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.625,
    "score": 0.625,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.068737+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa80b"
    },
    "model_benchmark_id": 492,
    "analysis_method": "Exact Match",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.029931+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.962,
    "score": 0.962,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.029931+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa80d"
    },
    "model_benchmark_id": 515,
    "analysis_method": "Pass@1",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.071814+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.071814+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa80f"
    },
    "model_benchmark_id": 58,
    "analysis_method": "Exact Match",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.207582+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.874,
    "score": 0.874,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:11.207582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa811"
    },
    "model_benchmark_id": 549,
    "analysis_method": "Pass@1",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.132422+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k1.5",
    "normalized_score": 0.7,
    "score": 0.7,
    "self_reported_source_link": "https://github.com/MoonshotAI/Kimi-k1.5",
    "updated_at": "2025-07-19T19:56:12.132422+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa813"
    },
    "model_benchmark_id": 9001,
    "analysis_method": null,
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2024-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-0905",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://moonshot.cn/blog/kimi-k2-0905",
    "updated_at": "2024-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa815"
    },
    "model_benchmark_id": 9002,
    "analysis_method": "Thinking mode enabled (up to 128K tokens) with enhanced reasoning capabilities and iterative problem-solving approach.",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa817"
    },
    "model_benchmark_id": 9003,
    "analysis_method": null,
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2024-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-0905",
    "normalized_score": 0.891,
    "score": 0.891,
    "self_reported_source_link": "https://moonshot.cn/blog/kimi-k2-0905",
    "updated_at": "2024-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa819"
    },
    "model_benchmark_id": 9004,
    "analysis_method": "Thinking mode enabled (up to 128K tokens) with step-by-step reasoning and multi-language code understanding.",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa81b"
    },
    "model_benchmark_id": 9005,
    "analysis_method": null,
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2024-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-0905",
    "normalized_score": 0.825,
    "score": 0.825,
    "self_reported_source_link": "https://moonshot.cn/blog/kimi-k2-0905",
    "updated_at": "2024-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa81d"
    },
    "model_benchmark_id": 9006,
    "analysis_method": "Standard benchmark across multiple academic subjects with comprehensive knowledge evaluation.",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.925,
    "score": 0.925,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa81f"
    },
    "model_benchmark_id": 10001,
    "analysis_method": "Agentic Coding - Single Attempt",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "Swe Bench Verified",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "65.8% single attempt, 71.6% multiple",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa821"
    },
    "model_benchmark_id": 10002,
    "analysis_method": "Agentic Coding - Single Attempt",
    "benchmark_id": "swe-bench-multilingual",
    "benchmark_name": "Swe Bench Multilingual",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.473,
    "score": 0.473,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa823"
    },
    "model_benchmark_id": 10003,
    "analysis_method": "Terminus",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal Bench",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.25,
    "score": 0.25,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa825"
    },
    "model_benchmark_id": 10004,
    "analysis_method": "v6 (Aug 24-May 25) Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "Livecodebench",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.537,
    "score": 0.537,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa827"
    },
    "model_benchmark_id": 10005,
    "analysis_method": "Pass@1",
    "benchmark_id": "ojbench",
    "benchmark_name": "Ojbench",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.271,
    "score": 0.271,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa829"
    },
    "model_benchmark_id": 10006,
    "analysis_method": "Pass@1",
    "benchmark_id": "multipl-e",
    "benchmark_name": "Multiple",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa82b"
    },
    "model_benchmark_id": 10007,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider Polyglot",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.6,
    "score": 0.6,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa82d"
    },
    "model_benchmark_id": 10008,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-retail",
    "benchmark_name": "Tau2 Retail",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.706,
    "score": 0.706,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa82f"
    },
    "model_benchmark_id": 10009,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-airline",
    "benchmark_name": "Tau2 Airline",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.565,
    "score": 0.565,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa831"
    },
    "model_benchmark_id": 10010,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "Tau2 Telecom",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa833"
    },
    "model_benchmark_id": 10011,
    "analysis_method": "GPT-4.1 with no tools - Competition mathematics (AIME 2025).",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.464,
    "score": 0.464,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa835"
    },
    "model_benchmark_id": 10012,
    "analysis_method": "GPT-4.1 with no tools - Expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.054,
    "score": 0.054,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa837"
    },
    "model_benchmark_id": 10013,
    "analysis_method": "GPT-4.1 with no tools - Harvard-MIT Mathematics Tournament.",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.289,
    "score": 0.289,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa839"
    },
    "model_benchmark_id": 10014,
    "analysis_method": "GPT-4.1 mini with no tools - Competition mathematics (AIME 2025).",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.402,
    "score": 0.402,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa83b"
    },
    "model_benchmark_id": 10015,
    "analysis_method": "GPT-4.1 mini with no tools - Expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.037,
    "score": 0.037,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa83d"
    },
    "model_benchmark_id": 10016,
    "analysis_method": "GPT-4.1 mini with no tools - Harvard-MIT Mathematics Tournament.",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.35,
    "score": 0.35,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa83f"
    },
    "model_benchmark_id": 10017,
    "analysis_method": "Avg@4",
    "benchmark_id": "polymath-en",
    "benchmark_name": "Polymath En",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.651,
    "score": 0.651,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa841"
    },
    "model_benchmark_id": 10018,
    "analysis_method": "Accuracy",
    "benchmark_id": "zebralogic",
    "benchmark_name": "Zebralogic",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa843"
    },
    "model_benchmark_id": 10019,
    "analysis_method": "Accuracy",
    "benchmark_id": "autologi",
    "benchmark_name": "Autologi",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.895,
    "score": 0.895,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa845"
    },
    "model_benchmark_id": 10020,
    "analysis_method": "Diamond - Avg@8",
    "benchmark_id": "gpqa",
    "benchmark_name": "Gpqa",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa847"
    },
    "model_benchmark_id": 10021,
    "analysis_method": "Accuracy",
    "benchmark_id": "supergpqa",
    "benchmark_name": "Supergpqa",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa849"
    },
    "model_benchmark_id": 10022,
    "analysis_method": "Text Only",
    "benchmark_id": "hle",
    "benchmark_name": "Hle",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.047,
    "score": 0.047,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa84b"
    },
    "model_benchmark_id": 10023,
    "analysis_method": "EM",
    "benchmark_id": "mmlu",
    "benchmark_name": "Mmlu",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.895,
    "score": 0.895,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa84d"
    },
    "model_benchmark_id": 10024,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "Mmlu Redux",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.927,
    "score": 0.927,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa84f"
    },
    "model_benchmark_id": 10025,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "Mmlu Pro",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa851"
    },
    "model_benchmark_id": 10026,
    "analysis_method": "Prompt Strict",
    "benchmark_id": "ifeval",
    "benchmark_name": "Ifeval",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.898,
    "score": 0.898,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa853"
    },
    "model_benchmark_id": 10027,
    "analysis_method": "GPT-5 - IC SWE Diamond Freelance Coding Tasks (earnings-based evaluation).",
    "benchmark_id": "swe-lancer-(ic-diamond-subset)",
    "benchmark_name": "SWE-Lancer (IC-Diamond subset)",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 1.0,
    "score": 1.0,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa855"
    },
    "model_benchmark_id": 10028,
    "analysis_method": "Correct",
    "benchmark_id": "simpleqa",
    "benchmark_name": "Simpleqa",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.31,
    "score": 0.31,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa857"
    },
    "model_benchmark_id": 10029,
    "analysis_method": "2024/11/25 Pass@1",
    "benchmark_id": "livebench",
    "benchmark_name": "Livebench",
    "created_at": "2025-09-05T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct-0905",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa859"
    },
    "model_benchmark_id": 676,
    "analysis_method": "Accuracy",
    "benchmark_id": "acebench",
    "benchmark_name": "AceBench",
    "created_at": "2025-07-19T19:56:12.408910+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.765,
    "score": 0.765,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.408910+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa85b"
    },
    "model_benchmark_id": 657,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.362819+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.6,
    "score": 0.6,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.362819+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa85d"
    },
    "model_benchmark_id": 445,
    "analysis_method": "Avg@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.946639+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.946639+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa85f"
    },
    "model_benchmark_id": 677,
    "analysis_method": "Avg@64",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.412395+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.495,
    "score": 0.495,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.412395+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa861"
    },
    "model_benchmark_id": 715,
    "analysis_method": "Accuracy",
    "benchmark_id": "autologi",
    "benchmark_name": "AutoLogi",
    "created_at": "2025-07-19T19:56:12.506457+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.895,
    "score": 0.895,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.506457+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa863"
    },
    "model_benchmark_id": 757,
    "analysis_method": "Accuracy",
    "benchmark_id": "cbnsl",
    "benchmark_name": "CBNSL",
    "created_at": "2025-07-19T19:56:12.594017+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.956,
    "score": 0.956,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.594017+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa865"
    },
    "model_benchmark_id": 709,
    "analysis_method": "Avg@16",
    "benchmark_id": "cnmo-2024",
    "benchmark_name": "CNMO 2024",
    "created_at": "2025-07-19T19:56:12.489469+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.489469+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa867"
    },
    "model_benchmark_id": 441,
    "analysis_method": "Correct",
    "benchmark_id": "csimpleqa",
    "benchmark_name": "CSimpleQA",
    "created_at": "2025-07-19T19:56:11.936097+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.784,
    "score": 0.784,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.936097+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa869"
    },
    "model_benchmark_id": 257,
    "analysis_method": "Diamond Avg@8",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.593256+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.593256+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa86b"
    },
    "model_benchmark_id": 159,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:11.405113+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.973,
    "score": 0.973,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.405113+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa86d"
    },
    "model_benchmark_id": 707,
    "analysis_method": "Avg@32",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-19T19:56:12.482540+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.388,
    "score": 0.388,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.482540+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa86f"
    },
    "model_benchmark_id": 758,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.598519+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.598519+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa871"
    },
    "model_benchmark_id": 819,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval-er",
    "benchmark_name": "HumanEval-ER",
    "created_at": "2025-07-19T19:56:12.707650+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.707650+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa873"
    },
    "model_benchmark_id": 716,
    "analysis_method": "Accuracy (Text Only)",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.510122+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.047,
    "score": 0.047,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.510122+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa875"
    },
    "model_benchmark_id": 603,
    "analysis_method": "Prompt Strict",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.247003+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.898,
    "score": 0.898,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.247003+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa877"
    },
    "model_benchmark_id": 745,
    "analysis_method": "Pass@1",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.567525+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.567525+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa879"
    },
    "model_benchmark_id": 368,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-07-19T19:56:11.791826+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.537,
    "score": 0.537,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.791826+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa87b"
    },
    "model_benchmark_id": 493,
    "analysis_method": "Accuracy",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.031465+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.974,
    "score": 0.974,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.031465+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa87d"
    },
    "model_benchmark_id": 59,
    "analysis_method": "EM",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.209924+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.895,
    "score": 0.895,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.209924+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa87f"
    },
    "model_benchmark_id": 162,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.412849+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.412849+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa881"
    },
    "model_benchmark_id": 727,
    "analysis_method": "EM",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.531649+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.927,
    "score": 0.927,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.531649+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa883"
    },
    "model_benchmark_id": 739,
    "analysis_method": "Accuracy",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.554319+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.541,
    "score": 0.541,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.554319+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa885"
    },
    "model_benchmark_id": 639,
    "analysis_method": "Pass@1",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.314432+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.314432+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa887"
    },
    "model_benchmark_id": 820,
    "analysis_method": "Pass@1",
    "benchmark_id": "musr",
    "benchmark_name": "MuSR",
    "created_at": "2025-07-19T19:56:12.711252+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.711252+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa889"
    },
    "model_benchmark_id": 638,
    "analysis_method": "Pass@1",
    "benchmark_id": "ojbench",
    "benchmark_name": "OJBench",
    "created_at": "2025-07-19T19:56:12.310963+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.271,
    "score": 0.271,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.310963+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa88b"
    },
    "model_benchmark_id": 713,
    "analysis_method": "Avg@4",
    "benchmark_id": "polymath-en",
    "benchmark_name": "PolyMath-en",
    "created_at": "2025-07-19T19:56:12.499339+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.651,
    "score": 0.651,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.499339+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa88d"
    },
    "model_benchmark_id": 223,
    "analysis_method": "Correct",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.526736+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.31,
    "score": 0.31,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.526736+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa88f"
    },
    "model_benchmark_id": 365,
    "analysis_method": "Accuracy",
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-07-19T19:56:11.782850+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:11.782850+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa891"
    },
    "model_benchmark_id": 651,
    "analysis_method": "Single Attempt",
    "benchmark_id": "swe-bench-multilingual",
    "benchmark_name": "SWE-bench Multilingual",
    "created_at": "2025-07-19T19:56:12.343981+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.473,
    "score": 0.473,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.343981+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa893"
    },
    "model_benchmark_id": 649,
    "analysis_method": "Single Attempt",
    "benchmark_id": "swe-bench-verified-(agentic-coding)",
    "benchmark_name": "SWE-bench Verified (Agentic Coding)",
    "created_at": "2025-07-19T19:56:12.333761+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.333761+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa895"
    },
    "model_benchmark_id": 648,
    "analysis_method": "Single Patch without Test",
    "benchmark_id": "swe-bench-verified-(agentless)",
    "benchmark_name": "SWE-bench Verified (Agentless)",
    "created_at": "2025-07-19T19:56:12.330548+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.518,
    "score": 0.518,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.330548+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa897"
    },
    "model_benchmark_id": 650,
    "analysis_method": "Multiple Attempts with parallel test-time compute",
    "benchmark_id": "swe-bench-verified-(multiple-attempts)",
    "benchmark_name": "SWE-bench Verified (Multiple Attempts)",
    "created_at": "2025-07-19T19:56:12.339305+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.339305+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa899"
    },
    "model_benchmark_id": 674,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-airline",
    "benchmark_name": "Tau2 airline",
    "created_at": "2025-07-19T19:56:12.401229+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.565,
    "score": 0.565,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.401229+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa89b"
    },
    "model_benchmark_id": 673,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-retail",
    "benchmark_name": "Tau2 retail",
    "created_at": "2025-07-19T19:56:12.395604+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.706,
    "score": 0.706,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.395604+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa89d"
    },
    "model_benchmark_id": 675,
    "analysis_method": "Avg@4",
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "Tau2 telecom",
    "created_at": "2025-07-19T19:56:12.405145+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.405145+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa89f"
    },
    "model_benchmark_id": 652,
    "analysis_method": "Inhouse Framework",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-bench",
    "created_at": "2025-07-19T19:56:12.348003+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.3,
    "score": 0.3,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.348003+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8a1"
    },
    "model_benchmark_id": 656,
    "analysis_method": "Accuracy",
    "benchmark_id": "terminus",
    "benchmark_name": "Terminus",
    "created_at": "2025-07-19T19:56:12.358921+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.25,
    "score": 0.25,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.358921+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8a3"
    },
    "model_benchmark_id": 714,
    "analysis_method": "Accuracy",
    "benchmark_id": "zebralogic",
    "benchmark_name": "ZebraLogic",
    "created_at": "2025-07-19T19:56:12.502879+00:00",
    "is_self_reported": true,
    "model_id": "kimi-k2-instruct",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://moonshotai.github.io/Kimi-K2/",
    "updated_at": "2025-07-19T19:56:12.502879+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8a5"
    },
    "model_benchmark_id": 2,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.080108+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.924,
    "score": 0.924,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.080108+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8a7"
    },
    "model_benchmark_id": 967,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.034481+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.824,
    "score": 0.824,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:13.034481+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8a9"
    },
    "model_benchmark_id": 843,
    "analysis_method": "accuracy",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.766776+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.666,
    "score": 0.666,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.766776+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8ab"
    },
    "model_benchmark_id": 853,
    "analysis_method": "relaxed accuracy",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.786772+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.786772+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8ad"
    },
    "model_benchmark_id": 834,
    "analysis_method": "accuracy",
    "benchmark_id": "crag",
    "benchmark_name": "CRAG",
    "created_at": "2025-07-19T19:56:12.743484+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.438,
    "score": 0.438,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.743484+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8af"
    },
    "model_benchmark_id": 876,
    "analysis_method": "ANLS",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.827478+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.924,
    "score": 0.924,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.827478+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8b1"
    },
    "model_benchmark_id": 939,
    "analysis_method": "0-shot",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.984716+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.984716+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8b3"
    },
    "model_benchmark_id": 918,
    "analysis_method": "accuracy",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.918221+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.714,
    "score": 0.714,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.918221+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8b5"
    },
    "model_benchmark_id": 831,
    "analysis_method": "0-shot accuracy",
    "benchmark_id": "finqa",
    "benchmark_name": "FinQA",
    "created_at": "2025-07-19T19:56:12.736609+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.736,
    "score": 0.736,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.736609+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8b7"
    },
    "model_benchmark_id": 258,
    "analysis_method": "6-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.594691+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.42,
    "score": 0.42,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.594691+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8b9"
    },
    "model_benchmark_id": 841,
    "analysis_method": "accuracy",
    "benchmark_id": "groundui-1k",
    "benchmark_name": "GroundUI-1K",
    "created_at": "2025-07-19T19:56:12.761300+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.761300+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8bb"
    },
    "model_benchmark_id": 160,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:11.407299+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.945,
    "score": 0.945,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.407299+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8bd"
    },
    "model_benchmark_id": 759,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.601822+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.854,
    "score": 0.854,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.601822+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8bf"
    },
    "model_benchmark_id": 604,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.248959+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.897,
    "score": 0.897,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.248959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8c1"
    },
    "model_benchmark_id": 826,
    "analysis_method": "accuracy",
    "benchmark_id": "lvbench",
    "benchmark_name": "LVBench",
    "created_at": "2025-07-19T19:56:12.726573+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.404,
    "score": 0.404,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.726573+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8c3"
    },
    "model_benchmark_id": 374,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.810622+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.810622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8c5"
    },
    "model_benchmark_id": 60,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.212315+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.212315+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8c7"
    },
    "model_benchmark_id": 839,
    "analysis_method": "accuracy",
    "benchmark_id": "mm-mind2web",
    "benchmark_name": "MM-Mind2Web",
    "created_at": "2025-07-19T19:56:12.755878+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.607,
    "score": 0.607,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.755878+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8c9"
    },
    "model_benchmark_id": 550,
    "analysis_method": "CoT accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.134288+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.562,
    "score": 0.562,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.134288+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8cb"
    },
    "model_benchmark_id": 821,
    "analysis_method": "rouge-l",
    "benchmark_id": "squality",
    "benchmark_name": "SQuALITY",
    "created_at": "2025-07-19T19:56:12.715662+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.192,
    "score": 0.192,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.715662+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8cd"
    },
    "model_benchmark_id": 901,
    "analysis_method": "weighted accuracy",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.878076+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.878076+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8cf"
    },
    "model_benchmark_id": 930,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-en\u2192set1-comet22",
    "benchmark_name": "Translation en\u2192Set1 COMET22",
    "created_at": "2025-07-19T19:56:12.962491+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.888,
    "score": 0.888,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.962491+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8d1"
    },
    "model_benchmark_id": 927,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-en\u2192set1-spbleu",
    "benchmark_name": "Translation en\u2192Set1 spBleu",
    "created_at": "2025-07-19T19:56:12.942744+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.415,
    "score": 0.415,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.942744+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8d3"
    },
    "model_benchmark_id": 936,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-set1\u2192en-comet22",
    "benchmark_name": "Translation Set1\u2192en COMET22",
    "created_at": "2025-07-19T19:56:12.977060+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.888,
    "score": 0.888,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.977060+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8d5"
    },
    "model_benchmark_id": 933,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-set1\u2192en-spbleu",
    "benchmark_name": "Translation Set1\u2192en spBleu",
    "created_at": "2025-07-19T19:56:12.969524+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.969524+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8d7"
    },
    "model_benchmark_id": 916,
    "analysis_method": "CIDEr",
    "benchmark_id": "vatex",
    "benchmark_name": "VATEX",
    "created_at": "2025-07-19T19:56:12.912261+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.912261+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8d9"
    },
    "model_benchmark_id": 837,
    "analysis_method": "composite step accuracy",
    "benchmark_id": "visualwebbench",
    "benchmark_name": "VisualWebBench",
    "created_at": "2025-07-19T19:56:12.750738+00:00",
    "is_self_reported": true,
    "model_id": "nova-lite",
    "normalized_score": 0.777,
    "score": 0.777,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.750738+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8db"
    },
    "model_benchmark_id": 3,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.085849+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.948,
    "score": 0.948,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.085849+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8dd"
    },
    "model_benchmark_id": 968,
    "analysis_method": "3-shot Chain-of-Thought",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.036192+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.869,
    "score": 0.869,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:13.036192+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8df"
    },
    "model_benchmark_id": 844,
    "analysis_method": "accuracy",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.768714+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.768714+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8e1"
    },
    "model_benchmark_id": 854,
    "analysis_method": "relaxed accuracy",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.788270+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.892,
    "score": 0.892,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.788270+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8e3"
    },
    "model_benchmark_id": 835,
    "analysis_method": "accuracy",
    "benchmark_id": "crag",
    "benchmark_name": "CRAG",
    "created_at": "2025-07-19T19:56:12.744994+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.503,
    "score": 0.503,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.744994+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8e5"
    },
    "model_benchmark_id": 877,
    "analysis_method": "ANLS",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.829064+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.935,
    "score": 0.935,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.829064+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8e7"
    },
    "model_benchmark_id": 940,
    "analysis_method": "0-shot",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.986311+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.854,
    "score": 0.854,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.986311+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8e9"
    },
    "model_benchmark_id": 919,
    "analysis_method": "accuracy",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.920400+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.721,
    "score": 0.721,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.920400+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8eb"
    },
    "model_benchmark_id": 832,
    "analysis_method": "0-shot accuracy",
    "benchmark_id": "finqa",
    "benchmark_name": "FinQA",
    "created_at": "2025-07-19T19:56:12.738456+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.772,
    "score": 0.772,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.738456+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8ed"
    },
    "model_benchmark_id": 259,
    "analysis_method": "6-shot Chain-of-Thought",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.596541+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.469,
    "score": 0.469,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.596541+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8ef"
    },
    "model_benchmark_id": 842,
    "analysis_method": "accuracy",
    "benchmark_id": "groundui-1k",
    "benchmark_name": "GroundUI-1K",
    "created_at": "2025-07-19T19:56:12.762846+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.762846+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8f1"
    },
    "model_benchmark_id": 975,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.049455+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.948,
    "score": 0.948,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:13.049455+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8f3"
    },
    "model_benchmark_id": 760,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.603428+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.603428+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8f5"
    },
    "model_benchmark_id": 605,
    "analysis_method": "0-shot",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.250818+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.921,
    "score": 0.921,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.250818+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8f7"
    },
    "model_benchmark_id": 827,
    "analysis_method": "accuracy",
    "benchmark_id": "lvbench",
    "benchmark_name": "LVBench",
    "created_at": "2025-07-19T19:56:12.728104+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.416,
    "score": 0.416,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.728104+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8f9"
    },
    "model_benchmark_id": 375,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.812663+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.812663+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8fb"
    },
    "model_benchmark_id": 61,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.214544+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.859,
    "score": 0.859,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.214544+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8fd"
    },
    "model_benchmark_id": 840,
    "analysis_method": "step accuracy",
    "benchmark_id": "mm-mind2web",
    "benchmark_name": "MM-Mind2Web",
    "created_at": "2025-07-19T19:56:12.757670+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.637,
    "score": 0.637,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.757670+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa8ff"
    },
    "model_benchmark_id": 551,
    "analysis_method": "Chain-of-Thought",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.135953+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.617,
    "score": 0.617,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.135953+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa901"
    },
    "model_benchmark_id": 822,
    "analysis_method": "ROUGE-L",
    "benchmark_id": "squality",
    "benchmark_name": "SQuALITY",
    "created_at": "2025-07-19T19:56:12.717624+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.198,
    "score": 0.198,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.717624+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa903"
    },
    "model_benchmark_id": 902,
    "analysis_method": "weighted accuracy",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.880228+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.815,
    "score": 0.815,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.880228+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa905"
    },
    "model_benchmark_id": 931,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-en\u2192set1-comet22",
    "benchmark_name": "Translation en\u2192Set1 COMET22",
    "created_at": "2025-07-19T19:56:12.964047+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.891,
    "score": 0.891,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.964047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa907"
    },
    "model_benchmark_id": 928,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-en\u2192set1-spbleu",
    "benchmark_name": "Translation en\u2192Set1 spBleu",
    "created_at": "2025-07-19T19:56:12.950458+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.434,
    "score": 0.434,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.950458+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa909"
    },
    "model_benchmark_id": 937,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-set1\u2192en-comet22",
    "benchmark_name": "Translation Set1\u2192en COMET22",
    "created_at": "2025-07-19T19:56:12.978787+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.978787+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa90b"
    },
    "model_benchmark_id": 934,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-set1\u2192en-spbleu",
    "benchmark_name": "Translation Set1\u2192en spBleu",
    "created_at": "2025-07-19T19:56:12.971295+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.444,
    "score": 0.444,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.971295+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa90d"
    },
    "model_benchmark_id": 917,
    "analysis_method": "CIDEr",
    "benchmark_id": "vatex",
    "benchmark_name": "VATEX",
    "created_at": "2025-07-19T19:56:12.913837+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.913837+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa90f"
    },
    "model_benchmark_id": 838,
    "analysis_method": "composite",
    "benchmark_id": "visualwebbench",
    "benchmark_name": "VisualWebBench",
    "created_at": "2025-07-19T19:56:12.752533+00:00",
    "is_self_reported": true,
    "model_id": "nova-pro",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.752533+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa911"
    },
    "model_benchmark_id": 4,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.088301+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.088301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa913"
    },
    "model_benchmark_id": 969,
    "analysis_method": "3-shot Chain-of-Thought",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.038288+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.795,
    "score": 0.795,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:13.038288+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa915"
    },
    "model_benchmark_id": 845,
    "analysis_method": "accuracy",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.770319+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.562,
    "score": 0.562,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.770319+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa917"
    },
    "model_benchmark_id": 836,
    "analysis_method": "accuracy",
    "benchmark_id": "crag",
    "benchmark_name": "CRAG",
    "created_at": "2025-07-19T19:56:12.746657+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.746657+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa919"
    },
    "model_benchmark_id": 941,
    "analysis_method": "6-shot Chain-of-Thought",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.987950+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.793,
    "score": 0.793,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.987950+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa91b"
    },
    "model_benchmark_id": 833,
    "analysis_method": "0-shot accuracy",
    "benchmark_id": "finqa",
    "benchmark_name": "FinQA",
    "created_at": "2025-07-19T19:56:12.740201+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.652,
    "score": 0.652,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.740201+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa91d"
    },
    "model_benchmark_id": 260,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.598530+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.4,
    "score": 0.4,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.598530+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa91f"
    },
    "model_benchmark_id": 976,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.051041+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:13.051041+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa921"
    },
    "model_benchmark_id": 761,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.605066+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.605066+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa923"
    },
    "model_benchmark_id": 606,
    "analysis_method": "0-shot",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.252589+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.872,
    "score": 0.872,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.252589+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa925"
    },
    "model_benchmark_id": 376,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.814150+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.693,
    "score": 0.693,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.814150+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa927"
    },
    "model_benchmark_id": 62,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.217284+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:11.217284+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa929"
    },
    "model_benchmark_id": 823,
    "analysis_method": "rouge-l",
    "benchmark_id": "squality",
    "benchmark_name": "SQuALITY",
    "created_at": "2025-07-19T19:56:12.719314+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.188,
    "score": 0.188,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.719314+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa92b"
    },
    "model_benchmark_id": 932,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-en\u2192set1-comet22",
    "benchmark_name": "Translation en\u2192Set1 COMET22",
    "created_at": "2025-07-19T19:56:12.966157+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.966157+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa92d"
    },
    "model_benchmark_id": 929,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-en\u2192set1-spbleu",
    "benchmark_name": "Translation en\u2192Set1 spBleu",
    "created_at": "2025-07-19T19:56:12.958167+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.402,
    "score": 0.402,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.958167+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa92f"
    },
    "model_benchmark_id": 938,
    "analysis_method": "COMET22",
    "benchmark_id": "translation-set1\u2192en-comet22",
    "benchmark_name": "Translation Set1\u2192en COMET22",
    "created_at": "2025-07-19T19:56:12.980365+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.887,
    "score": 0.887,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.980365+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa931"
    },
    "model_benchmark_id": 935,
    "analysis_method": "spBleu",
    "benchmark_id": "translation-set1\u2192en-spbleu",
    "benchmark_name": "Translation Set1\u2192en spBleu",
    "created_at": "2025-07-19T19:56:12.973209+00:00",
    "is_self_reported": true,
    "model_id": "nova-micro",
    "normalized_score": 0.426,
    "score": 0.426,
    "self_reported_source_link": "https://www.amazon.science/publications/the-amazon-nova-family-of-models-technical-report-and-model-card",
    "updated_at": "2025-07-19T19:56:12.973209+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa933"
    },
    "model_benchmark_id": 5,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.091862+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.616,
    "score": 0.616,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:11.091862+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa935"
    },
    "model_benchmark_id": 1051,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.195091+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.195091+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa937"
    },
    "model_benchmark_id": 1066,
    "analysis_method": "few-shot",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.225269+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.529,
    "score": 0.529,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.225269+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa939"
    },
    "model_benchmark_id": 1017,
    "analysis_method": "0-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.120054+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.120054+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa93b"
    },
    "model_benchmark_id": 942,
    "analysis_method": "Token F1 score. 1-shot.",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.989555+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:12.989555+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa93d"
    },
    "model_benchmark_id": 33,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.150880+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:11.150880+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa93f"
    },
    "model_benchmark_id": 1044,
    "analysis_method": "5-shot",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.181324+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.209,
    "score": 0.209,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.181324+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa941"
    },
    "model_benchmark_id": 1026,
    "analysis_method": "0-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.136080+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.136080+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa943"
    },
    "model_benchmark_id": 1035,
    "analysis_method": "0-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.159816+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.159816+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa945"
    },
    "model_benchmark_id": 244,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.567693+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:11.567693+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa947"
    },
    "model_benchmark_id": 1057,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.207598+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b",
    "normalized_score": 0.717,
    "score": 0.717,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B",
    "updated_at": "2025-07-19T19:56:13.207598+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa949"
    },
    "model_benchmark_id": 1247,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.621225+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.842,
    "score": 0.842,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.621225+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa94b"
    },
    "model_benchmark_id": 1096,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-extra-hard",
    "benchmark_name": "BIG-Bench Extra Hard",
    "created_at": "2025-07-19T19:56:13.282747+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.163,
    "score": 0.163,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.282747+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa94d"
    },
    "model_benchmark_id": 1067,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.226924+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.226924+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa94f"
    },
    "model_benchmark_id": 1147,
    "analysis_method": "- evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.413629+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.479,
    "score": 0.479,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.413629+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa951"
    },
    "model_benchmark_id": 855,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.789962+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.757,
    "score": 0.757,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.789962+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa953"
    },
    "model_benchmark_id": 878,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.830839+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.830839+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa955"
    },
    "model_benchmark_id": 1219,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.563615+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.103,
    "score": 0.103,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.563615+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa957"
    },
    "model_benchmark_id": 1087,
    "analysis_method": "- evaluation",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.262640+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.262640+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa959"
    },
    "model_benchmark_id": 1205,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.537058+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.695,
    "score": 0.695,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.537058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa95b"
    },
    "model_benchmark_id": 261,
    "analysis_method": "0-shot evaluation diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.600334+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.409,
    "score": 0.409,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.600334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa95d"
    },
    "model_benchmark_id": 977,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.052379+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.944,
    "score": 0.944,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.052379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa95f"
    },
    "model_benchmark_id": 1153,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.427708+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.545,
    "score": 0.545,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.427708+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa961"
    },
    "model_benchmark_id": 762,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.606840+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.854,
    "score": 0.854,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.606840+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa963"
    },
    "model_benchmark_id": 607,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.254325+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.889,
    "score": 0.889,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.254325+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa965"
    },
    "model_benchmark_id": 1238,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.604072+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.604072+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa967"
    },
    "model_benchmark_id": 1101,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.294686+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.246,
    "score": 0.246,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.294686+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa969"
    },
    "model_benchmark_id": 377,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.815597+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.838,
    "score": 0.838,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.815597+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa96b"
    },
    "model_benchmark_id": 1266,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.657019+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.629,
    "score": 0.629,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.657019+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa96d"
    },
    "model_benchmark_id": 1166,
    "analysis_method": "3-shot evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.456223+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.456223+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa96f"
    },
    "model_benchmark_id": 163,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.415028+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.606,
    "score": 0.606,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.415028+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa971"
    },
    "model_benchmark_id": 1235,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mmmu-(val)",
    "benchmark_name": "MMMU (val)",
    "created_at": "2025-07-19T19:56:13.595790+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.596,
    "score": 0.596,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.595790+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa973"
    },
    "model_benchmark_id": 1197,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.521277+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.807,
    "score": 0.807,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.521277+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa975"
    },
    "model_benchmark_id": 224,
    "analysis_method": "Score",
    "benchmark_id": "healthbench",
    "benchmark_name": "HealthBench - Realistic health conversations",
    "created_at": "2025-08-05T19:49:05.852855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-oss-20b",
    "normalized_score": 0.425,
    "score": 0.425,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-oss/",
    "updated_at": "2025-08-05T19:49:05.852855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa977"
    },
    "model_benchmark_id": 903,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.882990+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.677,
    "score": 0.677,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.882990+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa979"
    },
    "model_benchmark_id": 1263,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "vqav2-(val)",
    "benchmark_name": "VQAv2 (val)",
    "created_at": "2025-07-19T19:56:13.650557+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.650557+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa97b"
    },
    "model_benchmark_id": 1227,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.578915+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-12b-it",
    "normalized_score": 0.516,
    "score": 0.516,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.578915+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa97d"
    },
    "model_benchmark_id": 678,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.414248+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.116,
    "score": 0.116,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.414248+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa97f"
    },
    "model_benchmark_id": 6,
    "analysis_method": "25-shot Accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.093723+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.616,
    "score": 0.616,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.093723+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa981"
    },
    "model_benchmark_id": 1052,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.196728+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.196728+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa983"
    },
    "model_benchmark_id": 1068,
    "analysis_method": "few-shot Accuracy",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.228349+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.529,
    "score": 0.529,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.228349+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa985"
    },
    "model_benchmark_id": 1018,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.121696+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.121696+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa987"
    },
    "model_benchmark_id": 1324,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "codegolf-v2.2",
    "benchmark_name": "Codegolf v2.2",
    "created_at": "2025-07-19T19:56:13.781222+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.168,
    "score": 0.168,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.781222+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa989"
    },
    "model_benchmark_id": 943,
    "analysis_method": "1-shot Token F1 score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.991359+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.991359+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa98b"
    },
    "model_benchmark_id": 1220,
    "analysis_method": "0-shot ECLeKTic score",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.565422+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.019,
    "score": 0.019,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.565422+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa98d"
    },
    "model_benchmark_id": 1313,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "global-mmlu",
    "benchmark_name": "Global-MMLU",
    "created_at": "2025-07-19T19:56:13.752749+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.603,
    "score": 0.603,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.752749+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa98f"
    },
    "model_benchmark_id": 1206,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.538643+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.645,
    "score": 0.645,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.538643+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa991"
    },
    "model_benchmark_id": 262,
    "analysis_method": "Diamond, 0-shot RelaxedAccuracy/accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.602493+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.237,
    "score": 0.237,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.602493+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa993"
    },
    "model_benchmark_id": 34,
    "analysis_method": "10-shot Accuracy",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.152761+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.152761+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa995"
    },
    "model_benchmark_id": 1154,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.429415+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.377,
    "score": 0.377,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.429415+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa997"
    },
    "model_benchmark_id": 763,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.608423+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.608423+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa999"
    },
    "model_benchmark_id": 1304,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "include",
    "benchmark_name": "Include",
    "created_at": "2025-07-19T19:56:13.729199+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.729199+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa99b"
    },
    "model_benchmark_id": 1102,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.296281+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.132,
    "score": 0.132,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.296281+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa99d"
    },
    "model_benchmark_id": 1317,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.761673+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.257,
    "score": 0.257,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.761673+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa99f"
    },
    "model_benchmark_id": 1167,
    "analysis_method": "3-shot pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.458570+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.636,
    "score": 0.636,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.458570+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9a1"
    },
    "model_benchmark_id": 1273,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.671283+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.607,
    "score": 0.607,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.671283+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9a3"
    },
    "model_benchmark_id": 63,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.219372+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.219372+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9a5"
    },
    "model_benchmark_id": 164,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.420000+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.506,
    "score": 0.506,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.420000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9a7"
    },
    "model_benchmark_id": 1309,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-07-19T19:56:13.741460+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.199,
    "score": 0.199,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.741460+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9a9"
    },
    "model_benchmark_id": 1045,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.183031+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.209,
    "score": 0.209,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.183031+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9ab"
    },
    "model_benchmark_id": 1027,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.137952+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.137952+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9ad"
    },
    "model_benchmark_id": 1036,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.161822+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.161822+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9af"
    },
    "model_benchmark_id": 245,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.569334+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.569334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9b1"
    },
    "model_benchmark_id": 1058,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.209229+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.717,
    "score": 0.717,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.209229+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9b3"
    },
    "model_benchmark_id": 1228,
    "analysis_method": "ChrF, 0-shot Character-level F-score",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.580409+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it-litert-preview",
    "normalized_score": 0.501,
    "score": 0.501,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.580409+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9b5"
    },
    "model_benchmark_id": 658,
    "analysis_method": "-",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.364634+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.765,
    "score": 0.765,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.364634+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9b7"
    },
    "model_benchmark_id": 1328,
    "analysis_method": "Diff",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.793176+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.727,
    "score": 0.727,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.793176+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9b9"
    },
    "model_benchmark_id": 446,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.948567+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.92,
    "score": 0.92,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:11.948567+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9bb"
    },
    "model_benchmark_id": 679,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.417055+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.83,
    "score": 0.83,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.417055+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9bd"
    },
    "model_benchmark_id": 1385,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-agi-v2",
    "benchmark_name": "ARC-AGI v2",
    "created_at": "2025-07-19T19:56:13.918991+00:00",
    "is_self_reported": false,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.049,
    "score": 0.049,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.918991+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9bf"
    },
    "model_benchmark_id": 1207,
    "analysis_method": "Accuracy",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.540318+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.540318+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9c1"
    },
    "model_benchmark_id": 263,
    "analysis_method": "Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.605360+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.83,
    "score": 0.83,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:11.605360+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9c3"
    },
    "model_benchmark_id": 717,
    "analysis_method": "Accuracy",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.511856+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.178,
    "score": 0.178,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.511856+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9c5"
    },
    "model_benchmark_id": 1318,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.763325+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.756,
    "score": 0.756,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.763325+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9c7"
    },
    "model_benchmark_id": 552,
    "analysis_method": "Pass@1",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.137517+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.796,
    "score": 0.796,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.137517+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9c9"
    },
    "model_benchmark_id": 1372,
    "analysis_method": "128k-average",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.889867+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.93,
    "score": 0.93,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.889867+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9cb"
    },
    "model_benchmark_id": 1384,
    "analysis_method": "Pointwise",
    "benchmark_id": "mrcr-1m-(pointwise)",
    "benchmark_name": "MRCR 1M (pointwise)",
    "created_at": "2025-07-19T19:56:13.915166+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.829,
    "score": 0.829,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.915166+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9cd"
    },
    "model_benchmark_id": 225,
    "analysis_method": "Score",
    "benchmark_id": "healthbench-hard",
    "benchmark_name": "HealthBench Hard - Challenging health conversations",
    "created_at": "2025-08-05T19:49:05.852855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-oss-20b",
    "normalized_score": 0.108,
    "score": 0.108,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-oss/",
    "updated_at": "2025-08-05T19:49:05.852855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9cf"
    },
    "model_benchmark_id": 1338,
    "analysis_method": "Accuracy",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.816932+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.632,
    "score": 0.632,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.816932+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9d1"
    },
    "model_benchmark_id": 1364,
    "analysis_method": "Accuracy",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.874453+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.656,
    "score": 0.656,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.874453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9d3"
    },
    "model_benchmark_id": 1379,
    "analysis_method": "Accuracy",
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "created_at": "2025-07-19T19:56:13.904547+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://deepmind.google/models/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.904547+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9d5"
    },
    "model_benchmark_id": 1390,
    "analysis_method": "Accuracy",
    "benchmark_id": "big-bench",
    "benchmark_name": "BIG-Bench",
    "created_at": "2025-07-19T19:56:13.928761+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:13.928761+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9d7"
    },
    "model_benchmark_id": 920,
    "analysis_method": "Accuracy",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.922622+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.557,
    "score": 0.557,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.922622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9d9"
    },
    "model_benchmark_id": 1397,
    "analysis_method": "Accuracy",
    "benchmark_id": "fleurs",
    "benchmark_name": "FLEURS",
    "created_at": "2025-07-19T19:56:13.946039+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.064,
    "score": 0.064,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:13.946039+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9db"
    },
    "model_benchmark_id": 264,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.607534+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.279,
    "score": 0.279,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.607534+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9dd"
    },
    "model_benchmark_id": 378,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.817378+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.326,
    "score": 0.326,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.817378+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9df"
    },
    "model_benchmark_id": 516,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.073663+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.466,
    "score": 0.466,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:12.073663+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9e1"
    },
    "model_benchmark_id": 64,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.221259+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.718,
    "score": 0.718,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.221259+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9e3"
    },
    "model_benchmark_id": 553,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.139083+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.479,
    "score": 0.479,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:12.139083+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9e5"
    },
    "model_benchmark_id": 1393,
    "analysis_method": "Accuracy",
    "benchmark_id": "wmt23",
    "benchmark_name": "WMT23",
    "created_at": "2025-07-19T19:56:13.937549+00:00",
    "is_self_reported": false,
    "model_id": "gemini-1.0-pro",
    "normalized_score": 0.717,
    "score": 0.717,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:13.937549+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9e7"
    },
    "model_benchmark_id": 680,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.419451+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.067,
    "score": 0.067,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.419451+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9e9"
    },
    "model_benchmark_id": 7,
    "analysis_method": "25-shot Accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.095909+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.517,
    "score": 0.517,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.095909+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9eb"
    },
    "model_benchmark_id": 1053,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.199540+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.199540+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9ed"
    },
    "model_benchmark_id": 1069,
    "analysis_method": "few-shot Accuracy",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.229977+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.443,
    "score": 0.443,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.229977+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9ef"
    },
    "model_benchmark_id": 1019,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.123278+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.123278+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9f1"
    },
    "model_benchmark_id": 1325,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "codegolf-v2.2",
    "benchmark_name": "Codegolf v2.2",
    "created_at": "2025-07-19T19:56:13.783685+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.11,
    "score": 0.11,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.783685+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9f3"
    },
    "model_benchmark_id": 944,
    "analysis_method": "1-shot Token F1 score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.993202+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.539,
    "score": 0.539,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.993202+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9f5"
    },
    "model_benchmark_id": 1221,
    "analysis_method": "0-shot ECLeKTic score",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.567241+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.025,
    "score": 0.025,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.567241+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9f7"
    },
    "model_benchmark_id": 1314,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "global-mmlu",
    "benchmark_name": "Global-MMLU",
    "created_at": "2025-07-19T19:56:13.754602+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.551,
    "score": 0.551,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.754602+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9f9"
    },
    "model_benchmark_id": 1208,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.542151+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.59,
    "score": 0.59,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.542151+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9fb"
    },
    "model_benchmark_id": 265,
    "analysis_method": "Diamond, 0-shot RelaxedAccuracy/accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.609514+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.248,
    "score": 0.248,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.609514+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9fd"
    },
    "model_benchmark_id": 35,
    "analysis_method": "10-shot Accuracy",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.154889+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.154889+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daa9ff"
    },
    "model_benchmark_id": 1155,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.431354+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.277,
    "score": 0.277,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.431354+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa01"
    },
    "model_benchmark_id": 764,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.609959+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.665,
    "score": 0.665,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:12.609959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa03"
    },
    "model_benchmark_id": 1305,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "include",
    "benchmark_name": "Include",
    "created_at": "2025-07-19T19:56:13.731041+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.386,
    "score": 0.386,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.731041+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa05"
    },
    "model_benchmark_id": 1103,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.298197+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.132,
    "score": 0.132,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.298197+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa07"
    },
    "model_benchmark_id": 1319,
    "analysis_method": "0-shot pass@1",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.768006+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.186,
    "score": 0.186,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.768006+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa09"
    },
    "model_benchmark_id": 1168,
    "analysis_method": "3-shot pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.460487+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.566,
    "score": 0.566,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.460487+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa0b"
    },
    "model_benchmark_id": 1274,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.672774+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.531,
    "score": 0.531,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.672774+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa0d"
    },
    "model_benchmark_id": 65,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.222830+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.601,
    "score": 0.601,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.222830+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa0f"
    },
    "model_benchmark_id": 165,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.421645+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.405,
    "score": 0.405,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.421645+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa11"
    },
    "model_benchmark_id": 1310,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-07-19T19:56:13.743201+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.081,
    "score": 0.081,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.743201+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa13"
    },
    "model_benchmark_id": 1046,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.184897+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.155,
    "score": 0.155,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.184897+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa15"
    },
    "model_benchmark_id": 1028,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.142086+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.142086+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa17"
    },
    "model_benchmark_id": 1037,
    "analysis_method": "0-shot Accuracy",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.164056+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.488,
    "score": 0.488,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.164056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa19"
    },
    "model_benchmark_id": 246,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.571204+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:11.571204+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa1b"
    },
    "model_benchmark_id": 1059,
    "analysis_method": "5-shot Accuracy",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.210650+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.668,
    "score": 0.668,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.210650+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa1d"
    },
    "model_benchmark_id": 1229,
    "analysis_method": "ChrF, 0-shot Character-level F-score",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.582347+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it-litert-preview",
    "normalized_score": 0.427,
    "score": 0.427,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it-litert-preview",
    "updated_at": "2025-07-19T19:56:13.582347+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa1f"
    },
    "model_benchmark_id": 1148,
    "analysis_method": "- evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.415349+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.574,
    "score": 0.574,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.415349+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa21"
    },
    "model_benchmark_id": 1403,
    "analysis_method": "Automatic speech translation (BLEU score) across 21 languages",
    "benchmark_id": "covost2",
    "benchmark_name": "CoVoST2",
    "created_at": "2025-07-19T19:56:13.960537+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.384,
    "score": 0.384,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.960537+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa23"
    },
    "model_benchmark_id": 921,
    "analysis_method": "Video analysis across multiple domains",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.924659+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:12.924659+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa25"
    },
    "model_benchmark_id": 1088,
    "analysis_method": "- evaluation",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.264333+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.836,
    "score": 0.836,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.264333+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa27"
    },
    "model_benchmark_id": 1209,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.543616+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.782,
    "score": 0.782,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.543616+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa29"
    },
    "model_benchmark_id": 266,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.611234+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.515,
    "score": 0.515,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:11.611234+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa2b"
    },
    "model_benchmark_id": 1156,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.433332+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.553,
    "score": 0.553,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.433332+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa2d"
    },
    "model_benchmark_id": 1320,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.771288+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.289,
    "score": 0.289,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.771288+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa2f"
    },
    "model_benchmark_id": 379,
    "analysis_method": "standard",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.819524+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:11.819524+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa31"
    },
    "model_benchmark_id": 166,
    "analysis_method": "Chain-of-Thought accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.423223+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://developers.googleblog.com/en/gemini-2-family-expands/",
    "updated_at": "2025-07-19T19:56:11.423223+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa33"
    },
    "model_benchmark_id": 554,
    "analysis_method": "Multi-discipline college-level multimodal understanding and reasoning problems",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.141505+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:12.141505+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa35"
    },
    "model_benchmark_id": 1402,
    "analysis_method": "Long-context comprehension accuracy",
    "benchmark_id": "mrcr-1m",
    "benchmark_name": "MRCR 1M",
    "created_at": "2025-07-19T19:56:13.956748+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.58,
    "score": 0.58,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:13.956748+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa37"
    },
    "model_benchmark_id": 226,
    "analysis_method": "Factuality",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.535234+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-lite",
    "normalized_score": 0.217,
    "score": 0.217,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models",
    "updated_at": "2025-07-19T19:56:11.535234+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa39"
    },
    "model_benchmark_id": 659,
    "analysis_method": "Code editing",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.366506+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.267,
    "score": 0.267,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:12.366506+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa3b"
    },
    "model_benchmark_id": 681,
    "analysis_method": "Mathematics",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.422347+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.498,
    "score": 0.498,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:12.422347+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa3d"
    },
    "model_benchmark_id": 1406,
    "analysis_method": "Default",
    "benchmark_id": "arc",
    "benchmark_name": "Arc",
    "created_at": "2025-07-19T19:56:13.969921+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.025,
    "score": 0.025,
    "self_reported_source_link": "https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash-lite",
    "updated_at": "2025-07-19T19:56:13.969921+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa3f"
    },
    "model_benchmark_id": 1089,
    "analysis_method": "Factuality",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.267251+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.267251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa41"
    },
    "model_benchmark_id": 1210,
    "analysis_method": "Multilingual performance",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.546251+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.546251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa43"
    },
    "model_benchmark_id": 267,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.612808+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.646,
    "score": 0.646,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:11.612808+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa45"
    },
    "model_benchmark_id": 718,
    "analysis_method": "No tools",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.514286+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.051,
    "score": 0.051,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:12.514286+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa47"
    },
    "model_benchmark_id": 1104,
    "analysis_method": "Code generation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.300809+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.337,
    "score": 0.337,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.300809+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa49"
    },
    "model_benchmark_id": 555,
    "analysis_method": "Visual reasoning",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.143254+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.729,
    "score": 0.729,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:12.143254+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa4b"
    },
    "model_benchmark_id": 1405,
    "analysis_method": "Long context 128k average. 8 needle.",
    "benchmark_id": "mrcr-v2",
    "benchmark_name": "MRCR v2",
    "created_at": "2025-07-19T19:56:13.966057+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.166,
    "score": 0.166,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.966057+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa4d"
    },
    "model_benchmark_id": 227,
    "analysis_method": "Factuality",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.536893+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.107,
    "score": 0.107,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:11.536893+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa4f"
    },
    "model_benchmark_id": 1339,
    "analysis_method": "Agentic coding single attempt",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.819222+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.316,
    "score": 0.316,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.819222+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa51"
    },
    "model_benchmark_id": 1365,
    "analysis_method": "Reka",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.875989+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash-lite",
    "normalized_score": 0.513,
    "score": 0.513,
    "self_reported_source_link": "https://deepmind.google/models/gemini/flash-lite/",
    "updated_at": "2025-07-19T19:56:13.875989+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa53"
    },
    "model_benchmark_id": 1407,
    "analysis_method": "3-5-shot evaluation",
    "benchmark_id": "agieval",
    "benchmark_name": "AGIEval",
    "created_at": "2025-07-19T19:56:13.973652+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.528,
    "score": 0.528,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.973652+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa55"
    },
    "model_benchmark_id": 8,
    "analysis_method": "25-shot evaluation",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.097779+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.097779+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa57"
    },
    "model_benchmark_id": 1054,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.201834+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.201834+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa59"
    },
    "model_benchmark_id": 1391,
    "analysis_method": "3-shot Chain-of-Thought",
    "benchmark_id": "big-bench",
    "benchmark_name": "BIG-Bench",
    "created_at": "2025-07-19T19:56:13.930966+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.682,
    "score": 0.682,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.930966+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa5b"
    },
    "model_benchmark_id": 1020,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.124981+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.842,
    "score": 0.842,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.124981+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa5d"
    },
    "model_benchmark_id": 978,
    "analysis_method": "5-shot majority@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.053844+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.686,
    "score": 0.686,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.053844+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa5f"
    },
    "model_benchmark_id": 36,
    "analysis_method": "10-shot evaluation",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.157090+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.819,
    "score": 0.819,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.157090+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa61"
    },
    "model_benchmark_id": 765,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.611318+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.402,
    "score": 0.402,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:12.611318+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa63"
    },
    "model_benchmark_id": 380,
    "analysis_method": "4-shot evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.821125+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.366,
    "score": 0.366,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.821125+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa65"
    },
    "model_benchmark_id": 1169,
    "analysis_method": "3-shot evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.462564+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.524,
    "score": 0.524,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.462564+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa67"
    },
    "model_benchmark_id": 66,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.224994+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.713,
    "score": 0.713,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.224994+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa69"
    },
    "model_benchmark_id": 1047,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.186631+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.292,
    "score": 0.292,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.186631+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa6b"
    },
    "model_benchmark_id": 1029,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.144012+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.817,
    "score": 0.817,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.144012+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa6d"
    },
    "model_benchmark_id": 1038,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.166311+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.534,
    "score": 0.534,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.166311+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa6f"
    },
    "model_benchmark_id": 247,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.572657+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.572657+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa71"
    },
    "model_benchmark_id": 148,
    "analysis_method": "partial score evaluation",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.380497+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-9b-it",
    "normalized_score": 0.806,
    "score": 0.806,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.380497+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa73"
    },
    "model_benchmark_id": 1416,
    "analysis_method": "4-shot",
    "benchmark_id": "amc-2022-23",
    "benchmark_name": "AMC_2022_23",
    "created_at": "2025-07-19T19:56:13.995700+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.464,
    "score": 0.464,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.995700+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa75"
    },
    "model_benchmark_id": 1070,
    "analysis_method": "3-shot",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.231702+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.892,
    "score": 0.892,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.231702+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa77"
    },
    "model_benchmark_id": 945,
    "analysis_method": "Variable shots",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.994980+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:12.994980+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa79"
    },
    "model_benchmark_id": 1398,
    "analysis_method": "Word Error Rate",
    "benchmark_id": "fleurs",
    "benchmark_name": "FLEURS",
    "created_at": "2025-07-19T19:56:13.947638+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.067,
    "score": 0.067,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.947638+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa7b"
    },
    "model_benchmark_id": 1414,
    "analysis_method": "0-shot",
    "benchmark_id": "functionalmath",
    "benchmark_name": "FunctionalMATH",
    "created_at": "2025-07-19T19:56:13.990248+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.646,
    "score": 0.646,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.990248+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa7d"
    },
    "model_benchmark_id": 268,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.614440+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.591,
    "score": 0.591,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:11.614440+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa7f"
    },
    "model_benchmark_id": 979,
    "analysis_method": "11-shot",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.055992+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.055992+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa81"
    },
    "model_benchmark_id": 37,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.158919+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:11.158919+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa83"
    },
    "model_benchmark_id": 1157,
    "analysis_method": "Accuracy",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.434888+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.52,
    "score": 0.52,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.434888+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa85"
    },
    "model_benchmark_id": 766,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.613548+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:12.613548+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa87"
    },
    "model_benchmark_id": 381,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.822515+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:11.822515+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa89"
    },
    "model_benchmark_id": 517,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.075702+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.681,
    "score": 0.681,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.075702+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa8b"
    },
    "model_benchmark_id": 1275,
    "analysis_method": "8-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.674684+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.674684+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa8d"
    },
    "model_benchmark_id": 67,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.226593+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.859,
    "score": 0.859,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:11.226593+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa8f"
    },
    "model_benchmark_id": 167,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.425109+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:11.425109+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa91"
    },
    "model_benchmark_id": 556,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.145100+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.659,
    "score": 0.659,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:12.145100+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa93"
    },
    "model_benchmark_id": 1373,
    "analysis_method": "Accuracy",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.891629+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.891629+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa95"
    },
    "model_benchmark_id": 1198,
    "analysis_method": "Accuracy",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.523328+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.854,
    "score": 0.854,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.523328+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa97"
    },
    "model_benchmark_id": 1412,
    "analysis_method": "0-shot",
    "benchmark_id": "physicsfinals",
    "benchmark_name": "PhysicsFinals",
    "created_at": "2025-07-19T19:56:13.984883+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.639,
    "score": 0.639,
    "self_reported_source_link": "https://arxiv.org/pdf/2403.05530",
    "updated_at": "2025-07-19T19:56:13.984883+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa99"
    },
    "model_benchmark_id": 1366,
    "analysis_method": "Accuracy",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.877591+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.539,
    "score": 0.539,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.877591+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa9b"
    },
    "model_benchmark_id": 1380,
    "analysis_method": "Accuracy",
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "created_at": "2025-07-19T19:56:13.906552+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.906552+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa9d"
    },
    "model_benchmark_id": 1394,
    "analysis_method": "Score",
    "benchmark_id": "wmt23",
    "benchmark_name": "WMT23",
    "created_at": "2025-07-19T19:56:13.939104+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:13.939104+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaa9f"
    },
    "model_benchmark_id": 1418,
    "analysis_method": "Safety Compliance",
    "benchmark_id": "xstest",
    "benchmark_name": "XSTest",
    "created_at": "2025-07-19T19:56:14.002222+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-pro",
    "normalized_score": 0.988,
    "score": 0.988,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/pro/",
    "updated_at": "2025-07-19T19:56:14.002222+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaa1"
    },
    "model_benchmark_id": 1408,
    "analysis_method": "3-5-shot",
    "benchmark_id": "agieval",
    "benchmark_name": "AGIEval",
    "created_at": "2025-07-19T19:56:13.975397+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.551,
    "score": 0.551,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.975397+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaa3"
    },
    "model_benchmark_id": 9,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.099650+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.714,
    "score": 0.714,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.099650+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaa5"
    },
    "model_benchmark_id": 1055,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.203403+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.203403+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaa7"
    },
    "model_benchmark_id": 1392,
    "analysis_method": "3-shot, CoT",
    "benchmark_id": "big-bench",
    "benchmark_name": "BIG-Bench",
    "created_at": "2025-07-19T19:56:13.932992+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.932992+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaa9"
    },
    "model_benchmark_id": 1021,
    "analysis_method": "0-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.126514+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.126514+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaab"
    },
    "model_benchmark_id": 980,
    "analysis_method": "5-shot, maj@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.058102+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.74,
    "score": 0.74,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.058102+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaad"
    },
    "model_benchmark_id": 38,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.164247+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.164247+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaaf"
    },
    "model_benchmark_id": 767,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.615384+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.518,
    "score": 0.518,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:12.615384+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaab1"
    },
    "model_benchmark_id": 382,
    "analysis_method": "4-shot",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.824501+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.423,
    "score": 0.423,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.824501+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaab3"
    },
    "model_benchmark_id": 1170,
    "analysis_method": "3-shot",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.464425+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.626,
    "score": 0.626,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.464425+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaab5"
    },
    "model_benchmark_id": 68,
    "analysis_method": "5-shot, top-1",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.228104+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.752,
    "score": 0.752,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.228104+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaab7"
    },
    "model_benchmark_id": 1048,
    "analysis_method": "5-shot",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.188220+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.345,
    "score": 0.345,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.188220+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaab9"
    },
    "model_benchmark_id": 1030,
    "analysis_method": "0-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.145819+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.832,
    "score": 0.832,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.145819+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaabb"
    },
    "model_benchmark_id": 1039,
    "analysis_method": "0-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.168648+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.537,
    "score": 0.537,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.168648+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaabd"
    },
    "model_benchmark_id": 248,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.574247+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.837,
    "score": 0.837,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:11.574247+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaabf"
    },
    "model_benchmark_id": 1060,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.212219+00:00",
    "is_self_reported": true,
    "model_id": "gemma-2-27b-it",
    "normalized_score": 0.837,
    "score": 0.837,
    "self_reported_source_link": "https://huggingface.co/blog/gemma2",
    "updated_at": "2025-07-19T19:56:13.212219+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaac1"
    },
    "model_benchmark_id": 660,
    "analysis_method": "Diff-fenced",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.368655+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.822,
    "score": 0.822,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:12.368655+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaac3"
    },
    "model_benchmark_id": 682,
    "analysis_method": "Single attempt",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.425843+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:12.425843+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaac5"
    },
    "model_benchmark_id": 1090,
    "analysis_method": "Factuality",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.269434+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:13.269434+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaac7"
    },
    "model_benchmark_id": 1211,
    "analysis_method": "Multilingual performance",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.548453+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.892,
    "score": 0.892,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:13.548453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaac9"
    },
    "model_benchmark_id": 269,
    "analysis_method": "Single attempt Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.617404+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:11.617404+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaacb"
    },
    "model_benchmark_id": 719,
    "analysis_method": "No tools",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.516239+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.216,
    "score": 0.216,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:12.516239+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaacd"
    },
    "model_benchmark_id": 1105,
    "analysis_method": "Single attempt (1/1/2025-5/1/2025)",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.303010+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.69,
    "score": 0.69,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:13.303010+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaacf"
    },
    "model_benchmark_id": 557,
    "analysis_method": "Single attempt",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.146880+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.82,
    "score": 0.82,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:12.146880+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaad1"
    },
    "model_benchmark_id": 1422,
    "analysis_method": "1M pointwise",
    "benchmark_id": "mrcr-v2-(8-needle)",
    "benchmark_name": "MRCR v2 (8-needle)",
    "created_at": "2025-07-19T19:56:14.013534+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.164,
    "score": 0.164,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:14.016258+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaad3"
    },
    "model_benchmark_id": 228,
    "analysis_method": "Factuality",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.538432+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.54,
    "score": 0.54,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:11.538432+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaad5"
    },
    "model_benchmark_id": 1340,
    "analysis_method": "Multiple attempts",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.820885+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:13.820885+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaad7"
    },
    "model_benchmark_id": 1367,
    "analysis_method": "Image understanding",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.879257+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:13.879257+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaad9"
    },
    "model_benchmark_id": 1421,
    "analysis_method": "Video understanding",
    "benchmark_id": "videommmu",
    "benchmark_name": "VideoMMMU",
    "created_at": "2025-07-19T19:56:14.009959+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "normalized_score": 0.836,
    "score": 0.836,
    "self_reported_source_link": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "updated_at": "2025-07-19T19:56:14.009959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaadb"
    },
    "model_benchmark_id": 661,
    "analysis_method": "whole",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.370513+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.619,
    "score": 0.619,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:12.370513+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaadd"
    },
    "model_benchmark_id": 1329,
    "analysis_method": "Diff-Fenced",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.795058+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.567,
    "score": 0.567,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025",
    "updated_at": "2025-07-19T19:56:13.795058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaadf"
    },
    "model_benchmark_id": 447,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.950448+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:11.950448+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaae1"
    },
    "model_benchmark_id": 683,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.428509+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:12.428509+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaae3"
    },
    "model_benchmark_id": 1091,
    "analysis_method": "Accuracy",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.271323+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.853,
    "score": 0.853,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:13.271323+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaae5"
    },
    "model_benchmark_id": 1212,
    "analysis_method": "Accuracy",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.550549+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:13.550549+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaae7"
    },
    "model_benchmark_id": 270,
    "analysis_method": "Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.619078+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.828,
    "score": 0.828,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:11.619078+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaae9"
    },
    "model_benchmark_id": 720,
    "analysis_method": "Accuracy",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.518055+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.11,
    "score": 0.11,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:12.518055+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaeb"
    },
    "model_benchmark_id": 1321,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.773194+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.639,
    "score": 0.639,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:13.773194+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaed"
    },
    "model_benchmark_id": 558,
    "analysis_method": "Pass@1",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.148985+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:12.148985+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaef"
    },
    "model_benchmark_id": 1374,
    "analysis_method": "1M-pointwise",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.893404+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.32,
    "score": 0.32,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025",
    "updated_at": "2025-07-19T19:56:13.895016+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaf1"
    },
    "model_benchmark_id": 229,
    "analysis_method": "Accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.540281+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.269,
    "score": 0.269,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:11.540281+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaf3"
    },
    "model_benchmark_id": 1341,
    "analysis_method": "Accuracy",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.822771+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:13.822771+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaf5"
    },
    "model_benchmark_id": 1368,
    "analysis_method": "Accuracy",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.880772+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.5-flash",
    "normalized_score": 0.654,
    "score": 0.654,
    "self_reported_source_link": "https://developers.googleblog.com/en/start-building-with-gemini-25-flash/",
    "updated_at": "2025-07-19T19:56:13.880772+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaf7"
    },
    "model_benchmark_id": 448,
    "analysis_method": "Enhanced reasoning on competition-level math prompts",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.952263+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-thinking",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models/gemini#evaluation",
    "updated_at": "2025-07-19T19:56:11.952263+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaf9"
    },
    "model_benchmark_id": 271,
    "analysis_method": "Challenging science questions requiring chain-of-thought reasoning",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.620752+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-thinking",
    "normalized_score": 0.742,
    "score": 0.742,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models/gemini#evaluation",
    "updated_at": "2025-07-19T19:56:11.620752+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaafb"
    },
    "model_benchmark_id": 559,
    "analysis_method": "Image-text QA across various domains",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.151038+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash-thinking",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://ai.google.dev/gemini-api/docs/models/gemini#evaluation",
    "updated_at": "2025-07-19T19:56:12.151038+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaafd"
    },
    "model_benchmark_id": 10,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.102376+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.517,
    "score": 0.517,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:11.102376+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaaff"
    },
    "model_benchmark_id": 1056,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-e",
    "benchmark_name": "ARC-E",
    "created_at": "2025-07-19T19:56:13.204955+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.204955+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab01"
    },
    "model_benchmark_id": 1071,
    "analysis_method": "few-shot",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.233872+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.443,
    "score": 0.443,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.233872+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab03"
    },
    "model_benchmark_id": 1022,
    "analysis_method": "0-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.127882+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.127882+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab05"
    },
    "model_benchmark_id": 946,
    "analysis_method": "Token F1 score. 1-shot.",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.996776+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.539,
    "score": 0.539,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:12.996776+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab07"
    },
    "model_benchmark_id": 39,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.166470+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:11.166470+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab09"
    },
    "model_benchmark_id": 1049,
    "analysis_method": "5-shot",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.190039+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.155,
    "score": 0.155,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.190039+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab0b"
    },
    "model_benchmark_id": 1031,
    "analysis_method": "0-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.147878+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.147878+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab0d"
    },
    "model_benchmark_id": 1040,
    "analysis_method": "0-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.170669+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.488,
    "score": 0.488,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.170669+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab0f"
    },
    "model_benchmark_id": 249,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.576196+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:11.576196+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab11"
    },
    "model_benchmark_id": 1061,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.213740+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b",
    "normalized_score": 0.668,
    "score": 0.668,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B",
    "updated_at": "2025-07-19T19:56:13.213740+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab13"
    },
    "model_benchmark_id": 1425,
    "analysis_method": "Average F1 for top 5 conditions",
    "benchmark_id": "chexpert-cxr",
    "benchmark_name": "CheXpert CXR",
    "created_at": "2025-07-19T19:56:14.023334+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.481,
    "score": 0.481,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.023334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab15"
    },
    "model_benchmark_id": 1426,
    "analysis_method": "Accuracy",
    "benchmark_id": "dermmcqa",
    "benchmark_name": "DermMCQA",
    "created_at": "2025-07-19T19:56:14.026812+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.718,
    "score": 0.718,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.026812+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab17"
    },
    "model_benchmark_id": 1430,
    "analysis_method": "Accuracy",
    "benchmark_id": "medxpertqa",
    "benchmark_name": "MedXpertQA",
    "created_at": "2025-07-19T19:56:14.042823+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.188,
    "score": 0.188,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.042823+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab19"
    },
    "model_benchmark_id": 1424,
    "analysis_method": "Average F1 for top 5 conditions",
    "benchmark_id": "mimic-cxr",
    "benchmark_name": "MIMIC CXR",
    "created_at": "2025-07-19T19:56:14.019964+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.889,
    "score": 0.889,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.019964+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab1b"
    },
    "model_benchmark_id": 1429,
    "analysis_method": "Accuracy",
    "benchmark_id": "pathmcqa",
    "benchmark_name": "PathMCQA",
    "created_at": "2025-07-19T19:56:14.039089+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.698,
    "score": 0.698,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.039089+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab1d"
    },
    "model_benchmark_id": 1427,
    "analysis_method": "Tokenized F1",
    "benchmark_id": "slakevqa",
    "benchmark_name": "SlakeVQA",
    "created_at": "2025-07-19T19:56:14.029835+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.623,
    "score": 0.623,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.029835+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab1f"
    },
    "model_benchmark_id": 1428,
    "analysis_method": "Tokenized F1",
    "benchmark_id": "vqa-rad",
    "benchmark_name": "VQA-Rad",
    "created_at": "2025-07-19T19:56:14.035504+00:00",
    "is_self_reported": true,
    "model_id": "medgemma-4b-it",
    "normalized_score": 0.499,
    "score": 0.499,
    "self_reported_source_link": "https://huggingface.co/google/medgemma-4b-it",
    "updated_at": "2025-07-19T19:56:14.035504+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab21"
    },
    "model_benchmark_id": 1417,
    "analysis_method": "Accuracy (4-shot)",
    "benchmark_id": "amc-2022-23",
    "benchmark_name": "AMC_2022_23",
    "created_at": "2025-07-19T19:56:13.997413+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.348,
    "score": 0.348,
    "self_reported_source_link": "https://www.maa.org/math-competitions/amc-1012",
    "updated_at": "2025-07-19T19:56:13.997413+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab23"
    },
    "model_benchmark_id": 1072,
    "analysis_method": "Accuracy (3-shot)",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.235605+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.855,
    "score": 0.855,
    "self_reported_source_link": "https://arxiv.org/abs/2206.04615",
    "updated_at": "2025-07-19T19:56:13.235605+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab25"
    },
    "model_benchmark_id": 1399,
    "analysis_method": "Word Error Rate",
    "benchmark_id": "fleurs",
    "benchmark_name": "FLEURS",
    "created_at": "2025-07-19T19:56:13.949679+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.096,
    "score": 0.096,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.949679+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab27"
    },
    "model_benchmark_id": 1415,
    "analysis_method": "Accuracy (0-shot)",
    "benchmark_id": "functionalmath",
    "benchmark_name": "FunctionalMATH",
    "created_at": "2025-07-19T19:56:13.991969+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://arxiv.org/abs/2201.04723",
    "updated_at": "2025-07-19T19:56:13.991969+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab29"
    },
    "model_benchmark_id": 272,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.622361+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.51,
    "score": 0.51,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.622361+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab2b"
    },
    "model_benchmark_id": 981,
    "analysis_method": "Accuracy (11-shot)",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.060014+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.862,
    "score": 0.862,
    "self_reported_source_link": "https://arxiv.org/abs/2110.14168",
    "updated_at": "2025-07-19T19:56:13.060014+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab2d"
    },
    "model_benchmark_id": 40,
    "analysis_method": "Accuracy (10-shot)",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.168455+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://arxiv.org/abs/1905.07830",
    "updated_at": "2025-07-19T19:56:11.168455+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab2f"
    },
    "model_benchmark_id": 1158,
    "analysis_method": "Accuracy",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.436585+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.472,
    "score": 0.472,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.436585+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab31"
    },
    "model_benchmark_id": 768,
    "analysis_method": "Pass Rate",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.617215+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:12.617215+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab33"
    },
    "model_benchmark_id": 383,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.826586+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.779,
    "score": 0.779,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.826586+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab35"
    },
    "model_benchmark_id": 518,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.077492+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:12.077492+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab37"
    },
    "model_benchmark_id": 1276,
    "analysis_method": "Accuracy (8-shot)",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.676395+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://arxiv.org/abs/2305.08916",
    "updated_at": "2025-07-19T19:56:13.676395+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab39"
    },
    "model_benchmark_id": 69,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.229674+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://arxiv.org/abs/2403.05530",
    "updated_at": "2025-07-19T19:56:11.229674+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab3b"
    },
    "model_benchmark_id": 168,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.426986+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.673,
    "score": 0.673,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.426986+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab3d"
    },
    "model_benchmark_id": 560,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.153019+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.623,
    "score": 0.623,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:12.153019+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab3f"
    },
    "model_benchmark_id": 1376,
    "analysis_method": "Accuracy",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.896456+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.719,
    "score": 0.719,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.896456+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab41"
    },
    "model_benchmark_id": 1199,
    "analysis_method": "Accuracy",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.525034+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.798,
    "score": 0.798,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.525034+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab43"
    },
    "model_benchmark_id": 1413,
    "analysis_method": "Accuracy (0-shot)",
    "benchmark_id": "physicsfinals",
    "benchmark_name": "PhysicsFinals",
    "created_at": "2025-07-19T19:56:13.986673+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.574,
    "score": 0.574,
    "self_reported_source_link": "https://arxiv.org/abs/2303.16416",
    "updated_at": "2025-07-19T19:56:13.986673+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab45"
    },
    "model_benchmark_id": 1369,
    "analysis_method": "Accuracy",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.882991+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.489,
    "score": 0.489,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.882991+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab47"
    },
    "model_benchmark_id": 1381,
    "analysis_method": "Accuracy",
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "created_at": "2025-07-19T19:56:13.908485+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.761,
    "score": 0.761,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.908485+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab49"
    },
    "model_benchmark_id": 1395,
    "analysis_method": "Score",
    "benchmark_id": "wmt23",
    "benchmark_name": "WMT23",
    "created_at": "2025-07-19T19:56:13.940965+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.741,
    "score": 0.741,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.940965+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab4b"
    },
    "model_benchmark_id": 1419,
    "analysis_method": "Accuracy",
    "benchmark_id": "xstest",
    "benchmark_name": "XSTest",
    "created_at": "2025-07-19T19:56:14.004109+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash",
    "normalized_score": 0.97,
    "score": 0.97,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:14.004109+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab4d"
    },
    "model_benchmark_id": 684,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.431148+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.116,
    "score": 0.116,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:12.431148+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab4f"
    },
    "model_benchmark_id": 1326,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "codegolf-v2.2",
    "benchmark_name": "Codegolf v2.2",
    "created_at": "2025-07-19T19:56:13.785856+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.168,
    "score": 0.168,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.785856+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab51"
    },
    "model_benchmark_id": 1222,
    "analysis_method": "0-shot",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.569227+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.19,
    "score": 0.19,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.569227+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab53"
    },
    "model_benchmark_id": 1315,
    "analysis_method": "0-shot",
    "benchmark_id": "global-mmlu",
    "benchmark_name": "Global-MMLU",
    "created_at": "2025-07-19T19:56:13.756363+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.603,
    "score": 0.603,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.756363+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab55"
    },
    "model_benchmark_id": 1213,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.552233+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.645,
    "score": 0.645,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.552233+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab57"
    },
    "model_benchmark_id": 273,
    "analysis_method": "Diamond. 0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.624084+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.237,
    "score": 0.237,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:11.624084+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab59"
    },
    "model_benchmark_id": 1159,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.438271+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.377,
    "score": 0.377,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.438271+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab5b"
    },
    "model_benchmark_id": 769,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.618954+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:12.618954+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab5d"
    },
    "model_benchmark_id": 1306,
    "analysis_method": "0-shot",
    "benchmark_id": "include",
    "benchmark_name": "Include",
    "created_at": "2025-07-19T19:56:13.733461+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.733461+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab5f"
    },
    "model_benchmark_id": 1106,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.304919+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.132,
    "score": 0.132,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.304919+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab61"
    },
    "model_benchmark_id": 1322,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.775429+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.257,
    "score": 0.257,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.775429+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab63"
    },
    "model_benchmark_id": 1171,
    "analysis_method": "pass@1. 3-shot.",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.466832+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.636,
    "score": 0.636,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.466832+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab65"
    },
    "model_benchmark_id": 1277,
    "analysis_method": "0-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.678210+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.678210+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab67"
    },
    "model_benchmark_id": 70,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.232243+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:11.232243+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab69"
    },
    "model_benchmark_id": 169,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.428457+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.506,
    "score": 0.506,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:11.428457+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab6b"
    },
    "model_benchmark_id": 1311,
    "analysis_method": "0-shot",
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-07-19T19:56:13.744918+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.199,
    "score": 0.199,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.744918+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab6d"
    },
    "model_benchmark_id": 1431,
    "analysis_method": "0-shot",
    "benchmark_id": "openai-mmlu",
    "benchmark_name": "OpenAI MMLU",
    "created_at": "2025-07-19T19:56:14.045887+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.356,
    "score": 0.356,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:14.045887+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab6f"
    },
    "model_benchmark_id": 1230,
    "analysis_method": "Character-level F-score. 0-shot.",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.584588+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e4b-it",
    "normalized_score": 0.501,
    "score": 0.501,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E4B-it",
    "updated_at": "2025-07-19T19:56:13.584588+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab71"
    },
    "model_benchmark_id": 1248,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.622871+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.748,
    "score": 0.748,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.622871+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab73"
    },
    "model_benchmark_id": 1097,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-extra-hard",
    "benchmark_name": "BIG-Bench Extra Hard",
    "created_at": "2025-07-19T19:56:13.285056+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.11,
    "score": 0.11,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.285056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab75"
    },
    "model_benchmark_id": 1073,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.237255+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.237255+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab77"
    },
    "model_benchmark_id": 1149,
    "analysis_method": "- evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.417046+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.363,
    "score": 0.363,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.417046+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab79"
    },
    "model_benchmark_id": 856,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.791952+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.688,
    "score": 0.688,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.791952+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab7b"
    },
    "model_benchmark_id": 879,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.832468+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.832468+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab7d"
    },
    "model_benchmark_id": 1223,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.570776+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.046,
    "score": 0.046,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.570776+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab7f"
    },
    "model_benchmark_id": 1092,
    "analysis_method": "- evaluation",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.273464+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.701,
    "score": 0.701,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.273464+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab81"
    },
    "model_benchmark_id": 1214,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.553690+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.545,
    "score": 0.545,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.553690+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab83"
    },
    "model_benchmark_id": 274,
    "analysis_method": "0-shot evaluation diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.625675+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.308,
    "score": 0.308,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.625675+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab85"
    },
    "model_benchmark_id": 982,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.061601+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.892,
    "score": 0.892,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.061601+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab87"
    },
    "model_benchmark_id": 1160,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.440350+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.43,
    "score": 0.43,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.440350+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab89"
    },
    "model_benchmark_id": 770,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.620468+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.713,
    "score": 0.713,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.620468+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab8b"
    },
    "model_benchmark_id": 608,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.256346+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.256346+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab8d"
    },
    "model_benchmark_id": 1239,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.605648+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.605648+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab8f"
    },
    "model_benchmark_id": 1107,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.306674+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.126,
    "score": 0.126,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.306674+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab91"
    },
    "model_benchmark_id": 384,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.828322+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.756,
    "score": 0.756,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.828322+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab93"
    },
    "model_benchmark_id": 1267,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.659077+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.659077+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab95"
    },
    "model_benchmark_id": 1172,
    "analysis_method": "3-shot evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.469983+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.632,
    "score": 0.632,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.469983+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab97"
    },
    "model_benchmark_id": 170,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.430343+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.436,
    "score": 0.436,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.430343+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab99"
    },
    "model_benchmark_id": 1236,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mmmu-(val)",
    "benchmark_name": "MMMU (val)",
    "created_at": "2025-07-19T19:56:13.597769+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.488,
    "score": 0.488,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.597769+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab9b"
    },
    "model_benchmark_id": 1200,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.526663+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.526663+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab9d"
    },
    "model_benchmark_id": 230,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.542000+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.04,
    "score": 0.04,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.542000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daab9f"
    },
    "model_benchmark_id": 904,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.885190+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.578,
    "score": 0.578,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.885190+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaba1"
    },
    "model_benchmark_id": 1264,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "vqav2-(val)",
    "benchmark_name": "VQAv2 (val)",
    "created_at": "2025-07-19T19:56:13.652122+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.624,
    "score": 0.624,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.652122+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaba3"
    },
    "model_benchmark_id": 1231,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.586157+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-4b-it",
    "normalized_score": 0.468,
    "score": 0.468,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.586157+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaba5"
    },
    "model_benchmark_id": 1249,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.624921+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.624921+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaba7"
    },
    "model_benchmark_id": 1098,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-extra-hard",
    "benchmark_name": "BIG-Bench Extra Hard",
    "created_at": "2025-07-19T19:56:13.286991+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.193,
    "score": 0.193,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.286991+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaba9"
    },
    "model_benchmark_id": 1074,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.238868+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.876,
    "score": 0.876,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.238868+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabab"
    },
    "model_benchmark_id": 1150,
    "analysis_method": "- evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.418526+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.544,
    "score": 0.544,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.418526+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabad"
    },
    "model_benchmark_id": 857,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.793657+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.793657+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabaf"
    },
    "model_benchmark_id": 880,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.834284+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.866,
    "score": 0.866,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.834284+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabb1"
    },
    "model_benchmark_id": 1224,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.572334+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.167,
    "score": 0.167,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.572334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabb3"
    },
    "model_benchmark_id": 1093,
    "analysis_method": "- evaluation",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.275050+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.275050+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabb5"
    },
    "model_benchmark_id": 1215,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.555532+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.555532+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabb7"
    },
    "model_benchmark_id": 275,
    "analysis_method": "0-shot evaluation diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.628803+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.424,
    "score": 0.424,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.628803+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabb9"
    },
    "model_benchmark_id": 983,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.063038+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.959,
    "score": 0.959,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.063038+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabbb"
    },
    "model_benchmark_id": 1161,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.443231+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.603,
    "score": 0.603,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.443231+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabbd"
    },
    "model_benchmark_id": 771,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.621954+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.621954+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabbf"
    },
    "model_benchmark_id": 609,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.258406+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.904,
    "score": 0.904,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.258406+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabc1"
    },
    "model_benchmark_id": 1240,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.607541+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.706,
    "score": 0.706,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.607541+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabc3"
    },
    "model_benchmark_id": 1108,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.308517+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.297,
    "score": 0.297,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.308517+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabc5"
    },
    "model_benchmark_id": 385,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.830123+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.830123+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabc7"
    },
    "model_benchmark_id": 1268,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.660624+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.676,
    "score": 0.676,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.660624+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabc9"
    },
    "model_benchmark_id": 1173,
    "analysis_method": "3-shot evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.472259+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.744,
    "score": 0.744,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.472259+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabcb"
    },
    "model_benchmark_id": 171,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.432013+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.675,
    "score": 0.675,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.432013+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabcd"
    },
    "model_benchmark_id": 1237,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "mmmu-(val)",
    "benchmark_name": "MMMU (val)",
    "created_at": "2025-07-19T19:56:13.599826+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.599826+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabcf"
    },
    "model_benchmark_id": 1201,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.528235+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.528235+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabd1"
    },
    "model_benchmark_id": 231,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.543428+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.1,
    "score": 0.1,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.543428+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabd3"
    },
    "model_benchmark_id": 905,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.886992+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.651,
    "score": 0.651,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.886992+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabd5"
    },
    "model_benchmark_id": 1265,
    "analysis_method": "multimodal evaluation",
    "benchmark_id": "vqav2-(val)",
    "benchmark_name": "VQAv2 (val)",
    "created_at": "2025-07-19T19:56:13.653584+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.71,
    "score": 0.71,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.653584+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabd7"
    },
    "model_benchmark_id": 1232,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.587542+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-27b-it",
    "normalized_score": 0.534,
    "score": 0.534,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.587542+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabd9"
    },
    "model_benchmark_id": 1099,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-extra-hard",
    "benchmark_name": "BIG-Bench Extra Hard",
    "created_at": "2025-07-19T19:56:13.289054+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.072,
    "score": 0.072,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.289054+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabdb"
    },
    "model_benchmark_id": 1075,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.240587+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.391,
    "score": 0.391,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.240587+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabdd"
    },
    "model_benchmark_id": 1151,
    "analysis_method": "- evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.421336+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.064,
    "score": 0.064,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.421336+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabdf"
    },
    "model_benchmark_id": 1225,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.574307+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.014,
    "score": 0.014,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.574307+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabe1"
    },
    "model_benchmark_id": 1094,
    "analysis_method": "- evaluation",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.276605+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.364,
    "score": 0.364,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.276605+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabe3"
    },
    "model_benchmark_id": 1216,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.557306+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.342,
    "score": 0.342,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.557306+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabe5"
    },
    "model_benchmark_id": 276,
    "analysis_method": "0-shot evaluation diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.633668+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.192,
    "score": 0.192,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.633668+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabe7"
    },
    "model_benchmark_id": 984,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.064705+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.628,
    "score": 0.628,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.064705+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabe9"
    },
    "model_benchmark_id": 1162,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.445125+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.158,
    "score": 0.158,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.445125+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabeb"
    },
    "model_benchmark_id": 772,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.623656+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.415,
    "score": 0.415,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.623656+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabed"
    },
    "model_benchmark_id": 610,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.260062+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:12.260062+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabef"
    },
    "model_benchmark_id": 1109,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.311408+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.019,
    "score": 0.019,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.311408+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabf1"
    },
    "model_benchmark_id": 386,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.832121+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.48,
    "score": 0.48,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.832121+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabf3"
    },
    "model_benchmark_id": 1174,
    "analysis_method": "3-shot evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.474036+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.352,
    "score": 0.352,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.474036+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabf5"
    },
    "model_benchmark_id": 172,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.434242+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.147,
    "score": 0.147,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.434242+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabf7"
    },
    "model_benchmark_id": 1202,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.529701+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.56,
    "score": 0.56,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.529701+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabf9"
    },
    "model_benchmark_id": 232,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.544931+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.022,
    "score": 0.022,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:11.544931+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabfb"
    },
    "model_benchmark_id": 1233,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.590063+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3-1b-it",
    "normalized_score": 0.359,
    "score": 0.359,
    "self_reported_source_link": "https://ai.google.dev/gemma/docs/core/model_card_3",
    "updated_at": "2025-07-19T19:56:13.590063+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabfd"
    },
    "model_benchmark_id": 1400,
    "analysis_method": "Speech recognition accuracy (1 - WER)",
    "benchmark_id": "fleurs",
    "benchmark_name": "FLEURS",
    "created_at": "2025-07-19T19:56:13.951665+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.951665+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daabff"
    },
    "model_benchmark_id": 277,
    "analysis_method": "Accuracy on expert-written science questions",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.635441+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.384,
    "score": 0.384,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.635441+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac01"
    },
    "model_benchmark_id": 1163,
    "analysis_method": "Accuracy on competition-level math problems",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.447290+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.447290+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac03"
    },
    "model_benchmark_id": 387,
    "analysis_method": "Accuracy on mathematical problem-solving tasks",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.834192+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.587,
    "score": 0.587,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.834192+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac05"
    },
    "model_benchmark_id": 519,
    "analysis_method": "Visual mathematical reasoning accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.078820+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.547,
    "score": 0.547,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:12.078820+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac07"
    },
    "model_benchmark_id": 173,
    "analysis_method": "Multiple choice accuracy across enhanced MMLU dataset with higher difficulty tasks",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.436045+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.587,
    "score": 0.587,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:11.436045+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac09"
    },
    "model_benchmark_id": 561,
    "analysis_method": "Multimodal understanding accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.154594+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.537,
    "score": 0.537,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:12.154594+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac0b"
    },
    "model_benchmark_id": 1377,
    "analysis_method": "Long-context comprehension accuracy",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.898262+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.547,
    "score": 0.547,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.898262+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac0d"
    },
    "model_benchmark_id": 1203,
    "analysis_method": "Pass rate on code generation tasks across multiple programming languages",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.531432+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.755,
    "score": 0.755,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.531432+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac0f"
    },
    "model_benchmark_id": 1370,
    "analysis_method": "Visual understanding evaluation",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.885058+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.409,
    "score": 0.409,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.885058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac11"
    },
    "model_benchmark_id": 1382,
    "analysis_method": "Video analysis accuracy",
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "created_at": "2025-07-19T19:56:13.910273+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.662,
    "score": 0.662,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.910273+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac13"
    },
    "model_benchmark_id": 1396,
    "analysis_method": "Translation quality score",
    "benchmark_id": "wmt23",
    "benchmark_name": "WMT23",
    "created_at": "2025-07-19T19:56:13.942779+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.726,
    "score": 0.726,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:13.942779+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac15"
    },
    "model_benchmark_id": 1420,
    "analysis_method": "Safe request fulfillment rate",
    "benchmark_id": "xstest",
    "benchmark_name": "XSTest",
    "created_at": "2025-07-19T19:56:14.005888+00:00",
    "is_self_reported": true,
    "model_id": "gemini-1.5-flash-8b",
    "normalized_score": 0.926,
    "score": 0.926,
    "self_reported_source_link": "https://deepmind.google/technologies/gemini/flash/",
    "updated_at": "2025-07-19T19:56:14.005888+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac17"
    },
    "model_benchmark_id": 685,
    "analysis_method": "pass @1",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.434861+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.233,
    "score": 0.233,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:12.434861+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac19"
    },
    "model_benchmark_id": 1100,
    "analysis_method": "pass @1",
    "benchmark_id": "big-bench-extra-hard",
    "benchmark_name": "BIG-Bench Extra Hard",
    "created_at": "2025-07-19T19:56:13.291288+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.15,
    "score": 0.15,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:13.291288+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac1b"
    },
    "model_benchmark_id": 1433,
    "analysis_method": "pass @1",
    "benchmark_id": "bigcodebench",
    "benchmark_name": "BigCodeBench",
    "created_at": "2025-07-19T19:56:14.050987+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.454,
    "score": 0.454,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:14.050987+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac1d"
    },
    "model_benchmark_id": 1217,
    "analysis_method": "pass @1",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.559014+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.691,
    "score": 0.691,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:13.559014+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac1f"
    },
    "model_benchmark_id": 278,
    "analysis_method": "pass @1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.637311+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.404,
    "score": 0.404,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:11.637311+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac21"
    },
    "model_benchmark_id": 773,
    "analysis_method": "pass @1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.625233+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.896,
    "score": 0.896,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:12.625233+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac23"
    },
    "model_benchmark_id": 1435,
    "analysis_method": "pass @1",
    "benchmark_id": "lbpp-(v2)",
    "benchmark_name": "LBPP (v2)",
    "created_at": "2025-07-19T19:56:14.056060+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.568,
    "score": 0.568,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:14.056060+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac25"
    },
    "model_benchmark_id": 1110,
    "analysis_method": "pass @1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.314684+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.309,
    "score": 0.309,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:13.314684+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac27"
    },
    "model_benchmark_id": 1175,
    "analysis_method": "pass @1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.475906+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.76,
    "score": 0.76,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:13.475906+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac29"
    },
    "model_benchmark_id": 1342,
    "analysis_method": "pass @1, Non-agentic evaluation (single turn edit only), max prompt length of 32K",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.824708+00:00",
    "is_self_reported": true,
    "model_id": "gemini-diffusion",
    "normalized_score": 0.229,
    "score": 0.229,
    "self_reported_source_link": "https://deepmind.google/models/gemini-diffusion/",
    "updated_at": "2025-07-19T19:56:13.824708+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac2b"
    },
    "model_benchmark_id": 1152,
    "analysis_method": "Natural language to SQL conversion evaluation",
    "benchmark_id": "bird-sql-(dev)",
    "benchmark_name": "Bird-SQL (dev)",
    "created_at": "2025-07-19T19:56:13.423568+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.569,
    "score": 0.569,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.423568+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac2d"
    },
    "model_benchmark_id": 1404,
    "analysis_method": "Automatic speech translation (BLEU score) across 21 languages",
    "benchmark_id": "covost2",
    "benchmark_name": "CoVoST2",
    "created_at": "2025-07-19T19:56:13.962212+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.392,
    "score": 0.392,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.962212+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac2f"
    },
    "model_benchmark_id": 922,
    "analysis_method": "Video analysis across multiple domains",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.926117+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.715,
    "score": 0.715,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:12.926117+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac31"
    },
    "model_benchmark_id": 1095,
    "analysis_method": "Ability to provide factuality correct responses given documents and diverse user requests",
    "benchmark_id": "facts-grounding",
    "benchmark_name": "FACTS Grounding",
    "created_at": "2025-07-19T19:56:13.278460+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.836,
    "score": 0.836,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.278460+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac33"
    },
    "model_benchmark_id": 279,
    "analysis_method": "Challenging dataset of questions written by domain experts in biology, physics, and chemistry",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.639283+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.621,
    "score": 0.621,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:11.639283+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac35"
    },
    "model_benchmark_id": 1164,
    "analysis_method": "Competition-level math problems, Held out dataset AIME/AMC-like",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.449979+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.63,
    "score": 0.63,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.449979+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac37"
    },
    "model_benchmark_id": 1111,
    "analysis_method": "Code generation in Python. Code Generation subset covering more recent examples: 06/01/2024 - 10/05/2024",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.317443+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.351,
    "score": 0.351,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.317443+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac39"
    },
    "model_benchmark_id": 388,
    "analysis_method": "Challenging math problems including algebra, geometry, pre-calculus, and others",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.835842+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.897,
    "score": 0.897,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:11.835842+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac3b"
    },
    "model_benchmark_id": 174,
    "analysis_method": "Enhanced version of MMLU dataset evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.437540+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:11.437540+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac3d"
    },
    "model_benchmark_id": 562,
    "analysis_method": "Multi-discipline college-level multimodal understanding and reasoning problems",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.156776+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:12.156776+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac3f"
    },
    "model_benchmark_id": 1378,
    "analysis_method": "Novel, diagnostic long-context understanding evaluation",
    "benchmark_id": "mrcr",
    "benchmark_name": "MRCR",
    "created_at": "2025-07-19T19:56:13.900780+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.900780+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac41"
    },
    "model_benchmark_id": 1204,
    "analysis_method": "Code generation evaluation across multiple languages",
    "benchmark_id": "natural2code",
    "benchmark_name": "Natural2Code",
    "created_at": "2025-07-19T19:56:13.533525+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.929,
    "score": 0.929,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.533525+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac43"
    },
    "model_benchmark_id": 1371,
    "analysis_method": "Visual understanding in chat models with challenging everyday examples",
    "benchmark_id": "vibe-eval",
    "benchmark_name": "Vibe-Eval",
    "created_at": "2025-07-19T19:56:13.886575+00:00",
    "is_self_reported": true,
    "model_id": "gemini-2.0-flash",
    "normalized_score": 0.563,
    "score": 0.563,
    "self_reported_source_link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
    "updated_at": "2025-07-19T19:56:13.886575+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac45"
    },
    "model_benchmark_id": 686,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.437675+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.067,
    "score": 0.067,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:12.437675+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac47"
    },
    "model_benchmark_id": 1327,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "codegolf-v2.2",
    "benchmark_name": "Codegolf v2.2",
    "created_at": "2025-07-19T19:56:13.787794+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.11,
    "score": 0.11,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.787794+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac49"
    },
    "model_benchmark_id": 1226,
    "analysis_method": "0-shot",
    "benchmark_id": "eclektic",
    "benchmark_name": "ECLeKTic",
    "created_at": "2025-07-19T19:56:13.575847+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.025,
    "score": 0.025,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.575847+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac4b"
    },
    "model_benchmark_id": 1316,
    "analysis_method": "0-shot",
    "benchmark_id": "global-mmlu",
    "benchmark_name": "Global-MMLU",
    "created_at": "2025-07-19T19:56:13.758455+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.551,
    "score": 0.551,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.758455+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac4d"
    },
    "model_benchmark_id": 1218,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "global-mmlu-lite",
    "benchmark_name": "Global-MMLU-Lite",
    "created_at": "2025-07-19T19:56:13.560513+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.59,
    "score": 0.59,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.560513+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac4f"
    },
    "model_benchmark_id": 280,
    "analysis_method": "Diamond. 0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.641018+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.248,
    "score": 0.248,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:11.641018+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac51"
    },
    "model_benchmark_id": 1165,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "hiddenmath",
    "benchmark_name": "HiddenMath",
    "created_at": "2025-07-19T19:56:13.451948+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.277,
    "score": 0.277,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.451948+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac53"
    },
    "model_benchmark_id": 774,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.626596+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.665,
    "score": 0.665,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:12.626596+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac55"
    },
    "model_benchmark_id": 1307,
    "analysis_method": "0-shot",
    "benchmark_id": "include",
    "benchmark_name": "Include",
    "created_at": "2025-07-19T19:56:13.735634+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.386,
    "score": 0.386,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.735634+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac57"
    },
    "model_benchmark_id": 1112,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.320311+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.132,
    "score": 0.132,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.320311+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac59"
    },
    "model_benchmark_id": 1323,
    "analysis_method": "pass@1. 0-shot.",
    "benchmark_id": "livecodebench-v5",
    "benchmark_name": "LiveCodeBench v5",
    "created_at": "2025-07-19T19:56:13.777049+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.186,
    "score": 0.186,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.777049+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac5b"
    },
    "model_benchmark_id": 1176,
    "analysis_method": "pass@1. 3-shot.",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.477545+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.566,
    "score": 0.566,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.477545+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac5d"
    },
    "model_benchmark_id": 1278,
    "analysis_method": "0-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.679623+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.531,
    "score": 0.531,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.679623+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac5f"
    },
    "model_benchmark_id": 71,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.234595+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.601,
    "score": 0.601,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:11.234595+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac61"
    },
    "model_benchmark_id": 175,
    "analysis_method": "Accuracy. 0-shot.",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.439365+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.405,
    "score": 0.405,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:11.439365+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac63"
    },
    "model_benchmark_id": 1312,
    "analysis_method": "0-shot",
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-07-19T19:56:13.746554+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.081,
    "score": 0.081,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.746554+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac65"
    },
    "model_benchmark_id": 1432,
    "analysis_method": "0-shot",
    "benchmark_id": "openai-mmlu",
    "benchmark_name": "OpenAI MMLU",
    "created_at": "2025-07-19T19:56:14.047435+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.223,
    "score": 0.223,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:14.047435+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac67"
    },
    "model_benchmark_id": 1234,
    "analysis_method": "Character-level F-score. 0-shot.",
    "benchmark_id": "wmt24++",
    "benchmark_name": "WMT24++",
    "created_at": "2025-07-19T19:56:13.592107+00:00",
    "is_self_reported": true,
    "model_id": "gemma-3n-e2b-it",
    "normalized_score": 0.427,
    "score": 0.427,
    "self_reported_source_link": "https://huggingface.co/google/gemma-3n-E2B-it",
    "updated_at": "2025-07-19T19:56:13.592107+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac69"
    },
    "model_benchmark_id": 1436,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "aime",
    "benchmark_name": "AIME",
    "created_at": "2025-07-19T19:56:14.061299+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini-reasoning",
    "normalized_score": 0.575,
    "score": 0.575,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-reasoning",
    "updated_at": "2025-07-19T19:56:14.061299+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac6b"
    },
    "model_benchmark_id": 281,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.642870+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini-reasoning",
    "normalized_score": 0.52,
    "score": 0.52,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-reasoning",
    "updated_at": "2025-07-19T19:56:11.642870+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac6d"
    },
    "model_benchmark_id": 494,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.032863+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini-reasoning",
    "normalized_score": 0.946,
    "score": 0.946,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-reasoning",
    "updated_at": "2025-07-19T19:56:12.032863+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac6f"
    },
    "model_benchmark_id": 1445,
    "analysis_method": "simple-evals",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.082804+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:14.082804+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac71"
    },
    "model_benchmark_id": 947,
    "analysis_method": "simple-evals",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:12.999411+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.755,
    "score": 0.755,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:12.999411+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac73"
    },
    "model_benchmark_id": 282,
    "analysis_method": "simple-evals",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.644574+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.561,
    "score": 0.561,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:11.644574+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac75"
    },
    "model_benchmark_id": 775,
    "analysis_method": "simple-evals",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.628035+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:12.628035+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac77"
    },
    "model_benchmark_id": 1437,
    "analysis_method": "simple-evals",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.064824+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.828,
    "score": 0.828,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:14.064824+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac79"
    },
    "model_benchmark_id": 611,
    "analysis_method": "simple-evals",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.261770+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.63,
    "score": 0.63,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:12.261770+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac7b"
    },
    "model_benchmark_id": 746,
    "analysis_method": "simple-evals",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.569213+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.476,
    "score": 0.476,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:12.569213+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac7d"
    },
    "model_benchmark_id": 389,
    "analysis_method": "simple-evals",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.837602+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:11.837602+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac7f"
    },
    "model_benchmark_id": 1279,
    "analysis_method": "simple-evals",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.681417+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.806,
    "score": 0.806,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:13.681417+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac81"
    },
    "model_benchmark_id": 72,
    "analysis_method": "simple-evals",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.236043+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:11.236043+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac83"
    },
    "model_benchmark_id": 176,
    "analysis_method": "simple-evals",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.441164+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:11.441164+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac85"
    },
    "model_benchmark_id": 1466,
    "analysis_method": "simple-evals",
    "benchmark_id": "phibench",
    "benchmark_name": "PhiBench",
    "created_at": "2025-07-19T19:56:14.124860+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.562,
    "score": 0.562,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:14.124860+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac87"
    },
    "model_benchmark_id": 233,
    "analysis_method": "simple-evals",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.546523+00:00",
    "is_self_reported": true,
    "model_id": "phi-4",
    "normalized_score": 0.03,
    "score": 0.03,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.08905",
    "updated_at": "2025-07-19T19:56:11.546523+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac89"
    },
    "model_benchmark_id": 11,
    "analysis_method": "10-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.105059+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.837,
    "score": 0.837,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.105059+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac8b"
    },
    "model_benchmark_id": 1446,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.084727+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.084727+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac8d"
    },
    "model_benchmark_id": 1076,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.242363+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.242363+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac8f"
    },
    "model_benchmark_id": 1023,
    "analysis_method": "2-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.129244+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.129244+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac91"
    },
    "model_benchmark_id": 283,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.646470+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.252,
    "score": 0.252,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.646470+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac93"
    },
    "model_benchmark_id": 985,
    "analysis_method": "8-shot, CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.066927+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.066927+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac95"
    },
    "model_benchmark_id": 41,
    "analysis_method": "5-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.169983+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.691,
    "score": 0.691,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.169983+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac97"
    },
    "model_benchmark_id": 390,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.839081+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.839081+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac99"
    },
    "model_benchmark_id": 1280,
    "analysis_method": "5-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.683394+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.639,
    "score": 0.639,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.683394+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac9b"
    },
    "model_benchmark_id": 73,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.237489+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.673,
    "score": 0.673,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.237489+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac9d"
    },
    "model_benchmark_id": 177,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.443019+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.528,
    "score": 0.528,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.443019+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daac9f"
    },
    "model_benchmark_id": 1473,
    "analysis_method": "5-shot",
    "benchmark_id": "multilingual-mmlu",
    "benchmark_name": "Multilingual MMLU",
    "created_at": "2025-07-19T19:56:14.141886+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.493,
    "score": 0.493,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.141886+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaca1"
    },
    "model_benchmark_id": 1469,
    "analysis_method": "10-shot",
    "benchmark_id": "openbookqa",
    "benchmark_name": "OpenBookQA",
    "created_at": "2025-07-19T19:56:14.132301+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.792,
    "score": 0.792,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.132301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaca3"
    },
    "model_benchmark_id": 1032,
    "analysis_method": "5-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.150113+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.150113+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaca5"
    },
    "model_benchmark_id": 1041,
    "analysis_method": "5-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.172567+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.725,
    "score": 0.725,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.172567+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaca7"
    },
    "model_benchmark_id": 132,
    "analysis_method": "MC2, 10-shot",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.343180+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.664,
    "score": 0.664,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.343180+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaca9"
    },
    "model_benchmark_id": 149,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.382335+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-mini",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.382335+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacab"
    },
    "model_benchmark_id": 12,
    "analysis_method": "10-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.108027+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.91,
    "score": 0.91,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.108027+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacad"
    },
    "model_benchmark_id": 1447,
    "analysis_method": "standard evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.086453+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.379,
    "score": 0.379,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.086453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacaf"
    },
    "model_benchmark_id": 1077,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.244054+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.791,
    "score": 0.791,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.244054+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacb1"
    },
    "model_benchmark_id": 1024,
    "analysis_method": "2-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.130867+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.130867+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacb3"
    },
    "model_benchmark_id": 1503,
    "analysis_method": "standard evaluation",
    "benchmark_id": "govreport",
    "benchmark_name": "GovReport",
    "created_at": "2025-07-19T19:56:14.221191+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.264,
    "score": 0.264,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.221191+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacb5"
    },
    "model_benchmark_id": 284,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.649286+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.368,
    "score": 0.368,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.649286+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacb7"
    },
    "model_benchmark_id": 986,
    "analysis_method": "8-shot chain-of-thought",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.068601+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.887,
    "score": 0.887,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.068601+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacb9"
    },
    "model_benchmark_id": 42,
    "analysis_method": "5-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.171621+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.838,
    "score": 0.838,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.171621+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacbb"
    },
    "model_benchmark_id": 776,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.629465+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:12.629465+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacbd"
    },
    "model_benchmark_id": 391,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.841295+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.595,
    "score": 0.595,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.841295+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacbf"
    },
    "model_benchmark_id": 1177,
    "analysis_method": "3-shot",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.479387+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.808,
    "score": 0.808,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.479387+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacc1"
    },
    "model_benchmark_id": 1493,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-mlqa",
    "benchmark_name": "MEGA MLQA",
    "created_at": "2025-07-19T19:56:14.190086+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.653,
    "score": 0.653,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.190086+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacc3"
    },
    "model_benchmark_id": 1495,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-tydi-qa",
    "benchmark_name": "MEGA TyDi QA",
    "created_at": "2025-07-19T19:56:14.195123+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.671,
    "score": 0.671,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.195123+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacc5"
    },
    "model_benchmark_id": 1497,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-udpos",
    "benchmark_name": "MEGA UDPOS",
    "created_at": "2025-07-19T19:56:14.201497+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.201497+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacc7"
    },
    "model_benchmark_id": 1499,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-xcopa",
    "benchmark_name": "MEGA XCOPA",
    "created_at": "2025-07-19T19:56:14.208476+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.208476+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacc9"
    },
    "model_benchmark_id": 1501,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-xstorycloze",
    "benchmark_name": "MEGA XStoryCloze",
    "created_at": "2025-07-19T19:56:14.214764+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.828,
    "score": 0.828,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.214764+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaccb"
    },
    "model_benchmark_id": 1281,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.686017+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.587,
    "score": 0.587,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.686017+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaccd"
    },
    "model_benchmark_id": 74,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.239087+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.239087+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaccf"
    },
    "model_benchmark_id": 178,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.444580+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.453,
    "score": 0.453,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.446076+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacd1"
    },
    "model_benchmark_id": 1475,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.147234+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.699,
    "score": 0.699,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.147234+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacd3"
    },
    "model_benchmark_id": 1470,
    "analysis_method": "10-shot",
    "benchmark_id": "openbookqa",
    "benchmark_name": "OpenBookQA",
    "created_at": "2025-07-19T19:56:14.134275+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.896,
    "score": 0.896,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.134275+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacd5"
    },
    "model_benchmark_id": 1033,
    "analysis_method": "5-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.152199+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.152199+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacd7"
    },
    "model_benchmark_id": 1487,
    "analysis_method": "standard evaluation",
    "benchmark_id": "qasper",
    "benchmark_name": "Qasper",
    "created_at": "2025-07-19T19:56:14.171579+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.4,
    "score": 0.4,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.171579+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacd9"
    },
    "model_benchmark_id": 1505,
    "analysis_method": "standard evaluation",
    "benchmark_id": "qmsum",
    "benchmark_name": "QMSum",
    "created_at": "2025-07-19T19:56:14.226358+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.199,
    "score": 0.199,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.226358+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacdb"
    },
    "model_benchmark_id": 1491,
    "analysis_method": "average",
    "benchmark_id": "repoqa",
    "benchmark_name": "RepoQA",
    "created_at": "2025-07-19T19:56:14.184432+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.85,
    "score": 0.85,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.184432+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacdd"
    },
    "model_benchmark_id": 1489,
    "analysis_method": "long context (128K) evaluation",
    "benchmark_id": "ruler",
    "benchmark_name": "RULER",
    "created_at": "2025-07-19T19:56:14.177557+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.177557+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacdf"
    },
    "model_benchmark_id": 1042,
    "analysis_method": "5-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.176106+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.176106+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daace1"
    },
    "model_benchmark_id": 824,
    "analysis_method": "standard evaluation",
    "benchmark_id": "squality",
    "benchmark_name": "SQuALITY",
    "created_at": "2025-07-19T19:56:12.720914+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.241,
    "score": 0.241,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:12.720914+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daace3"
    },
    "model_benchmark_id": 1507,
    "analysis_method": "standard evaluation",
    "benchmark_id": "summscreenfd",
    "benchmark_name": "SummScreenFD",
    "created_at": "2025-07-19T19:56:14.232655+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.169,
    "score": 0.169,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:14.232655+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daace5"
    },
    "model_benchmark_id": 133,
    "analysis_method": "10-shot",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.344788+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.775,
    "score": 0.775,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:11.344788+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daace7"
    },
    "model_benchmark_id": 1062,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.215763+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-moe-instruct",
    "normalized_score": 0.813,
    "score": 0.813,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-MoE-instruct",
    "updated_at": "2025-07-19T19:56:13.215763+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daace9"
    },
    "model_benchmark_id": 13,
    "analysis_method": "10-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.111398+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.111398+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaceb"
    },
    "model_benchmark_id": 1448,
    "analysis_method": "standard evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.088299+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.37,
    "score": 0.37,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.088299+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaced"
    },
    "model_benchmark_id": 1078,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.245591+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.69,
    "score": 0.69,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.245591+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacef"
    },
    "model_benchmark_id": 1025,
    "analysis_method": "2-shot",
    "benchmark_id": "boolq",
    "benchmark_name": "BoolQ",
    "created_at": "2025-07-19T19:56:13.132882+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.132882+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacf1"
    },
    "model_benchmark_id": 1504,
    "analysis_method": "standard evaluation",
    "benchmark_id": "govreport",
    "benchmark_name": "GovReport",
    "created_at": "2025-07-19T19:56:14.222697+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.259,
    "score": 0.259,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.222697+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacf3"
    },
    "model_benchmark_id": 285,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.651230+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.304,
    "score": 0.304,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.651230+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacf5"
    },
    "model_benchmark_id": 987,
    "analysis_method": "8-shot chain-of-thought",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.070240+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.862,
    "score": 0.862,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.070240+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacf7"
    },
    "model_benchmark_id": 43,
    "analysis_method": "5-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.173447+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.694,
    "score": 0.694,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.173447+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacf9"
    },
    "model_benchmark_id": 777,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.631199+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.628,
    "score": 0.628,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:12.631199+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacfb"
    },
    "model_benchmark_id": 392,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.842901+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.485,
    "score": 0.485,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.842901+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacfd"
    },
    "model_benchmark_id": 1178,
    "analysis_method": "3-shot",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.481045+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.481045+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daacff"
    },
    "model_benchmark_id": 1494,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-mlqa",
    "benchmark_name": "MEGA MLQA",
    "created_at": "2025-07-19T19:56:14.191909+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.617,
    "score": 0.617,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.191909+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad01"
    },
    "model_benchmark_id": 1496,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-tydi-qa",
    "benchmark_name": "MEGA TyDi QA",
    "created_at": "2025-07-19T19:56:14.197084+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.622,
    "score": 0.622,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.197084+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad03"
    },
    "model_benchmark_id": 1498,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-udpos",
    "benchmark_name": "MEGA UDPOS",
    "created_at": "2025-07-19T19:56:14.203616+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.465,
    "score": 0.465,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.203616+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad05"
    },
    "model_benchmark_id": 1500,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-xcopa",
    "benchmark_name": "MEGA XCOPA",
    "created_at": "2025-07-19T19:56:14.210364+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.631,
    "score": 0.631,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.210364+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad07"
    },
    "model_benchmark_id": 1502,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mega-xstorycloze",
    "benchmark_name": "MEGA XStoryCloze",
    "created_at": "2025-07-19T19:56:14.217597+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.735,
    "score": 0.735,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.217597+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad09"
    },
    "model_benchmark_id": 1282,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.687534+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.479,
    "score": 0.479,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.687534+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad0b"
    },
    "model_benchmark_id": 75,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.240966+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.69,
    "score": 0.69,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.240966+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad0d"
    },
    "model_benchmark_id": 180,
    "analysis_method": "0-shot chain-of-thought",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.447960+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.474,
    "score": 0.474,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.450171+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad0f"
    },
    "model_benchmark_id": 1476,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.148935+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.554,
    "score": 0.554,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.148935+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad11"
    },
    "model_benchmark_id": 1471,
    "analysis_method": "10-shot",
    "benchmark_id": "openbookqa",
    "benchmark_name": "OpenBookQA",
    "created_at": "2025-07-19T19:56:14.136354+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.792,
    "score": 0.792,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.136354+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad13"
    },
    "model_benchmark_id": 1034,
    "analysis_method": "5-shot",
    "benchmark_id": "piqa",
    "benchmark_name": "PIQA",
    "created_at": "2025-07-19T19:56:13.154444+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.154444+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad15"
    },
    "model_benchmark_id": 1488,
    "analysis_method": "standard evaluation",
    "benchmark_id": "qasper",
    "benchmark_name": "Qasper",
    "created_at": "2025-07-19T19:56:14.173290+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.419,
    "score": 0.419,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.173290+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad17"
    },
    "model_benchmark_id": 1506,
    "analysis_method": "standard evaluation",
    "benchmark_id": "qmsum",
    "benchmark_name": "QMSum",
    "created_at": "2025-07-19T19:56:14.228389+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.213,
    "score": 0.213,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.228389+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad19"
    },
    "model_benchmark_id": 1492,
    "analysis_method": "average",
    "benchmark_id": "repoqa",
    "benchmark_name": "RepoQA",
    "created_at": "2025-07-19T19:56:14.186426+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.77,
    "score": 0.77,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.186426+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad1b"
    },
    "model_benchmark_id": 1490,
    "analysis_method": "128k",
    "benchmark_id": "ruler",
    "benchmark_name": "RULER",
    "created_at": "2025-07-19T19:56:14.179307+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.179307+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad1d"
    },
    "model_benchmark_id": 1043,
    "analysis_method": "5-shot",
    "benchmark_id": "social-iqa",
    "benchmark_name": "Social IQa",
    "created_at": "2025-07-19T19:56:13.177860+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.747,
    "score": 0.747,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.177860+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad1f"
    },
    "model_benchmark_id": 825,
    "analysis_method": "standard evaluation",
    "benchmark_id": "squality",
    "benchmark_name": "SQuALITY",
    "created_at": "2025-07-19T19:56:12.722570+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.243,
    "score": 0.243,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:12.722570+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad21"
    },
    "model_benchmark_id": 1508,
    "analysis_method": "standard evaluation",
    "benchmark_id": "summscreenfd",
    "benchmark_name": "SummScreenFD",
    "created_at": "2025-07-19T19:56:14.234498+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.16,
    "score": 0.16,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:14.234498+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad23"
    },
    "model_benchmark_id": 134,
    "analysis_method": "10-shot",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.346508+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:11.346508+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad25"
    },
    "model_benchmark_id": 1063,
    "analysis_method": "5-shot",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.217697+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-mini-instruct",
    "normalized_score": 0.685,
    "score": 0.685,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct",
    "updated_at": "2025-07-19T19:56:13.217697+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad27"
    },
    "model_benchmark_id": 1250,
    "analysis_method": "standard evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.626694+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.781,
    "score": 0.781,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:13.626694+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad29"
    },
    "model_benchmark_id": 858,
    "analysis_method": "standard evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.795942+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.818,
    "score": 0.818,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:12.795942+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad2b"
    },
    "model_benchmark_id": 1520,
    "analysis_method": "standard evaluation",
    "benchmark_id": "intergps",
    "benchmark_name": "InterGPS",
    "created_at": "2025-07-19T19:56:14.261813+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.363,
    "score": 0.363,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:14.261813+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad2d"
    },
    "model_benchmark_id": 520,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.080462+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.439,
    "score": 0.439,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:12.080462+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad2f"
    },
    "model_benchmark_id": 1509,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.238017+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.819,
    "score": 0.819,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:14.238017+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad31"
    },
    "model_benchmark_id": 563,
    "analysis_method": "standard evaluation",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.158730+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.43,
    "score": 0.43,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:12.158730+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad33"
    },
    "model_benchmark_id": 1522,
    "analysis_method": "standard evaluation",
    "benchmark_id": "pope",
    "benchmark_name": "POPE",
    "created_at": "2025-07-19T19:56:14.266959+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.861,
    "score": 0.861,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:14.266959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad35"
    },
    "model_benchmark_id": 1519,
    "analysis_method": "standard evaluation",
    "benchmark_id": "scienceqa",
    "benchmark_name": "ScienceQA",
    "created_at": "2025-07-19T19:56:14.258220+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.913,
    "score": 0.913,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:14.258220+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad37"
    },
    "model_benchmark_id": 906,
    "analysis_method": "standard evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.888892+00:00",
    "is_self_reported": true,
    "model_id": "phi-3.5-vision-instruct",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-3.5-vision-instruct",
    "updated_at": "2025-07-19T19:56:12.888892+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad39"
    },
    "model_benchmark_id": 449,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.953709+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.813,
    "score": 0.813,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:11.953709+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad3b"
    },
    "model_benchmark_id": 687,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.440995+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:12.440995+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad3d"
    },
    "model_benchmark_id": 1449,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.090173+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.090173+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad3f"
    },
    "model_benchmark_id": 1526,
    "analysis_method": "3K-token subset",
    "benchmark_id": "flenqa",
    "benchmark_name": "FlenQA",
    "created_at": "2025-07-19T19:56:14.279654+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.979,
    "score": 0.979,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.279654+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad41"
    },
    "model_benchmark_id": 286,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.652983+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:11.652983+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad43"
    },
    "model_benchmark_id": 1438,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.066904+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.066904+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad45"
    },
    "model_benchmark_id": 612,
    "analysis_method": "Strict",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.263243+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.849,
    "score": 0.849,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:12.263243+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad47"
    },
    "model_benchmark_id": 1113,
    "analysis_method": "8/1/24\u20132/1/25",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.322076+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.531,
    "score": 0.531,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:13.322076+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad49"
    },
    "model_benchmark_id": 182,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.451685+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.76,
    "score": 0.76,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:11.451685+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad4b"
    },
    "model_benchmark_id": 1524,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "omnimath",
    "benchmark_name": "OmniMath",
    "created_at": "2025-07-19T19:56:14.274539+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.819,
    "score": 0.819,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.274539+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad4d"
    },
    "model_benchmark_id": 1467,
    "analysis_method": "2.21",
    "benchmark_id": "phibench",
    "benchmark_name": "PhiBench",
    "created_at": "2025-07-19T19:56:14.126449+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning-plus",
    "normalized_score": 0.742,
    "score": 0.742,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.126449+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad4f"
    },
    "model_benchmark_id": 1251,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.628230+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.823,
    "score": 0.823,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:13.628230+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad51"
    },
    "model_benchmark_id": 1545,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "blink",
    "benchmark_name": "BLINK",
    "created_at": "2025-07-19T19:56:14.329567+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.613,
    "score": 0.613,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.329567+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad53"
    },
    "model_benchmark_id": 859,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.797898+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:12.797898+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad55"
    },
    "model_benchmark_id": 881,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.836095+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.932,
    "score": 0.932,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:12.836095+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad57"
    },
    "model_benchmark_id": 1241,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.609397+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.727,
    "score": 0.727,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:13.609397+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad59"
    },
    "model_benchmark_id": 1521,
    "analysis_method": "testmini",
    "benchmark_id": "intergps",
    "benchmark_name": "InterGPS",
    "created_at": "2025-07-19T19:56:14.263464+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.486,
    "score": 0.486,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.263464+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad5b"
    },
    "model_benchmark_id": 521,
    "analysis_method": "testmini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.082453+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.624,
    "score": 0.624,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:12.082453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad5d"
    },
    "model_benchmark_id": 1510,
    "analysis_method": "dev-en",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.240071+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.867,
    "score": 0.867,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.240071+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad5f"
    },
    "model_benchmark_id": 564,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.161302+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.551,
    "score": 0.551,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:12.161302+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad61"
    },
    "model_benchmark_id": 1528,
    "analysis_method": "std/vision",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.285447+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.385,
    "score": 0.385,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.285447+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad63"
    },
    "model_benchmark_id": 1538,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.309778+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.844,
    "score": 0.844,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.309778+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad65"
    },
    "model_benchmark_id": 1523,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "pope",
    "benchmark_name": "POPE",
    "created_at": "2025-07-19T19:56:14.268923+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.856,
    "score": 0.856,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.268923+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad67"
    },
    "model_benchmark_id": 1537,
    "analysis_method": "img-test",
    "benchmark_id": "scienceqa-visual",
    "benchmark_name": "ScienceQA Visual",
    "created_at": "2025-07-19T19:56:14.303456+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.975,
    "score": 0.975,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:14.303456+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad69"
    },
    "model_benchmark_id": 907,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.890738+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.756,
    "score": 0.756,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:12.890738+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad6b"
    },
    "model_benchmark_id": 1383,
    "analysis_method": "16 frames",
    "benchmark_id": "video-mme",
    "benchmark_name": "Video-MME",
    "created_at": "2025-07-19T19:56:13.911859+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-multimodal-instruct",
    "normalized_score": 0.55,
    "score": 0.55,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct",
    "updated_at": "2025-07-19T19:56:13.911859+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad6d"
    },
    "model_benchmark_id": 450,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.955706+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.753,
    "score": 0.753,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning",
    "updated_at": "2025-07-19T19:56:11.955706+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad6f"
    },
    "model_benchmark_id": 688,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.444086+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.629,
    "score": 0.629,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning",
    "updated_at": "2025-07-19T19:56:12.444086+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad71"
    },
    "model_benchmark_id": 1450,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.091856+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.091856+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad73"
    },
    "model_benchmark_id": 1527,
    "analysis_method": "3K-token subset",
    "benchmark_id": "flenqa",
    "benchmark_name": "FlenQA",
    "created_at": "2025-07-19T19:56:14.281300+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.977,
    "score": 0.977,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.281300+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad75"
    },
    "model_benchmark_id": 287,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.654843+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning",
    "updated_at": "2025-07-19T19:56:11.654843+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad77"
    },
    "model_benchmark_id": 1439,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.068831+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.929,
    "score": 0.929,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.068831+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad79"
    },
    "model_benchmark_id": 613,
    "analysis_method": "Strict",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.265033+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:12.265033+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad7b"
    },
    "model_benchmark_id": 1114,
    "analysis_method": "8/1/24\u20132/1/25",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.324523+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.538,
    "score": 0.538,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning",
    "updated_at": "2025-07-19T19:56:13.324523+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad7d"
    },
    "model_benchmark_id": 183,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.453150+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:11.453150+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad7f"
    },
    "model_benchmark_id": 1525,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "omnimath",
    "benchmark_name": "OmniMath",
    "created_at": "2025-07-19T19:56:14.276205+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning",
    "updated_at": "2025-07-19T19:56:14.276205+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad81"
    },
    "model_benchmark_id": 1468,
    "analysis_method": "2.21",
    "benchmark_id": "phibench",
    "benchmark_name": "PhiBench",
    "created_at": "2025-07-19T19:56:14.127989+00:00",
    "is_self_reported": true,
    "model_id": "phi-4-reasoning",
    "normalized_score": 0.706,
    "score": 0.706,
    "self_reported_source_link": "https://huggingface.co/microsoft/Phi-4-reasoning-plus",
    "updated_at": "2025-07-19T19:56:14.127989+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad83"
    },
    "model_benchmark_id": 1560,
    "analysis_method": "0-shot",
    "benchmark_id": "api-bank",
    "benchmark_name": "API-Bank",
    "created_at": "2025-07-19T19:56:14.378301+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.378301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad85"
    },
    "model_benchmark_id": 14,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.113697+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.948,
    "score": 0.948,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:11.113697+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad87"
    },
    "model_benchmark_id": 846,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.771784+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:12.771784+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad89"
    },
    "model_benchmark_id": 948,
    "analysis_method": "0-shot",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.001514+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.796,
    "score": 0.796,
    "self_reported_source_link": "https://arxiv.org/pdf/2407.21783",
    "updated_at": "2025-07-19T19:56:13.001514+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad8b"
    },
    "model_benchmark_id": 1563,
    "analysis_method": "0-shot",
    "benchmark_id": "gorilla-benchmark-api-bench",
    "benchmark_name": "Gorilla Benchmark API Bench",
    "created_at": "2025-07-19T19:56:14.386457+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.297,
    "score": 0.297,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.386457+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad8d"
    },
    "model_benchmark_id": 288,
    "analysis_method": "0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.657221+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.417,
    "score": 0.417,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:11.657221+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad8f"
    },
    "model_benchmark_id": 1556,
    "analysis_method": "8-shot Chain-of-Thought",
    "benchmark_id": "gsm-8k-(cot)",
    "benchmark_name": "GSM-8K (CoT)",
    "created_at": "2025-07-19T19:56:14.362878+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.951,
    "score": 0.951,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.362878+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad91"
    },
    "model_benchmark_id": 778,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.632931+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:12.632931+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad93"
    },
    "model_benchmark_id": 614,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.266791+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:12.266791+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad95"
    },
    "model_benchmark_id": 1558,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "math-(cot)",
    "benchmark_name": "MATH (CoT)",
    "created_at": "2025-07-19T19:56:14.371489+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.371489+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad97"
    },
    "model_benchmark_id": 1549,
    "analysis_method": "0-shot",
    "benchmark_id": "mbpp-++-base-version",
    "benchmark_name": "MBPP ++ base version",
    "created_at": "2025-07-19T19:56:14.344061+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.344061+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad99"
    },
    "model_benchmark_id": 76,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.243294+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.836,
    "score": 0.836,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:11.243294+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad9b"
    },
    "model_benchmark_id": 1546,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "mmlu-(cot)",
    "benchmark_name": "MMLU (CoT)",
    "created_at": "2025-07-19T19:56:14.334507+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.334507+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad9d"
    },
    "model_benchmark_id": 184,
    "analysis_method": "5-shot Chain-of-Thought",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.455089+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.664,
    "score": 0.664,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:11.455089+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daad9f"
    },
    "model_benchmark_id": 1570,
    "analysis_method": "0-shot Chain-of-Thought",
    "benchmark_id": "multilingual-mgsm-(cot)",
    "benchmark_name": "Multilingual MGSM (CoT)",
    "created_at": "2025-07-19T19:56:14.405488+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.869,
    "score": 0.869,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.405488+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daada1"
    },
    "model_benchmark_id": 1550,
    "analysis_method": "0-shot",
    "benchmark_id": "multipl-e-humaneval",
    "benchmark_name": "Multipl-E HumanEval",
    "created_at": "2025-07-19T19:56:14.347431+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.655,
    "score": 0.655,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.347431+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daada3"
    },
    "model_benchmark_id": 1553,
    "analysis_method": "0-shot",
    "benchmark_id": "multipl-e-mbpp",
    "benchmark_name": "Multipl-E MBPP",
    "created_at": "2025-07-19T19:56:14.356043+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.62,
    "score": 0.62,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.356043+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daada5"
    },
    "model_benchmark_id": 1566,
    "analysis_method": "0-shot",
    "benchmark_id": "nexus",
    "benchmark_name": "Nexus",
    "created_at": "2025-07-19T19:56:14.394299+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-70b-instruct",
    "normalized_score": 0.567,
    "score": 0.567,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "updated_at": "2025-07-19T19:56:14.394299+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daada7"
    },
    "model_benchmark_id": 1252,
    "analysis_method": "-",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.629735+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:13.629735+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daada9"
    },
    "model_benchmark_id": 860,
    "analysis_method": "-",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.799861+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.855,
    "score": 0.855,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:12.799861+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadab"
    },
    "model_benchmark_id": 882,
    "analysis_method": "-",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.837654+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.901,
    "score": 0.901,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:12.837654+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadad"
    },
    "model_benchmark_id": 289,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.659193+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.467,
    "score": 0.467,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:11.659193+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadaf"
    },
    "model_benchmark_id": 1576,
    "analysis_method": "-",
    "benchmark_id": "infographicsqa",
    "benchmark_name": "InfographicsQA",
    "created_at": "2025-07-19T19:56:14.420214+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.568,
    "score": 0.568,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:14.420214+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadb1"
    },
    "model_benchmark_id": 393,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.844378+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:11.844378+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadb3"
    },
    "model_benchmark_id": 522,
    "analysis_method": "-",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.084321+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.573,
    "score": 0.573,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:12.084321+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadb5"
    },
    "model_benchmark_id": 1283,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.688987+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.869,
    "score": 0.869,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:13.688987+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadb7"
    },
    "model_benchmark_id": 77,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.245688+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:11.245688+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadb9"
    },
    "model_benchmark_id": 565,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.162828+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.603,
    "score": 0.603,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:12.162828+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadbb"
    },
    "model_benchmark_id": 1529,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.287214+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.452,
    "score": 0.452,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:14.287214+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadbd"
    },
    "model_benchmark_id": 908,
    "analysis_method": "-",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.892927+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.735,
    "score": 0.735,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:12.892927+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadbf"
    },
    "model_benchmark_id": 1573,
    "analysis_method": "-",
    "benchmark_id": "vqav2",
    "benchmark_name": "VQAv2",
    "created_at": "2025-07-19T19:56:14.412800+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-90b-instruct",
    "normalized_score": 0.781,
    "score": 0.781,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
    "updated_at": "2025-07-19T19:56:14.412800+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadc1"
    },
    "model_benchmark_id": 1561,
    "analysis_method": "0-shot",
    "benchmark_id": "api-bank",
    "benchmark_name": "API-Bank",
    "created_at": "2025-07-19T19:56:14.380088+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.380088+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadc3"
    },
    "model_benchmark_id": 15,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.115810+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:11.115810+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadc5"
    },
    "model_benchmark_id": 847,
    "analysis_method": "0-shot",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.773659+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.761,
    "score": 0.761,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:12.773659+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadc7"
    },
    "model_benchmark_id": 949,
    "analysis_method": "0-shot",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.003032+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.595,
    "score": 0.595,
    "self_reported_source_link": "https://arxiv.org/pdf/2407.21783",
    "updated_at": "2025-07-19T19:56:13.003032+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadc9"
    },
    "model_benchmark_id": 1564,
    "analysis_method": "0-shot",
    "benchmark_id": "gorilla-benchmark-api-bench",
    "benchmark_name": "Gorilla Benchmark API Bench",
    "created_at": "2025-07-19T19:56:14.388429+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.082,
    "score": 0.082,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.388429+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadcb"
    },
    "model_benchmark_id": 290,
    "analysis_method": "0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.660952+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.304,
    "score": 0.304,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:11.660952+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadcd"
    },
    "model_benchmark_id": 1557,
    "analysis_method": "8-shot",
    "benchmark_id": "gsm-8k-(cot)",
    "benchmark_name": "GSM-8K (CoT)",
    "created_at": "2025-07-19T19:56:14.364382+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.364382+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadcf"
    },
    "model_benchmark_id": 779,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.634981+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.726,
    "score": 0.726,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:12.634981+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadd1"
    },
    "model_benchmark_id": 615,
    "analysis_method": "unspecified",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.268709+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:12.268709+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadd3"
    },
    "model_benchmark_id": 1559,
    "analysis_method": "0-shot",
    "benchmark_id": "math-(cot)",
    "benchmark_name": "MATH (CoT)",
    "created_at": "2025-07-19T19:56:14.373274+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.519,
    "score": 0.519,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.373274+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadd5"
    },
    "model_benchmark_id": 1577,
    "analysis_method": "0-shot",
    "benchmark_id": "mbpp-evalplus-(base)",
    "benchmark_name": "MBPP EvalPlus (base)",
    "created_at": "2025-07-19T19:56:14.424442+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.728,
    "score": 0.728,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.424442+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadd7"
    },
    "model_benchmark_id": 78,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.247675+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.694,
    "score": 0.694,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:11.247675+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadd9"
    },
    "model_benchmark_id": 1547,
    "analysis_method": "0-shot",
    "benchmark_id": "mmlu-(cot)",
    "benchmark_name": "MMLU (CoT)",
    "created_at": "2025-07-19T19:56:14.337443+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.337443+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaddb"
    },
    "model_benchmark_id": 185,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.457212+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.483,
    "score": 0.483,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:11.457212+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaddd"
    },
    "model_benchmark_id": 1571,
    "analysis_method": "0-shot",
    "benchmark_id": "multilingual-mgsm-(cot)",
    "benchmark_name": "Multilingual MGSM (CoT)",
    "created_at": "2025-07-19T19:56:14.407707+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.407707+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaddf"
    },
    "model_benchmark_id": 1551,
    "analysis_method": "0-shot",
    "benchmark_id": "multipl-e-humaneval",
    "benchmark_name": "Multipl-E HumanEval",
    "created_at": "2025-07-19T19:56:14.350301+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.508,
    "score": 0.508,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.350301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daade1"
    },
    "model_benchmark_id": 1554,
    "analysis_method": "0-shot",
    "benchmark_id": "multipl-e-mbpp",
    "benchmark_name": "Multipl-E MBPP",
    "created_at": "2025-07-19T19:56:14.357886+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.524,
    "score": 0.524,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.357886+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daade3"
    },
    "model_benchmark_id": 1567,
    "analysis_method": "0-shot",
    "benchmark_id": "nexus",
    "benchmark_name": "Nexus",
    "created_at": "2025-07-19T19:56:14.396611+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-8b-instruct",
    "normalized_score": 0.385,
    "score": 0.385,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "updated_at": "2025-07-19T19:56:14.396611+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daade5"
    },
    "model_benchmark_id": 1562,
    "analysis_method": "0-shot",
    "benchmark_id": "api-bank",
    "benchmark_name": "API-Bank",
    "created_at": "2025-07-19T19:56:14.382379+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.92,
    "score": 0.92,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.382379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daade7"
    },
    "model_benchmark_id": 16,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.118562+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.969,
    "score": 0.969,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:11.118562+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daade9"
    },
    "model_benchmark_id": 848,
    "analysis_method": "0-shot",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.775431+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:12.775431+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadeb"
    },
    "model_benchmark_id": 950,
    "analysis_method": "0-shot",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.004517+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://arxiv.org/pdf/2407.21783",
    "updated_at": "2025-07-19T19:56:13.004517+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaded"
    },
    "model_benchmark_id": 1565,
    "analysis_method": "0-shot",
    "benchmark_id": "gorilla-benchmark-api-bench",
    "benchmark_name": "Gorilla Benchmark API Bench",
    "created_at": "2025-07-19T19:56:14.390263+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.353,
    "score": 0.353,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.390263+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadef"
    },
    "model_benchmark_id": 291,
    "analysis_method": "0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.662460+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.507,
    "score": 0.507,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:11.662460+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadf1"
    },
    "model_benchmark_id": 988,
    "analysis_method": "8-shot, CoT, em_maj1@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.071677+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.968,
    "score": 0.968,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:13.071677+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadf3"
    },
    "model_benchmark_id": 780,
    "analysis_method": "0-shot, pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.636480+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:12.636480+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadf5"
    },
    "model_benchmark_id": 616,
    "analysis_method": "Standard",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.270752+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:12.270752+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadf7"
    },
    "model_benchmark_id": 394,
    "analysis_method": "0-shot, CoT, final_em",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.846056+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.738,
    "score": 0.738,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:11.846056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadf9"
    },
    "model_benchmark_id": 1578,
    "analysis_method": "0-shot, base, pass@1",
    "benchmark_id": "mbpp-evalplus",
    "benchmark_name": "MBPP EvalPlus",
    "created_at": "2025-07-19T19:56:14.428183+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.428183+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadfb"
    },
    "model_benchmark_id": 79,
    "analysis_method": "5-shot, macro_avg/acc",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.249582+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.873,
    "score": 0.873,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:11.249582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadfd"
    },
    "model_benchmark_id": 1548,
    "analysis_method": "0-shot, macro_avg/acc",
    "benchmark_id": "mmlu-(cot)",
    "benchmark_name": "MMLU (CoT)",
    "created_at": "2025-07-19T19:56:14.339647+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.886,
    "score": 0.886,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.339647+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daadff"
    },
    "model_benchmark_id": 186,
    "analysis_method": "5-shot, CoT, micro_avg/acc_char",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.458814+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:11.458814+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae01"
    },
    "model_benchmark_id": 1572,
    "analysis_method": "0-shot, CoT, em",
    "benchmark_id": "multilingual-mgsm-(cot)",
    "benchmark_name": "Multilingual MGSM (CoT)",
    "created_at": "2025-07-19T19:56:14.409472+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.409472+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae03"
    },
    "model_benchmark_id": 1552,
    "analysis_method": "0-shot, pass@1",
    "benchmark_id": "multipl-e-humaneval",
    "benchmark_name": "Multipl-E HumanEval",
    "created_at": "2025-07-19T19:56:14.352505+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.752,
    "score": 0.752,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.352505+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae05"
    },
    "model_benchmark_id": 1555,
    "analysis_method": "0-shot, pass@1",
    "benchmark_id": "multipl-e-mbpp",
    "benchmark_name": "Multipl-E MBPP",
    "created_at": "2025-07-19T19:56:14.359473+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.657,
    "score": 0.657,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.359473+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae07"
    },
    "model_benchmark_id": 1568,
    "analysis_method": "0-shot, macro_avg/acc",
    "benchmark_id": "nexus",
    "benchmark_name": "Nexus",
    "created_at": "2025-07-19T19:56:14.398966+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-405b-instruct",
    "normalized_score": 0.587,
    "score": 0.587,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "updated_at": "2025-07-19T19:56:14.398966+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae09"
    },
    "model_benchmark_id": 1253,
    "analysis_method": "Test accuracy",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.631448+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.911,
    "score": 0.911,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:13.631448+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae0b"
    },
    "model_benchmark_id": 861,
    "analysis_method": "Test, 0-shot CoT relaxed accuracy",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.801741+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:12.801741+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae0d"
    },
    "model_benchmark_id": 883,
    "analysis_method": "Test ANLS",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.839416+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:12.839416+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae0f"
    },
    "model_benchmark_id": 292,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.663962+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:11.663962+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae11"
    },
    "model_benchmark_id": 395,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.847598+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.519,
    "score": 0.519,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:11.847598+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae13"
    },
    "model_benchmark_id": 523,
    "analysis_method": "Test accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.086640+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.515,
    "score": 0.515,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:12.086640+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae15"
    },
    "model_benchmark_id": 1284,
    "analysis_method": "0-shot, CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.690958+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:13.690958+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae17"
    },
    "model_benchmark_id": 80,
    "analysis_method": "Macro average accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.251362+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:11.251362+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae19"
    },
    "model_benchmark_id": 566,
    "analysis_method": "Val, 0-shot CoT, micro avg accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.164872+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.507,
    "score": 0.507,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:12.164872+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae1b"
    },
    "model_benchmark_id": 1530,
    "analysis_method": "Test accuracy",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.288730+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.33,
    "score": 0.33,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:14.288730+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae1d"
    },
    "model_benchmark_id": 1580,
    "analysis_method": "Accuracy",
    "benchmark_id": "vqav2-(test)",
    "benchmark_name": "VQAv2 (test)",
    "created_at": "2025-07-19T19:56:14.434081+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-11b-instruct",
    "normalized_score": 0.752,
    "score": 0.752,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
    "updated_at": "2025-07-19T19:56:14.434081+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae1f"
    },
    "model_benchmark_id": 17,
    "analysis_method": "0-shot, acc",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.120164+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:11.120164+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae21"
    },
    "model_benchmark_id": 1583,
    "analysis_method": "0-shot, acc",
    "benchmark_id": "bfcl-v2",
    "benchmark_name": "BFCL v2",
    "created_at": "2025-07-19T19:56:14.446368+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.446368+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae23"
    },
    "model_benchmark_id": 293,
    "analysis_method": "0-shot, acc",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.665423+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:11.665423+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae25"
    },
    "model_benchmark_id": 989,
    "analysis_method": "8-shot, em_maj1@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.073210+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.777,
    "score": 0.777,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:13.073210+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae27"
    },
    "model_benchmark_id": 44,
    "analysis_method": "0-shot, acc",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.175473+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.698,
    "score": 0.698,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:11.175473+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae29"
    },
    "model_benchmark_id": 617,
    "analysis_method": "Avg(Prompt/Instruction acc Loose/Strict)",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.272319+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.774,
    "score": 0.774,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:12.272319+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae2b"
    },
    "model_benchmark_id": 1589,
    "analysis_method": "0-shot, longbook_choice/acc",
    "benchmark_id": "infinitebench-en.mc",
    "benchmark_name": "InfiniteBench/En.MC",
    "created_at": "2025-07-19T19:56:14.464298+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.633,
    "score": 0.633,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.464298+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae2d"
    },
    "model_benchmark_id": 1588,
    "analysis_method": "0-shot, longbook_qa/f1",
    "benchmark_id": "infinitebench-en.qa",
    "benchmark_name": "InfiniteBench/En.QA",
    "created_at": "2025-07-19T19:56:14.460560+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.198,
    "score": 0.198,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.460560+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae2f"
    },
    "model_benchmark_id": 396,
    "analysis_method": "0-shot, final_em",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.849582+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.48,
    "score": 0.48,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:11.849582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae31"
    },
    "model_benchmark_id": 1285,
    "analysis_method": "CoT, em",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.692573+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.582,
    "score": 0.582,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:13.692573+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae33"
    },
    "model_benchmark_id": 81,
    "analysis_method": "5-shot, macro_avg/acc",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.252797+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.634,
    "score": 0.634,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:11.252797+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae35"
    },
    "model_benchmark_id": 1569,
    "analysis_method": "0-shot, macro_avg/acc",
    "benchmark_id": "nexus",
    "benchmark_name": "Nexus",
    "created_at": "2025-07-19T19:56:14.401027+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.343,
    "score": 0.343,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.401027+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae37"
    },
    "model_benchmark_id": 1590,
    "analysis_method": "0-shot, recall",
    "benchmark_id": "nih-multi-needle",
    "benchmark_name": "NIH/Multi-needle",
    "created_at": "2025-07-19T19:56:14.469424+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.847,
    "score": 0.847,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.469424+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae39"
    },
    "model_benchmark_id": 1581,
    "analysis_method": "0-shot, micro_avg/rougeL",
    "benchmark_id": "open-rewrite",
    "benchmark_name": "Open-rewrite",
    "created_at": "2025-07-19T19:56:14.438526+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.401,
    "score": 0.401,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.438526+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae3b"
    },
    "model_benchmark_id": 1582,
    "analysis_method": "1-shot, rougeL",
    "benchmark_id": "tldr9+-(test)",
    "benchmark_name": "TLDR9+ (test)",
    "created_at": "2025-07-19T19:56:14.443142+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.2-3b-instruct",
    "normalized_score": 0.19,
    "score": 0.19,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
    "updated_at": "2025-07-19T19:56:14.443142+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae3d"
    },
    "model_benchmark_id": 862,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.803334+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.803334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae3f"
    },
    "model_benchmark_id": 884,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.841331+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.944,
    "score": 0.944,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.841331+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae41"
    },
    "model_benchmark_id": 294,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.666983+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.698,
    "score": 0.698,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:11.666983+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae43"
    },
    "model_benchmark_id": 1115,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.326624+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.434,
    "score": 0.434,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:13.326624+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae45"
    },
    "model_benchmark_id": 397,
    "analysis_method": "4-shot em_maj1@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.851038+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.612,
    "score": 0.612,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:11.851038+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae47"
    },
    "model_benchmark_id": 524,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.088308+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.737,
    "score": 0.737,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.088308+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae49"
    },
    "model_benchmark_id": 1179,
    "analysis_method": "3-shot pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.485323+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:13.485323+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae4b"
    },
    "model_benchmark_id": 1286,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.694238+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:13.694238+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae4d"
    },
    "model_benchmark_id": 82,
    "analysis_method": "5-shot macro_avg/acc_char",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.254352+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.855,
    "score": 0.855,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:11.254352+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae4f"
    },
    "model_benchmark_id": 187,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.460210+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:11.460210+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae51"
    },
    "model_benchmark_id": 567,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.167124+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.734,
    "score": 0.734,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.167124+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae53"
    },
    "model_benchmark_id": 1531,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.290598+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.596,
    "score": 0.596,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:14.290598+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae55"
    },
    "model_benchmark_id": 1591,
    "analysis_method": "1-shot average/f1",
    "benchmark_id": "tydiqa",
    "benchmark_name": "TydiQA",
    "created_at": "2025-07-19T19:56:14.475429+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-maverick",
    "normalized_score": 0.317,
    "score": 0.317,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:14.475429+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae57"
    },
    "model_benchmark_id": 863,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.804916+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.888,
    "score": 0.888,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.804916+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae59"
    },
    "model_benchmark_id": 885,
    "analysis_method": "0-shot (ANLS)",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.842838+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.944,
    "score": 0.944,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.842838+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae5b"
    },
    "model_benchmark_id": 295,
    "analysis_method": "0-shot (accuracy)",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.668436+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:11.668436+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae5d"
    },
    "model_benchmark_id": 1116,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.328074+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:13.328074+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae5f"
    },
    "model_benchmark_id": 398,
    "analysis_method": "4-shot em_maj1@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.852669+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.503,
    "score": 0.503,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:11.852669+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae61"
    },
    "model_benchmark_id": 525,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.089981+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.089981+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae63"
    },
    "model_benchmark_id": 1180,
    "analysis_method": "3-shot pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.487376+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.678,
    "score": 0.678,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:13.487376+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae65"
    },
    "model_benchmark_id": 1287,
    "analysis_method": "0-shot (average/em)",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.695659+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.906,
    "score": 0.906,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:13.695659+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae67"
    },
    "model_benchmark_id": 83,
    "analysis_method": "5-shot macro_avg/acc_char",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.258246+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.796,
    "score": 0.796,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:11.258246+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae69"
    },
    "model_benchmark_id": 188,
    "analysis_method": "0-shot (macro_avg/acc)",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.461726+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:11.461726+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae6b"
    },
    "model_benchmark_id": 568,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.169227+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.694,
    "score": 0.694,
    "self_reported_source_link": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
    "updated_at": "2025-07-19T19:56:12.169227+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae6d"
    },
    "model_benchmark_id": 1592,
    "analysis_method": "1-shot average/f1",
    "benchmark_id": "tydiqa",
    "benchmark_name": "TydiQA",
    "created_at": "2025-07-19T19:56:14.477364+00:00",
    "is_self_reported": true,
    "model_id": "llama-4-scout",
    "normalized_score": 0.315,
    "score": 0.315,
    "self_reported_source_link": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "updated_at": "2025-07-19T19:56:14.477364+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae6f"
    },
    "model_benchmark_id": 1584,
    "analysis_method": "-",
    "benchmark_id": "bfcl-v2",
    "benchmark_name": "BFCL v2",
    "created_at": "2025-07-19T19:56:14.448863+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.773,
    "score": 0.773,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:14.448863+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae71"
    },
    "model_benchmark_id": 296,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.669923+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.505,
    "score": 0.505,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:11.669923+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae73"
    },
    "model_benchmark_id": 781,
    "analysis_method": "-",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.637990+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:12.637990+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae75"
    },
    "model_benchmark_id": 618,
    "analysis_method": "-",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.274109+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.921,
    "score": 0.921,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:12.274109+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae77"
    },
    "model_benchmark_id": 399,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.854268+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.77,
    "score": 0.77,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:11.854268+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae79"
    },
    "model_benchmark_id": 1579,
    "analysis_method": "-",
    "benchmark_id": "mbpp-evalplus",
    "benchmark_name": "MBPP EvalPlus",
    "created_at": "2025-07-19T19:56:14.429699+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.876,
    "score": 0.876,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:14.429699+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae7b"
    },
    "model_benchmark_id": 1288,
    "analysis_method": "-",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.697414+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.911,
    "score": 0.911,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:13.697414+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae7d"
    },
    "model_benchmark_id": 84,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.259963+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:11.259963+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae7f"
    },
    "model_benchmark_id": 189,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.463251+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-70b-instruct",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
    "updated_at": "2025-07-19T19:56:11.463251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae81"
    },
    "model_benchmark_id": 18,
    "analysis_method": "ARC-C benchmark evaluation",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.121747+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.121747+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae83"
    },
    "model_benchmark_id": 970,
    "analysis_method": "BBH benchmark evaluation",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.040428+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.040428+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae85"
    },
    "model_benchmark_id": 297,
    "analysis_method": "GPQA benchmark evaluation",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.671178+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.495,
    "score": 0.495,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.671178+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae87"
    },
    "model_benchmark_id": 990,
    "analysis_method": "GSM8K benchmark evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.074870+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.959,
    "score": 0.959,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.074870+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae89"
    },
    "model_benchmark_id": 45,
    "analysis_method": "HellaSwag benchmark evaluation",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.178158+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.852,
    "score": 0.852,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.178158+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae8b"
    },
    "model_benchmark_id": 782,
    "analysis_method": "HumanEval benchmark evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.639922+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.639922+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae8d"
    },
    "model_benchmark_id": 1440,
    "analysis_method": "HumanEval+ benchmark evaluation",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.070409+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.524,
    "score": 0.524,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.070409+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae8f"
    },
    "model_benchmark_id": 400,
    "analysis_method": "MATH benchmark evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.856115+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.831,
    "score": 0.831,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.856115+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae91"
    },
    "model_benchmark_id": 1181,
    "analysis_method": "MBPP benchmark evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.489427+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.84,
    "score": 0.84,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.489427+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae93"
    },
    "model_benchmark_id": 1601,
    "analysis_method": "MBPP+ benchmark evaluation",
    "benchmark_id": "mbpp+",
    "benchmark_name": "MBPP+",
    "created_at": "2025-07-19T19:56:14.504915+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.504915+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae95"
    },
    "model_benchmark_id": 85,
    "analysis_method": "MMLU benchmark evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.261705+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.833,
    "score": 0.833,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.261705+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae97"
    },
    "model_benchmark_id": 190,
    "analysis_method": "MMLU-Pro benchmark evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.465052+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.69,
    "score": 0.69,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.465052+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae99"
    },
    "model_benchmark_id": 728,
    "analysis_method": "MMLU-redux benchmark evaluation",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.533630+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.839,
    "score": 0.839,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.533630+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae9b"
    },
    "model_benchmark_id": 1599,
    "analysis_method": "MMLU-STEM benchmark evaluation",
    "benchmark_id": "mmlu-stem",
    "benchmark_name": "MMLU-STEM",
    "created_at": "2025-07-19T19:56:14.498255+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.809,
    "score": 0.809,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.498255+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae9d"
    },
    "model_benchmark_id": 640,
    "analysis_method": "MultiPL-E benchmark evaluation",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.316384+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.316384+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daae9f"
    },
    "model_benchmark_id": 1593,
    "analysis_method": "TheoremQA benchmark evaluation",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.482526+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.441,
    "score": 0.441,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.482526+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaea1"
    },
    "model_benchmark_id": 135,
    "analysis_method": "TruthfulQA benchmark evaluation",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.349397+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.578,
    "score": 0.578,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.349397+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaea3"
    },
    "model_benchmark_id": 150,
    "analysis_method": "Winogrande benchmark evaluation",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.384431+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-32b-instruct",
    "normalized_score": 0.82,
    "score": 0.82,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.384431+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaea5"
    },
    "model_benchmark_id": 19,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.123905+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.123905+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaea7"
    },
    "model_benchmark_id": 1603,
    "analysis_method": "accuracy",
    "benchmark_id": "bigcodebench-full",
    "benchmark_name": "BigCodeBench-Full",
    "created_at": "2025-07-19T19:56:14.511653+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.496,
    "score": 0.496,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.511653+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaea9"
    },
    "model_benchmark_id": 1604,
    "analysis_method": "accuracy",
    "benchmark_id": "bigcodebench-hard",
    "benchmark_name": "BigCodeBench-Hard",
    "created_at": "2025-07-19T19:56:14.515099+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.27,
    "score": 0.27,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.515099+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeab"
    },
    "model_benchmark_id": 991,
    "analysis_method": "accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.076453+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.911,
    "score": 0.911,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.076453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaead"
    },
    "model_benchmark_id": 46,
    "analysis_method": "accuracy",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.180700+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.83,
    "score": 0.83,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.180700+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeaf"
    },
    "model_benchmark_id": 783,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.641672+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.927,
    "score": 0.927,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:12.641672+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeb1"
    },
    "model_benchmark_id": 1117,
    "analysis_method": "pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.329968+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.314,
    "score": 0.314,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.329968+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeb3"
    },
    "model_benchmark_id": 401,
    "analysis_method": "accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.857514+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.857514+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeb5"
    },
    "model_benchmark_id": 1182,
    "analysis_method": "pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.491369+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.491369+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeb7"
    },
    "model_benchmark_id": 86,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.263438+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.263438+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeb9"
    },
    "model_benchmark_id": 191,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.466410+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.504,
    "score": 0.504,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.466410+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaebb"
    },
    "model_benchmark_id": 729,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.535302+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.775,
    "score": 0.775,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:12.535302+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaebd"
    },
    "model_benchmark_id": 1594,
    "analysis_method": "accuracy",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.485084+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.485084+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaebf"
    },
    "model_benchmark_id": 136,
    "analysis_method": "accuracy",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.351250+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.542,
    "score": 0.542,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.351250+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaec1"
    },
    "model_benchmark_id": 1064,
    "analysis_method": "accuracy",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.219435+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-32b-instruct",
    "normalized_score": 0.808,
    "score": 0.808,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.219435+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaec3"
    },
    "model_benchmark_id": 15972,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-08-03T22:06:13.609026+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.573,
    "score": 0.573,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.609026+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaec5"
    },
    "model_benchmark_id": 15973,
    "analysis_method": "Accuracy",
    "benchmark_id": "aime25",
    "benchmark_name": "AIME25",
    "created_at": "2025-08-03T22:06:13.611021+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.611021+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaec7"
    },
    "model_benchmark_id": 15974,
    "analysis_method": "Accuracy",
    "benchmark_id": "arc-agi",
    "benchmark_name": "ARC-AGI",
    "created_at": "2025-08-03T22:06:13.618116+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.418,
    "score": 0.418,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.618116+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaec9"
    },
    "model_benchmark_id": 15975,
    "analysis_method": "Win Rate",
    "benchmark_id": "arena-hard-v2",
    "benchmark_name": "Arena-Hard v2",
    "created_at": "2025-08-03T22:06:13.620187+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.792,
    "score": 0.792,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.620187+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaecb"
    },
    "model_benchmark_id": 15976,
    "analysis_method": "Accuracy",
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-08-03T22:06:13.622144+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.709,
    "score": 0.709,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.622144+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaecd"
    },
    "model_benchmark_id": 15977,
    "analysis_method": "Score",
    "benchmark_id": "creative-writing-v3",
    "benchmark_name": "Creative Writing v3",
    "created_at": "2025-08-03T22:06:13.626065+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.626065+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaecf"
    },
    "model_benchmark_id": 15978,
    "analysis_method": "Accuracy",
    "benchmark_id": "csimpleqa",
    "benchmark_name": "CSimpleQA",
    "created_at": "2025-08-03T22:06:13.629696+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.843,
    "score": 0.843,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.629696+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaed1"
    },
    "model_benchmark_id": 15979,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-08-03T22:06:13.631769+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.775,
    "score": 0.775,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.631769+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaed3"
    },
    "model_benchmark_id": 15980,
    "analysis_method": "Accuracy",
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-08-03T22:06:13.633387+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.554,
    "score": 0.554,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.633387+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaed5"
    },
    "model_benchmark_id": 15981,
    "analysis_method": "Accuracy",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-08-03T22:06:13.635001+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.887,
    "score": 0.887,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.635001+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaed7"
    },
    "model_benchmark_id": 15982,
    "analysis_method": "Score",
    "benchmark_id": "include",
    "benchmark_name": "INCLUDE",
    "created_at": "2025-08-03T22:06:13.636605+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.795,
    "score": 0.795,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.636605+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaed9"
    },
    "model_benchmark_id": 15983,
    "analysis_method": "Accuracy",
    "benchmark_id": "livebench-20241125",
    "benchmark_name": "LiveBench 20241125",
    "created_at": "2025-08-03T22:06:13.638166+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.638166+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaedb"
    },
    "model_benchmark_id": 15984,
    "analysis_method": "Accuracy",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-08-03T22:06:13.639661+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.518,
    "score": 0.518,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.639661+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaedd"
    },
    "model_benchmark_id": 15985,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-08-03T22:06:13.641236+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.83,
    "score": 0.83,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.641236+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaedf"
    },
    "model_benchmark_id": 15986,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-08-03T22:06:13.642908+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.794,
    "score": 0.794,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.642908+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaee1"
    },
    "model_benchmark_id": 15987,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-08-03T22:06:13.644630+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.931,
    "score": 0.931,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.644630+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaee3"
    },
    "model_benchmark_id": 15988,
    "analysis_method": "Accuracy",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-08-03T22:06:13.646355+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.775,
    "score": 0.775,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.646355+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaee5"
    },
    "model_benchmark_id": 15989,
    "analysis_method": "Score",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-08-03T22:06:13.648211+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.879,
    "score": 0.879,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.648211+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaee7"
    },
    "model_benchmark_id": 15990,
    "analysis_method": "Accuracy",
    "benchmark_id": "polymath",
    "benchmark_name": "PolyMATH",
    "created_at": "2025-08-03T22:06:13.649756+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.502,
    "score": 0.502,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.649756+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaee9"
    },
    "model_benchmark_id": 15991,
    "analysis_method": "Accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-08-03T22:06:13.651445+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.543,
    "score": 0.543,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.651445+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeeb"
    },
    "model_benchmark_id": 15992,
    "analysis_method": "Accuracy",
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-08-03T22:06:13.652980+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.626,
    "score": 0.626,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.652980+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeed"
    },
    "model_benchmark_id": 15993,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau2-airline",
    "benchmark_name": "Tau2 airline",
    "created_at": "2025-08-03T22:06:13.654737+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.44,
    "score": 0.44,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.654737+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeef"
    },
    "model_benchmark_id": 15994,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau2-retail",
    "benchmark_name": "Tau2 retail",
    "created_at": "2025-08-03T22:06:13.656359+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.713,
    "score": 0.713,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.656359+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaef1"
    },
    "model_benchmark_id": 15995,
    "analysis_method": "Accuracy",
    "benchmark_id": "writingbench",
    "benchmark_name": "WritingBench",
    "created_at": "2025-08-03T22:06:13.657968+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.852,
    "score": 0.852,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.657968+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaef3"
    },
    "model_benchmark_id": 15996,
    "analysis_method": "Accuracy",
    "benchmark_id": "zebralogic",
    "benchmark_name": "ZebraLogic",
    "created_at": "2025-08-03T22:06:13.659618+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-instruct-2507",
    "normalized_score": 0.95,
    "score": 0.95,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507",
    "updated_at": "2025-08-03T22:06:13.659618+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaef5"
    },
    "model_benchmark_id": 451,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.957773+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.795,
    "score": 0.795,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b/",
    "updated_at": "2025-07-19T19:56:11.957773+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaef7"
    },
    "model_benchmark_id": 849,
    "analysis_method": "accuracy",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.777209+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.664,
    "score": 0.664,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b/",
    "updated_at": "2025-07-19T19:56:12.777209+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaef9"
    },
    "model_benchmark_id": 298,
    "analysis_method": "Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.672880+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.652,
    "score": 0.652,
    "self_reported_source_link": "https://qwen-ai.com/qwq-32b/",
    "updated_at": "2025-07-19T19:56:11.672880+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaefb"
    },
    "model_benchmark_id": 619,
    "analysis_method": "accuracy",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.275723+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.839,
    "score": 0.839,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b/",
    "updated_at": "2025-07-19T19:56:12.275723+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaefd"
    },
    "model_benchmark_id": 747,
    "analysis_method": "accuracy",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.570952+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.731,
    "score": 0.731,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b/",
    "updated_at": "2025-07-19T19:56:12.570952+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaeff"
    },
    "model_benchmark_id": 1118,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.332752+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.634,
    "score": 0.634,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b/",
    "updated_at": "2025-07-19T19:56:13.332752+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf01"
    },
    "model_benchmark_id": 495,
    "analysis_method": "accuracy",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.034467+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b",
    "normalized_score": 0.906,
    "score": 0.906,
    "self_reported_source_link": "https://qwen-ai.com/qwq-32b/",
    "updated_at": "2025-07-19T19:56:12.034467+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf03"
    },
    "model_benchmark_id": 9101,
    "analysis_method": null,
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.844,
    "score": 0.844,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf05"
    },
    "model_benchmark_id": 9102,
    "analysis_method": null,
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.938,
    "score": 0.938,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf07"
    },
    "model_benchmark_id": 9103,
    "analysis_method": null,
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf09"
    },
    "model_benchmark_id": 9104,
    "analysis_method": null,
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf0b"
    },
    "model_benchmark_id": 9105,
    "analysis_method": null,
    "benchmark_id": "aime25",
    "benchmark_name": "AIME25",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf0d"
    },
    "model_benchmark_id": 9106,
    "analysis_method": null,
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.839,
    "score": 0.839,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf0f"
    },
    "model_benchmark_id": 9107,
    "analysis_method": null,
    "benchmark_id": "livebench-20241125",
    "benchmark_name": "LiveBench 20241125",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.784,
    "score": 0.784,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf11"
    },
    "model_benchmark_id": 9108,
    "analysis_method": "text-only subset",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "HLE",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.182,
    "score": 0.182,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Score refers to text-only subset as model is not multi-modal",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf13"
    },
    "model_benchmark_id": 9109,
    "analysis_method": "25.02-25.05",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.741,
    "score": 0.741,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf15"
    },
    "model_benchmark_id": 9110,
    "analysis_method": null,
    "benchmark_id": "cfeval",
    "benchmark_name": "CFEval",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.2134,
    "score": 2134,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Raw score: 2134",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf17"
    },
    "model_benchmark_id": 9111,
    "analysis_method": null,
    "benchmark_id": "ojbench",
    "benchmark_name": "OJBench",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.325,
    "score": 0.325,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf19"
    },
    "model_benchmark_id": 9112,
    "analysis_method": null,
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf1b"
    },
    "model_benchmark_id": 9113,
    "analysis_method": "GPT-4 evaluated win rates",
    "benchmark_id": "arena-hard-v2",
    "benchmark_name": "Arena-Hard v2",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf1d"
    },
    "model_benchmark_id": 9114,
    "analysis_method": null,
    "benchmark_id": "creative-writing-v3",
    "benchmark_name": "Creative Writing v3",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.861,
    "score": 0.861,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf1f"
    },
    "model_benchmark_id": 9115,
    "analysis_method": null,
    "benchmark_id": "writingbench",
    "benchmark_name": "WritingBench",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.883,
    "score": 0.883,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf21"
    },
    "model_benchmark_id": 9116,
    "analysis_method": null,
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.719,
    "score": 0.719,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf23"
    },
    "model_benchmark_id": 9117,
    "analysis_method": null,
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU1-Retail",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.678,
    "score": 0.678,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Retail",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf25"
    },
    "model_benchmark_id": 9118,
    "analysis_method": null,
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU1-Airline",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.46,
    "score": 0.46,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Airline",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf27"
    },
    "model_benchmark_id": 9119,
    "analysis_method": null,
    "benchmark_id": "tau2-retail",
    "benchmark_name": "TAU2-Retail",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.719,
    "score": 0.719,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf29"
    },
    "model_benchmark_id": 9120,
    "analysis_method": null,
    "benchmark_id": "tau2-airline",
    "benchmark_name": "TAU2-Airline",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.58,
    "score": 0.58,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf2b"
    },
    "model_benchmark_id": 9121,
    "analysis_method": null,
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "TAU2-Telecom",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.456,
    "score": 0.456,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf2d"
    },
    "model_benchmark_id": 9122,
    "analysis_method": null,
    "benchmark_id": "multi-if",
    "benchmark_name": "MultiIF",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.806,
    "score": 0.806,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MultiIF",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf2f"
    },
    "model_benchmark_id": 9123,
    "analysis_method": null,
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MMLU-ProX",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf31"
    },
    "model_benchmark_id": 9124,
    "analysis_method": null,
    "benchmark_id": "include",
    "benchmark_name": "INCLUDE",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf33"
    },
    "model_benchmark_id": 9125,
    "analysis_method": null,
    "benchmark_id": "polymath",
    "benchmark_name": "PolyMATH",
    "created_at": "2025-07-25T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b-thinking-2507",
    "normalized_score": 0.601,
    "score": 0.601,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-thinking/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf35"
    },
    "model_benchmark_id": 1616,
    "analysis_method": "Score",
    "benchmark_id": "alignbench",
    "benchmark_name": "AlignBench",
    "created_at": "2025-07-19T19:56:14.544441+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.721,
    "score": 0.721,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.544441+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf37"
    },
    "model_benchmark_id": 436,
    "analysis_method": "Accuracy",
    "benchmark_id": "c-eval",
    "benchmark_name": "C-Eval",
    "created_at": "2025-07-19T19:56:11.924104+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.772,
    "score": 0.772,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.924104+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf39"
    },
    "model_benchmark_id": 370,
    "analysis_method": "Pass@1",
    "benchmark_id": "evalplus",
    "benchmark_name": "EvalPlus",
    "created_at": "2025-07-19T19:56:11.799094+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.799094+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf3b"
    },
    "model_benchmark_id": 299,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.674412+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.253,
    "score": 0.253,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.674412+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf3d"
    },
    "model_benchmark_id": 992,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.078833+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.823,
    "score": 0.823,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:13.078833+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf3f"
    },
    "model_benchmark_id": 784,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.643272+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.799,
    "score": 0.799,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.643272+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf41"
    },
    "model_benchmark_id": 1119,
    "analysis_method": "Score",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.335377+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.266,
    "score": 0.266,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:13.335377+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf43"
    },
    "model_benchmark_id": 402,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.859120+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.496,
    "score": 0.496,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.859120+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf45"
    },
    "model_benchmark_id": 1183,
    "analysis_method": "Pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.493272+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:13.493272+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf47"
    },
    "model_benchmark_id": 87,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.265352+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.265352+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf49"
    },
    "model_benchmark_id": 192,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.467957+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.441,
    "score": 0.441,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:11.467957+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf4b"
    },
    "model_benchmark_id": 1605,
    "analysis_method": "Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.519120+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.519120+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf4d"
    },
    "model_benchmark_id": 641,
    "analysis_method": "Pass@1",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.317803+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.591,
    "score": 0.591,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.317803+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf4f"
    },
    "model_benchmark_id": 1595,
    "analysis_method": "Accuracy",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.487702+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-7b-instruct",
    "normalized_score": 0.253,
    "score": 0.253,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.487702+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf51"
    },
    "model_benchmark_id": 452,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.959852+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b-preview",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b-preview/",
    "updated_at": "2025-07-19T19:56:11.959852+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf53"
    },
    "model_benchmark_id": 300,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.675997+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b-preview",
    "normalized_score": 0.652,
    "score": 0.652,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b-preview/",
    "updated_at": "2025-07-19T19:56:11.675997+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf55"
    },
    "model_benchmark_id": 1120,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.337401+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b-preview",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b-preview/",
    "updated_at": "2025-07-19T19:56:13.337401+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf57"
    },
    "model_benchmark_id": 496,
    "analysis_method": "accuracy",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.036449+00:00",
    "is_self_reported": true,
    "model_id": "qwq-32b-preview",
    "normalized_score": 0.906,
    "score": 0.906,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwq-32b-preview/",
    "updated_at": "2025-07-19T19:56:12.036449+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf59"
    },
    "model_benchmark_id": 9201,
    "analysis_method": null,
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.827,
    "score": 0.827,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf5b"
    },
    "model_benchmark_id": 9202,
    "analysis_method": null,
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.925,
    "score": 0.925,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf5d"
    },
    "model_benchmark_id": 9203,
    "analysis_method": null,
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.772,
    "score": 0.772,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf5f"
    },
    "model_benchmark_id": 9204,
    "analysis_method": null,
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf61"
    },
    "model_benchmark_id": 9205,
    "analysis_method": null,
    "benchmark_id": "aime25",
    "benchmark_name": "AIME25",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf63"
    },
    "model_benchmark_id": 9206,
    "analysis_method": null,
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.739,
    "score": 0.739,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf65"
    },
    "model_benchmark_id": 9207,
    "analysis_method": null,
    "benchmark_id": "livebench-20241125",
    "benchmark_name": "LiveBench 241125",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf67"
    },
    "model_benchmark_id": 9208,
    "analysis_method": "25.02-25.05",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.687,
    "score": 0.687,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf69"
    },
    "model_benchmark_id": 9209,
    "analysis_method": null,
    "benchmark_id": "cfeval",
    "benchmark_name": "CFEval",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.2071,
    "score": 2071,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Raw score: 2071",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf6b"
    },
    "model_benchmark_id": 9210,
    "analysis_method": null,
    "benchmark_id": "ojbench",
    "benchmark_name": "OJBench",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.297,
    "score": 0.297,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf6d"
    },
    "model_benchmark_id": 9211,
    "analysis_method": null,
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.889,
    "score": 0.889,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf6f"
    },
    "model_benchmark_id": 9212,
    "analysis_method": "GPT-4.1 evaluated win rates",
    "benchmark_id": "arena-hard-v2",
    "benchmark_name": "Arena-Hard v2",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.623,
    "score": 0.623,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf71"
    },
    "model_benchmark_id": 9213,
    "analysis_method": null,
    "benchmark_id": "writingbench",
    "benchmark_name": "WritingBench",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf73"
    },
    "model_benchmark_id": 9214,
    "analysis_method": null,
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf75"
    },
    "model_benchmark_id": 9215,
    "analysis_method": null,
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU1-Retail",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Retail",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf77"
    },
    "model_benchmark_id": 9216,
    "analysis_method": null,
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU1-Airline",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.49,
    "score": 0.49,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Airline",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf79"
    },
    "model_benchmark_id": 9217,
    "analysis_method": null,
    "benchmark_id": "tau2-retail",
    "benchmark_name": "TAU2-Retail",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.678,
    "score": 0.678,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf7b"
    },
    "model_benchmark_id": 9218,
    "analysis_method": null,
    "benchmark_id": "tau2-airline",
    "benchmark_name": "TAU2-Airline",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.605,
    "score": 0.605,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf7d"
    },
    "model_benchmark_id": 9219,
    "analysis_method": null,
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "TAU2-Telecom",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.439,
    "score": 0.439,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf7f"
    },
    "model_benchmark_id": 9220,
    "analysis_method": null,
    "benchmark_id": "multi-if",
    "benchmark_name": "MultiIF",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MultiIF",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf81"
    },
    "model_benchmark_id": 9221,
    "analysis_method": null,
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.787,
    "score": 0.787,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MMLU-ProX",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf83"
    },
    "model_benchmark_id": 9222,
    "analysis_method": null,
    "benchmark_id": "include",
    "benchmark_name": "INCLUDE",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf85"
    },
    "model_benchmark_id": 9223,
    "analysis_method": null,
    "benchmark_id": "polymath",
    "benchmark_name": "PolyMATH",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-thinking",
    "normalized_score": 0.563,
    "score": 0.563,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf87"
    },
    "model_benchmark_id": 1624,
    "analysis_method": "pass@1",
    "benchmark_id": "aider",
    "benchmark_name": "Aider",
    "created_at": "2025-07-19T19:56:14.569369+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.556,
    "score": 0.556,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.569369+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf89"
    },
    "model_benchmark_id": 20,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.126002+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.609,
    "score": 0.609,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.126002+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf8b"
    },
    "model_benchmark_id": 1434,
    "analysis_method": "accuracy",
    "benchmark_id": "bigcodebench",
    "benchmark_name": "BigCodeBench",
    "created_at": "2025-07-19T19:56:14.052666+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.41,
    "score": 0.41,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.052666+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf8d"
    },
    "model_benchmark_id": 1620,
    "analysis_method": "accuracy",
    "benchmark_id": "cruxeval-input-cot",
    "benchmark_name": "CRUXEval-Input-CoT",
    "created_at": "2025-07-19T19:56:14.554528+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.565,
    "score": 0.565,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.554528+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf8f"
    },
    "model_benchmark_id": 1621,
    "analysis_method": "accuracy",
    "benchmark_id": "cruxeval-output-cot",
    "benchmark_name": "CRUXEval-Output-CoT",
    "created_at": "2025-07-19T19:56:14.558251+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.56,
    "score": 0.56,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.558251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf91"
    },
    "model_benchmark_id": 993,
    "analysis_method": "accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.080381+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.839,
    "score": 0.839,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.080381+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf93"
    },
    "model_benchmark_id": 47,
    "analysis_method": "accuracy",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.182466+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.768,
    "score": 0.768,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.182466+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf95"
    },
    "model_benchmark_id": 785,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.644936+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:12.644936+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf97"
    },
    "model_benchmark_id": 1121,
    "analysis_method": "pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.340042+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.182,
    "score": 0.182,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.340042+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf99"
    },
    "model_benchmark_id": 403,
    "analysis_method": "accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.860821+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.466,
    "score": 0.466,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.860821+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf9b"
    },
    "model_benchmark_id": 1184,
    "analysis_method": "pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.495284+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.835,
    "score": 0.835,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.495284+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf9d"
    },
    "model_benchmark_id": 88,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.267319+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.676,
    "score": 0.676,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.267319+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaf9f"
    },
    "model_benchmark_id": 1623,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-base",
    "benchmark_name": "MMLU-Base",
    "created_at": "2025-07-19T19:56:14.565292+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.565292+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafa1"
    },
    "model_benchmark_id": 193,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.469384+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.401,
    "score": 0.401,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.469384+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafa3"
    },
    "model_benchmark_id": 730,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.537049+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.666,
    "score": 0.666,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:12.537049+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafa5"
    },
    "model_benchmark_id": 1622,
    "analysis_method": "accuracy",
    "benchmark_id": "stem",
    "benchmark_name": "STEM",
    "created_at": "2025-07-19T19:56:14.561469+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.34,
    "score": 0.34,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.561469+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafa7"
    },
    "model_benchmark_id": 1596,
    "analysis_method": "accuracy",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.489921+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.34,
    "score": 0.34,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:14.489921+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafa9"
    },
    "model_benchmark_id": 137,
    "analysis_method": "accuracy",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.353301+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.506,
    "score": 0.506,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:11.353301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafab"
    },
    "model_benchmark_id": 1065,
    "analysis_method": "accuracy",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:13.221874+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-coder-7b-instruct",
    "normalized_score": 0.729,
    "score": 0.729,
    "self_reported_source_link": "https://arxiv.org/abs/2409.12186",
    "updated_at": "2025-07-19T19:56:13.221874+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafad"
    },
    "model_benchmark_id": 21,
    "analysis_method": "ARC-C benchmark evaluation",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.127541+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.673,
    "score": 0.673,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.127541+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafaf"
    },
    "model_benchmark_id": 971,
    "analysis_method": "BBH benchmark evaluation",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.042167+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.782,
    "score": 0.782,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.042167+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafb1"
    },
    "model_benchmark_id": 301,
    "analysis_method": "GPQA benchmark evaluation",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.677954+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.455,
    "score": 0.455,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.677954+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafb3"
    },
    "model_benchmark_id": 994,
    "analysis_method": "GSM8K benchmark evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.082212+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.948,
    "score": 0.948,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.082212+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafb5"
    },
    "model_benchmark_id": 786,
    "analysis_method": "HumanEval benchmark evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.646500+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.835,
    "score": 0.835,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.646500+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafb7"
    },
    "model_benchmark_id": 1441,
    "analysis_method": "HumanEval+ benchmark evaluation",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.071967+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.512,
    "score": 0.512,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.071967+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafb9"
    },
    "model_benchmark_id": 404,
    "analysis_method": "MATH benchmark evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.862254+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.862254+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafbb"
    },
    "model_benchmark_id": 1185,
    "analysis_method": "MBPP benchmark evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.497488+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.82,
    "score": 0.82,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.497488+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafbd"
    },
    "model_benchmark_id": 1602,
    "analysis_method": "MBPP+ benchmark evaluation",
    "benchmark_id": "mbpp+",
    "benchmark_name": "MBPP+",
    "created_at": "2025-07-19T19:56:14.507421+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.632,
    "score": 0.632,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.507421+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafbf"
    },
    "model_benchmark_id": 89,
    "analysis_method": "MMLU benchmark evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.269091+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.269091+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafc1"
    },
    "model_benchmark_id": 194,
    "analysis_method": "MMLU-Pro benchmark evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.471047+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.637,
    "score": 0.637,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.471047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafc3"
    },
    "model_benchmark_id": 731,
    "analysis_method": "MMLU-redux benchmark evaluation",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.538944+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.538944+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafc5"
    },
    "model_benchmark_id": 1600,
    "analysis_method": "MMLU-STEM benchmark evaluation",
    "benchmark_id": "mmlu-stem",
    "benchmark_name": "MMLU-STEM",
    "created_at": "2025-07-19T19:56:14.500528+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.500528+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafc7"
    },
    "model_benchmark_id": 642,
    "analysis_method": "MultiPL-E benchmark evaluation",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.319213+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.728,
    "score": 0.728,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.319213+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafc9"
    },
    "model_benchmark_id": 1597,
    "analysis_method": "TheoremQA benchmark evaluation",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.492163+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.43,
    "score": 0.43,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.492163+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafcb"
    },
    "model_benchmark_id": 138,
    "analysis_method": "TruthfulQA benchmark evaluation",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.355004+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-14b-instruct",
    "normalized_score": 0.584,
    "score": 0.584,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.355004+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafcd"
    },
    "model_benchmark_id": 864,
    "analysis_method": "score",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.806635+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.883,
    "score": 0.883,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:12.806635+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafcf"
    },
    "model_benchmark_id": 1629,
    "analysis_method": "score",
    "benchmark_id": "docvqatest",
    "benchmark_name": "DocVQAtest",
    "created_at": "2025-07-19T19:56:14.582058+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.965,
    "score": 0.965,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.582058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafd1"
    },
    "model_benchmark_id": 923,
    "analysis_method": "score",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.928297+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.779,
    "score": 0.779,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:12.928297+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafd3"
    },
    "model_benchmark_id": 1630,
    "analysis_method": "score",
    "benchmark_id": "infovqatest",
    "benchmark_name": "InfoVQAtest",
    "created_at": "2025-07-19T19:56:14.586477+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.586477+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafd5"
    },
    "model_benchmark_id": 1269,
    "analysis_method": "score",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.662750+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:13.662750+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafd7"
    },
    "model_benchmark_id": 1639,
    "analysis_method": "score",
    "benchmark_id": "mmbench-test",
    "benchmark_name": "MMBench_test",
    "created_at": "2025-07-19T19:56:14.610292+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.610292+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafd9"
    },
    "model_benchmark_id": 1532,
    "analysis_method": "score",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.292395+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.462,
    "score": 0.462,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.292395+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafdb"
    },
    "model_benchmark_id": 1628,
    "analysis_method": "score",
    "benchmark_id": "mmmuval",
    "benchmark_name": "MMMUval",
    "created_at": "2025-07-19T19:56:14.578458+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.645,
    "score": 0.645,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.578458+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafdd"
    },
    "model_benchmark_id": 1640,
    "analysis_method": "score",
    "benchmark_id": "mmvetgpt4turbo",
    "benchmark_name": "MMVetGPT4Turbo",
    "created_at": "2025-07-19T19:56:14.613913+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.74,
    "score": 0.74,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.613913+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafdf"
    },
    "model_benchmark_id": 1631,
    "analysis_method": "score",
    "benchmark_id": "mtvqa",
    "benchmark_name": "MTVQA",
    "created_at": "2025-07-19T19:56:14.590936+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.309,
    "score": 0.309,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.590936+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafe1"
    },
    "model_benchmark_id": 1641,
    "analysis_method": "score",
    "benchmark_id": "mvbench",
    "benchmark_name": "MVBench",
    "created_at": "2025-07-19T19:56:14.618622+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.736,
    "score": 0.736,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.618622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafe3"
    },
    "model_benchmark_id": 1539,
    "analysis_method": "score",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.311748+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.877,
    "score": 0.877,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.311748+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafe5"
    },
    "model_benchmark_id": 1633,
    "analysis_method": "score",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.597450+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.597450+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafe7"
    },
    "model_benchmark_id": 909,
    "analysis_method": "score",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.894922+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.855,
    "score": 0.855,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:12.894922+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafe9"
    },
    "model_benchmark_id": 1632,
    "analysis_method": "score",
    "benchmark_id": "vcr-en-easy",
    "benchmark_name": "VCR_en_easy",
    "created_at": "2025-07-19T19:56:14.594379+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-vl-72b",
    "normalized_score": 0.9193,
    "score": 0.9193,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2",
    "updated_at": "2025-07-19T19:56:14.594379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafeb"
    },
    "model_benchmark_id": 1625,
    "analysis_method": "Pass@2",
    "benchmark_id": "aider",
    "benchmark_name": "Aider",
    "created_at": "2025-07-19T19:56:14.571165+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.502,
    "score": 0.502,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.571165+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafed"
    },
    "model_benchmark_id": 453,
    "analysis_method": "Pass@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.961658+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.961658+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafef"
    },
    "model_benchmark_id": 689,
    "analysis_method": "Pass@64",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.446075+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.729,
    "score": 0.729,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.446075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaff1"
    },
    "model_benchmark_id": 1451,
    "analysis_method": "Accuracy",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.093495+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.938,
    "score": 0.938,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.093495+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaff3"
    },
    "model_benchmark_id": 850,
    "analysis_method": "v3",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.778924+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.778924+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaff5"
    },
    "model_benchmark_id": 1645,
    "analysis_method": "Elo Rating",
    "benchmark_id": "codeforces",
    "benchmark_name": "CodeForces",
    "created_at": "2025-07-19T19:56:14.627279+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.659,
    "score": 0.659,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.627279+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaff7"
    },
    "model_benchmark_id": 748,
    "analysis_method": "Accuracy",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.573432+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.573432+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaff9"
    },
    "model_benchmark_id": 1122,
    "analysis_method": "v5",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.342304+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.657,
    "score": 0.657,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.342304+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaffb"
    },
    "model_benchmark_id": 1646,
    "analysis_method": "Accuracy",
    "benchmark_id": "multilf",
    "benchmark_name": "MultiLF",
    "created_at": "2025-07-19T19:56:14.630716+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-32b",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.630716+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daaffd"
    },
    "model_benchmark_id": 1626,
    "analysis_method": "Pass@2",
    "benchmark_id": "aider",
    "benchmark_name": "Aider",
    "created_at": "2025-07-19T19:56:14.572970+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.618,
    "score": 0.618,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.572970+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5daafff"
    },
    "model_benchmark_id": 454,
    "analysis_method": "Pass@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.963641+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.963641+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab001"
    },
    "model_benchmark_id": 690,
    "analysis_method": "Pass@64",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.447678+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.815,
    "score": 0.815,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.447678+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab003"
    },
    "model_benchmark_id": 1452,
    "analysis_method": "Accuracy",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.095282+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.956,
    "score": 0.956,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.095282+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab005"
    },
    "model_benchmark_id": 972,
    "analysis_method": "Accuracy",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.043683+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.8887,
    "score": 0.8887,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.043683+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab007"
    },
    "model_benchmark_id": 851,
    "analysis_method": "v3",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.780457+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.780457+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab009"
    },
    "model_benchmark_id": 1648,
    "analysis_method": "Score",
    "benchmark_id": "crux-o",
    "benchmark_name": "CRUX-O",
    "created_at": "2025-07-19T19:56:14.637715+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.637715+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab00b"
    },
    "model_benchmark_id": 371,
    "analysis_method": "Score",
    "benchmark_id": "evalplus",
    "benchmark_name": "EvalPlus",
    "created_at": "2025-07-19T19:56:11.801301+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.801301+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab00d"
    },
    "model_benchmark_id": 302,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.679464+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.4747,
    "score": 0.4747,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.679464+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab00f"
    },
    "model_benchmark_id": 995,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.083824+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.9439,
    "score": 0.9439,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.083824+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab011"
    },
    "model_benchmark_id": 1308,
    "analysis_method": "Score",
    "benchmark_id": "include",
    "benchmark_name": "Include",
    "created_at": "2025-07-19T19:56:13.737543+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.7346,
    "score": 0.7346,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.737543+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab013"
    },
    "model_benchmark_id": 749,
    "analysis_method": "Accuracy",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.575629+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.771,
    "score": 0.771,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.575629+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab015"
    },
    "model_benchmark_id": 1123,
    "analysis_method": "v5",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.344206+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.344206+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab017"
    },
    "model_benchmark_id": 405,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.863985+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.7184,
    "score": 0.7184,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.863985+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab019"
    },
    "model_benchmark_id": 1186,
    "analysis_method": "Accuracy",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.500617+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.500617+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab01b"
    },
    "model_benchmark_id": 1289,
    "analysis_method": "Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.700097+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.8353,
    "score": 0.8353,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.700097+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab01d"
    },
    "model_benchmark_id": 90,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.270963+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.8781,
    "score": 0.8781,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.270963+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab01f"
    },
    "model_benchmark_id": 195,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.472627+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.6818,
    "score": 0.6818,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.472627+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab021"
    },
    "model_benchmark_id": 732,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.540685+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.874,
    "score": 0.874,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.540685+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab023"
    },
    "model_benchmark_id": 1477,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.150792+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.867,
    "score": 0.867,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.150792+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab025"
    },
    "model_benchmark_id": 1647,
    "analysis_method": "Accuracy",
    "benchmark_id": "multilf",
    "benchmark_name": "MultiLF",
    "created_at": "2025-07-19T19:56:14.633963+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.719,
    "score": 0.719,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.633963+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab027"
    },
    "model_benchmark_id": 643,
    "analysis_method": "Score",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.320821+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.6594,
    "score": 0.6594,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.320821+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab029"
    },
    "model_benchmark_id": 366,
    "analysis_method": "Accuracy",
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-07-19T19:56:11.784624+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-235b-a22b",
    "normalized_score": 0.4406,
    "score": 0.4406,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.784624+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab02b"
    },
    "model_benchmark_id": 1617,
    "analysis_method": "AlignBench v1.1 benchmark evaluation",
    "benchmark_id": "alignbench",
    "benchmark_name": "AlignBench",
    "created_at": "2025-07-19T19:56:14.546122+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:14.546122+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab02d"
    },
    "model_benchmark_id": 1453,
    "analysis_method": "Arena Hard benchmark evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.097075+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:14.097075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab02f"
    },
    "model_benchmark_id": 303,
    "analysis_method": "GPQA benchmark evaluation",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.681073+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.49,
    "score": 0.49,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:11.681073+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab031"
    },
    "model_benchmark_id": 996,
    "analysis_method": "GSM8K benchmark evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.085236+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.958,
    "score": 0.958,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:13.085236+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab033"
    },
    "model_benchmark_id": 787,
    "analysis_method": "HumanEval benchmark evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.648406+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.866,
    "score": 0.866,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:12.648406+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab035"
    },
    "model_benchmark_id": 620,
    "analysis_method": "IFEval strict-prompt benchmark evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.277303+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:12.277303+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab037"
    },
    "model_benchmark_id": 750,
    "analysis_method": "LiveBench benchmark evaluation",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.577555+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.523,
    "score": 0.523,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:12.577555+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab039"
    },
    "model_benchmark_id": 1124,
    "analysis_method": "LiveCodeBench benchmark evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.346315+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.555,
    "score": 0.555,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:13.346315+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab03b"
    },
    "model_benchmark_id": 406,
    "analysis_method": "MATH benchmark evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.865721+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.831,
    "score": 0.831,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:11.865721+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab03d"
    },
    "model_benchmark_id": 1187,
    "analysis_method": "MBPP benchmark evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.503069+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.882,
    "score": 0.882,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:13.503069+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab03f"
    },
    "model_benchmark_id": 196,
    "analysis_method": "MMLU-Pro benchmark evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.475182+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.711,
    "score": 0.711,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.475182+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab041"
    },
    "model_benchmark_id": 733,
    "analysis_method": "MMLU-redux benchmark evaluation",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.542364+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:12.542364+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab043"
    },
    "model_benchmark_id": 1606,
    "analysis_method": "MT-bench benchmark evaluation",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.521232+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.935,
    "score": 0.935,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:14.521232+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab045"
    },
    "model_benchmark_id": 644,
    "analysis_method": "MultiPL-E benchmark evaluation",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.322800+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-72b-instruct",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5/",
    "updated_at": "2025-07-19T19:56:12.322800+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab047"
    },
    "model_benchmark_id": 455,
    "analysis_method": "Accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.965575+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.965575+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab049"
    },
    "model_benchmark_id": 691,
    "analysis_method": "Accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.449947+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.709,
    "score": 0.709,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.449947+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab04b"
    },
    "model_benchmark_id": 1454,
    "analysis_method": "Accuracy",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.098594+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.91,
    "score": 0.91,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.098594+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab04d"
    },
    "model_benchmark_id": 852,
    "analysis_method": "v3",
    "benchmark_id": "bfcl",
    "benchmark_name": "BFCL",
    "created_at": "2025-07-19T19:56:12.782049+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.691,
    "score": 0.691,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.782049+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab04f"
    },
    "model_benchmark_id": 304,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.682771+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:11.682771+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab051"
    },
    "model_benchmark_id": 751,
    "analysis_method": "Accuracy",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.579527+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:12.579527+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab053"
    },
    "model_benchmark_id": 1125,
    "analysis_method": "v5",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.349221+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.626,
    "score": 0.626,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:13.349221+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab055"
    },
    "model_benchmark_id": 1649,
    "analysis_method": "Accuracy",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.641584+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-30b-a3b",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3/",
    "updated_at": "2025-07-19T19:56:14.641584+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab057"
    },
    "model_benchmark_id": 1702,
    "analysis_method": "EM",
    "benchmark_id": "aitz-em",
    "benchmark_name": "AITZ_EM",
    "created_at": "2025-07-19T19:56:14.787781+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.819,
    "score": 0.819,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.787781+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab059"
    },
    "model_benchmark_id": 1705,
    "analysis_method": "EM",
    "benchmark_id": "android-control-high-em",
    "benchmark_name": "Android Control High_EM",
    "created_at": "2025-07-19T19:56:14.794879+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.601,
    "score": 0.601,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.794879+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab05b"
    },
    "model_benchmark_id": 1708,
    "analysis_method": "EM",
    "benchmark_id": "android-control-low-em",
    "benchmark_name": "Android Control Low_EM",
    "created_at": "2025-07-19T19:56:14.803305+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.914,
    "score": 0.914,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.803305+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab05d"
    },
    "model_benchmark_id": 1711,
    "analysis_method": "SR",
    "benchmark_id": "androidworld-sr",
    "benchmark_name": "AndroidWorld_SR",
    "created_at": "2025-07-19T19:56:14.811782+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.255,
    "score": 0.255,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.811782+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab05f"
    },
    "model_benchmark_id": 1656,
    "analysis_method": "Score",
    "benchmark_id": "cc-ocr",
    "benchmark_name": "CC-OCR",
    "created_at": "2025-07-19T19:56:14.655251+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.655251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab061"
    },
    "model_benchmark_id": 1694,
    "analysis_method": "mIoU",
    "benchmark_id": "charadessta",
    "benchmark_name": "CharadesSTA",
    "created_at": "2025-07-19T19:56:14.763802+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.436,
    "score": 0.436,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.763802+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab063"
    },
    "model_benchmark_id": 865,
    "analysis_method": "Score",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.808329+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.873,
    "score": 0.873,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.808329+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab065"
    },
    "model_benchmark_id": 886,
    "analysis_method": "Score",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.844347+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.957,
    "score": 0.957,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.844347+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab067"
    },
    "model_benchmark_id": 1672,
    "analysis_method": "Score",
    "benchmark_id": "hallusion-bench",
    "benchmark_name": "Hallusion Bench",
    "created_at": "2025-07-19T19:56:14.693096+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.529,
    "score": 0.529,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.693096+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab069"
    },
    "model_benchmark_id": 1242,
    "analysis_method": "Score",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.610945+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:13.610945+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab06b"
    },
    "model_benchmark_id": 1687,
    "analysis_method": "Score",
    "benchmark_id": "longvideobench",
    "benchmark_name": "LongVideoBench",
    "created_at": "2025-07-19T19:56:14.737450+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.547,
    "score": 0.547,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.737450+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab06d"
    },
    "model_benchmark_id": 828,
    "analysis_method": "Score",
    "benchmark_id": "lvbench",
    "benchmark_name": "LVBench",
    "created_at": "2025-07-19T19:56:12.729778+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.453,
    "score": 0.453,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.729778+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab06f"
    },
    "model_benchmark_id": 1674,
    "analysis_method": "Score",
    "benchmark_id": "mathvision",
    "benchmark_name": "MathVision",
    "created_at": "2025-07-19T19:56:14.698748+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.2507,
    "score": 0.2507,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.698748+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab071"
    },
    "model_benchmark_id": 1270,
    "analysis_method": "Score",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.664381+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.682,
    "score": 0.682,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:13.664381+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab073"
    },
    "model_benchmark_id": 1693,
    "analysis_method": "Score",
    "benchmark_id": "mlvu",
    "benchmark_name": "MLVU",
    "created_at": "2025-07-19T19:56:14.758833+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.758833+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab075"
    },
    "model_benchmark_id": 1511,
    "analysis_method": "Score",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.241869+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.843,
    "score": 0.843,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.241869+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab077"
    },
    "model_benchmark_id": 1688,
    "analysis_method": "Score",
    "benchmark_id": "mmbench-video",
    "benchmark_name": "MMBench-Video",
    "created_at": "2025-07-19T19:56:14.742467+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.0179,
    "score": 0.0179,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.742467+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab079"
    },
    "model_benchmark_id": 569,
    "analysis_method": "Score",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.170987+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.586,
    "score": 0.586,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.170987+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab07b"
    },
    "model_benchmark_id": 1533,
    "analysis_method": "Score",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.294582+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.383,
    "score": 0.383,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.294582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab07d"
    },
    "model_benchmark_id": 1659,
    "analysis_method": "Score",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.662888+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.639,
    "score": 0.639,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.662888+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab07f"
    },
    "model_benchmark_id": 1666,
    "analysis_method": "Score",
    "benchmark_id": "mmt-bench",
    "benchmark_name": "MMT-Bench",
    "created_at": "2025-07-19T19:56:14.676869+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.636,
    "score": 0.636,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.676869+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab081"
    },
    "model_benchmark_id": 1670,
    "analysis_method": "Score",
    "benchmark_id": "mmvet",
    "benchmark_name": "MMVet",
    "created_at": "2025-07-19T19:56:14.687023+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.671,
    "score": 0.671,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.687023+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab083"
    },
    "model_benchmark_id": 1714,
    "analysis_method": "SR",
    "benchmark_id": "mobileminiwob++-sr",
    "benchmark_name": "MobileMiniWob++_SR",
    "created_at": "2025-07-19T19:56:14.819401+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.914,
    "score": 0.914,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.819401+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab085"
    },
    "model_benchmark_id": 1642,
    "analysis_method": "Score",
    "benchmark_id": "mvbench",
    "benchmark_name": "MVBench",
    "created_at": "2025-07-19T19:56:14.620310+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.620310+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab087"
    },
    "model_benchmark_id": 1540,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.315649+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.315649+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab089"
    },
    "model_benchmark_id": 1679,
    "analysis_method": "Score",
    "benchmark_id": "perceptiontest",
    "benchmark_name": "PerceptionTest",
    "created_at": "2025-07-19T19:56:14.712010+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.712010+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab08b"
    },
    "model_benchmark_id": 1696,
    "analysis_method": "Score",
    "benchmark_id": "screenspot",
    "benchmark_name": "ScreenSpot",
    "created_at": "2025-07-19T19:56:14.771516+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.847,
    "score": 0.847,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.771516+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab08d"
    },
    "model_benchmark_id": 1699,
    "analysis_method": "Score",
    "benchmark_id": "screenspot-pro",
    "benchmark_name": "ScreenSpot Pro",
    "created_at": "2025-07-19T19:56:14.779312+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.29,
    "score": 0.29,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.779312+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab08f"
    },
    "model_benchmark_id": 1691,
    "analysis_method": "Score",
    "benchmark_id": "tempcompass",
    "benchmark_name": "TempCompass",
    "created_at": "2025-07-19T19:56:14.752008+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.717,
    "score": 0.717,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.752008+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab091"
    },
    "model_benchmark_id": 910,
    "analysis_method": "Score",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.896871+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.849,
    "score": 0.849,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:12.896871+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab093"
    },
    "model_benchmark_id": 1681,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-o-sub.",
    "benchmark_name": "VideoMME w/o sub.",
    "created_at": "2025-07-19T19:56:14.718319+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.651,
    "score": 0.651,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.718319+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab095"
    },
    "model_benchmark_id": 1684,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-sub.",
    "benchmark_name": "VideoMME w sub.",
    "created_at": "2025-07-19T19:56:14.726358+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-7b",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
    "updated_at": "2025-07-19T19:56:14.726358+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab097"
    },
    "model_benchmark_id": 1675,
    "analysis_method": "full",
    "benchmark_id": "mathvision",
    "benchmark_name": "MathVision",
    "created_at": "2025-07-19T19:56:14.700746+00:00",
    "is_self_reported": true,
    "model_id": "qvq-72b-preview",
    "normalized_score": 0.359,
    "score": 0.359,
    "self_reported_source_link": "https://huggingface.co/Qwen/QVQ-72B-Preview",
    "updated_at": "2025-07-19T19:56:14.700746+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab099"
    },
    "model_benchmark_id": 526,
    "analysis_method": "mini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.092107+00:00",
    "is_self_reported": true,
    "model_id": "qvq-72b-preview",
    "normalized_score": 0.714,
    "score": 0.714,
    "self_reported_source_link": "https://huggingface.co/Qwen/QVQ-72B-Preview",
    "updated_at": "2025-07-19T19:56:12.092107+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab09b"
    },
    "model_benchmark_id": 570,
    "analysis_method": "val",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.173084+00:00",
    "is_self_reported": true,
    "model_id": "qvq-72b-preview",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://huggingface.co/Qwen/QVQ-72B-Preview",
    "updated_at": "2025-07-19T19:56:12.173084+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab09d"
    },
    "model_benchmark_id": 1716,
    "analysis_method": "full",
    "benchmark_id": "olympiadbench",
    "benchmark_name": "OlympiadBench",
    "created_at": "2025-07-19T19:56:14.824642+00:00",
    "is_self_reported": true,
    "model_id": "qvq-72b-preview",
    "normalized_score": 0.204,
    "score": 0.204,
    "self_reported_source_link": "https://huggingface.co/Qwen/QVQ-72B-Preview",
    "updated_at": "2025-07-19T19:56:14.824642+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab09f"
    },
    "model_benchmark_id": 1254,
    "analysis_method": "Score",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.633399+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.832,
    "score": 0.832,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:13.633399+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0a1"
    },
    "model_benchmark_id": 866,
    "analysis_method": "Score",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.809953+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.853,
    "score": 0.853,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.809953+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0a3"
    },
    "model_benchmark_id": 1718,
    "analysis_method": "WER",
    "benchmark_id": "common-voice-15",
    "benchmark_name": "Common Voice 15",
    "created_at": "2025-07-19T19:56:14.833534+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.076,
    "score": 0.076,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.833534+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0a5"
    },
    "model_benchmark_id": 1717,
    "analysis_method": "BLEU",
    "benchmark_id": "covost2-en-zh",
    "benchmark_name": "CoVoST2 en-zh",
    "created_at": "2025-07-19T19:56:14.828460+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.414,
    "score": 0.414,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.828460+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0a7"
    },
    "model_benchmark_id": 1719,
    "analysis_method": "Score",
    "benchmark_id": "crperelation",
    "benchmark_name": "CRPErelation",
    "created_at": "2025-07-19T19:56:14.837425+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.765,
    "score": 0.765,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.837425+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0a9"
    },
    "model_benchmark_id": 887,
    "analysis_method": "Score",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.846061+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.952,
    "score": 0.952,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.846061+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0ab"
    },
    "model_benchmark_id": 924,
    "analysis_method": "Score",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.931056+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.686,
    "score": 0.686,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.931056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0ad"
    },
    "model_benchmark_id": 1401,
    "analysis_method": "WER",
    "benchmark_id": "fleurs",
    "benchmark_name": "FLEURS",
    "created_at": "2025-07-19T19:56:13.953081+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.041,
    "score": 0.041,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:13.953081+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0af"
    },
    "model_benchmark_id": 1720,
    "analysis_method": "Score",
    "benchmark_id": "giantsteps-tempo",
    "benchmark_name": "GiantSteps Tempo",
    "created_at": "2025-07-19T19:56:14.841583+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.841583+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0b1"
    },
    "model_benchmark_id": 305,
    "analysis_method": "Score",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.684328+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.308,
    "score": 0.308,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:11.684328+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0b3"
    },
    "model_benchmark_id": 997,
    "analysis_method": "Score",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.086524+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.887,
    "score": 0.887,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:13.086524+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0b5"
    },
    "model_benchmark_id": 788,
    "analysis_method": "Score",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.650243+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.787,
    "score": 0.787,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.650243+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0b7"
    },
    "model_benchmark_id": 752,
    "analysis_method": "Score",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.581448+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.296,
    "score": 0.296,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.581448+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0b9"
    },
    "model_benchmark_id": 407,
    "analysis_method": "Score",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.867189+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.715,
    "score": 0.715,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:11.867189+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0bb"
    },
    "model_benchmark_id": 1676,
    "analysis_method": "Score",
    "benchmark_id": "mathvision",
    "benchmark_name": "MathVision",
    "created_at": "2025-07-19T19:56:14.702750+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.25,
    "score": 0.25,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.702750+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0bd"
    },
    "model_benchmark_id": 527,
    "analysis_method": "Score",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.094090+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.679,
    "score": 0.679,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.094090+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0bf"
    },
    "model_benchmark_id": 1188,
    "analysis_method": "Score",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.504920+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.732,
    "score": 0.732,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:13.504920+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0c1"
    },
    "model_benchmark_id": 1721,
    "analysis_method": "Score",
    "benchmark_id": "meld",
    "benchmark_name": "Meld",
    "created_at": "2025-07-19T19:56:14.845437+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.57,
    "score": 0.57,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.845437+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0c3"
    },
    "model_benchmark_id": 1722,
    "analysis_method": "Score",
    "benchmark_id": "mmau",
    "benchmark_name": "MMAU",
    "created_at": "2025-07-19T19:56:14.849392+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.656,
    "score": 0.656,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.849392+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0c5"
    },
    "model_benchmark_id": 1723,
    "analysis_method": "Score",
    "benchmark_id": "mmau-music",
    "benchmark_name": "MMAU Music",
    "created_at": "2025-07-19T19:56:14.854098+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.6916,
    "score": 0.6916,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.854098+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0c7"
    },
    "model_benchmark_id": 1724,
    "analysis_method": "Score",
    "benchmark_id": "mmau-sound",
    "benchmark_name": "MMAU Sound",
    "created_at": "2025-07-19T19:56:14.862523+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.6787,
    "score": 0.6787,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.862523+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0c9"
    },
    "model_benchmark_id": 1725,
    "analysis_method": "Score",
    "benchmark_id": "mmau-speech",
    "benchmark_name": "MMAU Speech",
    "created_at": "2025-07-19T19:56:14.867393+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.5976,
    "score": 0.5976,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.867393+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0cb"
    },
    "model_benchmark_id": 1726,
    "analysis_method": "Score",
    "benchmark_id": "mmbench-v1.1",
    "benchmark_name": "MMBench-V1.1",
    "created_at": "2025-07-19T19:56:14.871500+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.818,
    "score": 0.818,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.871500+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0cd"
    },
    "model_benchmark_id": 1730,
    "analysis_method": "Score",
    "benchmark_id": "mme-realworld",
    "benchmark_name": "MME-RealWorld",
    "created_at": "2025-07-19T19:56:14.879804+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.616,
    "score": 0.616,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.879804+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0cf"
    },
    "model_benchmark_id": 197,
    "analysis_method": "Score",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.477278+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.47,
    "score": 0.47,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:11.477278+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0d1"
    },
    "model_benchmark_id": 734,
    "analysis_method": "Score",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.544013+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.71,
    "score": 0.71,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.544013+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0d3"
    },
    "model_benchmark_id": 1731,
    "analysis_method": "Score",
    "benchmark_id": "mm-mt-bench",
    "benchmark_name": "MM-MT-Bench",
    "created_at": "2025-07-19T19:56:14.883880+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.06,
    "score": 0.06,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.883880+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0d5"
    },
    "model_benchmark_id": 571,
    "analysis_method": "Score",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.175251+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.592,
    "score": 0.592,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.175251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0d7"
    },
    "model_benchmark_id": 1534,
    "analysis_method": "Score",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.296124+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.366,
    "score": 0.366,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.296124+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0d9"
    },
    "model_benchmark_id": 1660,
    "analysis_method": "Score",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.664551+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.664551+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0db"
    },
    "model_benchmark_id": 1734,
    "analysis_method": "Score",
    "benchmark_id": "muirbench",
    "benchmark_name": "MuirBench",
    "created_at": "2025-07-19T19:56:14.891075+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.592,
    "score": 0.592,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.891075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0dd"
    },
    "model_benchmark_id": 645,
    "analysis_method": "Score",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.324318+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.324318+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0df"
    },
    "model_benchmark_id": 1735,
    "analysis_method": "Score",
    "benchmark_id": "musiccaps",
    "benchmark_name": "MusicCaps",
    "created_at": "2025-07-19T19:56:14.894342+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.328,
    "score": 0.328,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.894342+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0e1"
    },
    "model_benchmark_id": 1643,
    "analysis_method": "Score",
    "benchmark_id": "mvbench",
    "benchmark_name": "MVBench",
    "created_at": "2025-07-19T19:56:14.621841+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.621841+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0e3"
    },
    "model_benchmark_id": 1736,
    "analysis_method": "NMOS",
    "benchmark_id": "nmos",
    "benchmark_name": "NMOS",
    "created_at": "2025-07-19T19:56:14.897653+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.0451,
    "score": 0.0451,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-omni/",
    "updated_at": "2025-07-19T19:56:14.897653+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0e5"
    },
    "model_benchmark_id": 1737,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench-v2",
    "benchmark_name": "OCRBench_V2",
    "created_at": "2025-07-19T19:56:14.901546+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.578,
    "score": 0.578,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.901546+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0e7"
    },
    "model_benchmark_id": 1738,
    "analysis_method": "Score",
    "benchmark_id": "odinw",
    "benchmark_name": "ODinW",
    "created_at": "2025-07-19T19:56:14.905294+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.424,
    "score": 0.424,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.905294+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0e9"
    },
    "model_benchmark_id": 1739,
    "analysis_method": "Score",
    "benchmark_id": "omnibench",
    "benchmark_name": "OmniBench",
    "created_at": "2025-07-19T19:56:14.909979+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.5613,
    "score": 0.5613,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.909979+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0eb"
    },
    "model_benchmark_id": 1740,
    "analysis_method": "Score",
    "benchmark_id": "omnibench-music",
    "benchmark_name": "OmniBench Music",
    "created_at": "2025-07-19T19:56:14.913742+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.5283,
    "score": 0.5283,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.913742+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0ed"
    },
    "model_benchmark_id": 1741,
    "analysis_method": "Score",
    "benchmark_id": "pointgrounding",
    "benchmark_name": "PointGrounding",
    "created_at": "2025-07-19T19:56:14.918183+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.665,
    "score": 0.665,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.918183+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0ef"
    },
    "model_benchmark_id": 1634,
    "analysis_method": "Score",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.599392+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.599392+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0f1"
    },
    "model_benchmark_id": 911,
    "analysis_method": "Score",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.899579+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.844,
    "score": 0.844,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:12.899579+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0f3"
    },
    "model_benchmark_id": 1685,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-sub.",
    "benchmark_name": "VideoMME w sub.",
    "created_at": "2025-07-19T19:56:14.727965+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.724,
    "score": 0.724,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.727965+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0f5"
    },
    "model_benchmark_id": 1742,
    "analysis_method": "Score",
    "benchmark_id": "vocalsound",
    "benchmark_name": "VocalSound",
    "created_at": "2025-07-19T19:56:14.921505+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.939,
    "score": 0.939,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.921505+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0f7"
    },
    "model_benchmark_id": 1743,
    "analysis_method": "Score",
    "benchmark_id": "voicebench-avg",
    "benchmark_name": "VoiceBench Avg",
    "created_at": "2025-07-19T19:56:14.925208+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-omni-7b",
    "normalized_score": 0.7412,
    "score": 0.7412,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-Omni",
    "updated_at": "2025-07-19T19:56:14.925208+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0f9"
    },
    "model_benchmark_id": 1618,
    "analysis_method": "AlignBench v1.1 benchmark evaluation",
    "benchmark_id": "alignbench",
    "benchmark_name": "AlignBench",
    "created_at": "2025-07-19T19:56:14.548680+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.548680+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0fb"
    },
    "model_benchmark_id": 1455,
    "analysis_method": "Arena Hard benchmark evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.100766+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.52,
    "score": 0.52,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.100766+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0fd"
    },
    "model_benchmark_id": 306,
    "analysis_method": "GPQA benchmark evaluation",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.685965+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.364,
    "score": 0.364,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.685965+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab0ff"
    },
    "model_benchmark_id": 998,
    "analysis_method": "GSM8K benchmark evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.088027+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.088027+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab101"
    },
    "model_benchmark_id": 789,
    "analysis_method": "HumanEval benchmark evaluation",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.651744+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.651744+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab103"
    },
    "model_benchmark_id": 621,
    "analysis_method": "IFEval strict-prompt benchmark evaluation",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.278867+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.712,
    "score": 0.712,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.278867+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab105"
    },
    "model_benchmark_id": 753,
    "analysis_method": "LiveBench 0831 benchmark evaluation",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.584018+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.359,
    "score": 0.359,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.584018+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab107"
    },
    "model_benchmark_id": 1126,
    "analysis_method": "LiveCodeBench 2305-2409 benchmark evaluation",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.352497+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.287,
    "score": 0.287,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.352497+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab109"
    },
    "model_benchmark_id": 408,
    "analysis_method": "MATH benchmark evaluation",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.869960+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.755,
    "score": 0.755,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.869960+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab10b"
    },
    "model_benchmark_id": 1189,
    "analysis_method": "MBPP benchmark evaluation",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.506947+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.792,
    "score": 0.792,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:13.506947+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab10d"
    },
    "model_benchmark_id": 198,
    "analysis_method": "MMLU-Pro benchmark evaluation",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.479104+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.563,
    "score": 0.563,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:11.479104+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab10f"
    },
    "model_benchmark_id": 735,
    "analysis_method": "MMLU-redux benchmark evaluation",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.545338+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.545338+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab111"
    },
    "model_benchmark_id": 1607,
    "analysis_method": "MT-bench benchmark evaluation",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.523567+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:14.523567+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab113"
    },
    "model_benchmark_id": 646,
    "analysis_method": "MultiPL-E benchmark evaluation",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.325846+00:00",
    "is_self_reported": true,
    "model_id": "qwen-2.5-7b-instruct",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen2.5-llm/",
    "updated_at": "2025-07-19T19:56:12.325846+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab115"
    },
    "model_benchmark_id": 9301,
    "analysis_method": null,
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.806,
    "score": 0.806,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab117"
    },
    "model_benchmark_id": 9302,
    "analysis_method": null,
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.909,
    "score": 0.909,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab119"
    },
    "model_benchmark_id": 9303,
    "analysis_method": null,
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.729,
    "score": 0.729,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab11b"
    },
    "model_benchmark_id": 9304,
    "analysis_method": null,
    "benchmark_id": "supergpqa",
    "benchmark_name": "SuperGPQA",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.588,
    "score": 0.588,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab11d"
    },
    "model_benchmark_id": 9305,
    "analysis_method": null,
    "benchmark_id": "aime25",
    "benchmark_name": "AIME25",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.695,
    "score": 0.695,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab11f"
    },
    "model_benchmark_id": 9306,
    "analysis_method": null,
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.541,
    "score": 0.541,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab121"
    },
    "model_benchmark_id": 9307,
    "analysis_method": null,
    "benchmark_id": "livebench-20241125",
    "benchmark_name": "LiveBench 20241125",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab123"
    },
    "model_benchmark_id": 9308,
    "analysis_method": "25.02-25.05",
    "benchmark_id": "livecodebench-v6",
    "benchmark_name": "LiveCodeBench v6",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.566,
    "score": 0.566,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab125"
    },
    "model_benchmark_id": 9309,
    "analysis_method": null,
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab127"
    },
    "model_benchmark_id": 9310,
    "analysis_method": null,
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.498,
    "score": 0.498,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab129"
    },
    "model_benchmark_id": 9311,
    "analysis_method": null,
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.876,
    "score": 0.876,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab12b"
    },
    "model_benchmark_id": 9312,
    "analysis_method": "GPT-4.1 evaluated win rates",
    "benchmark_id": "arena-hard-v2",
    "benchmark_name": "Arena-Hard v2",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.827,
    "score": 0.827,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab12d"
    },
    "model_benchmark_id": 9313,
    "analysis_method": null,
    "benchmark_id": "creative-writing-v3",
    "benchmark_name": "Creative Writing v3",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.853,
    "score": 0.853,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab12f"
    },
    "model_benchmark_id": 9314,
    "analysis_method": null,
    "benchmark_id": "writingbench",
    "benchmark_name": "WritingBench",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.873,
    "score": 0.873,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab131"
    },
    "model_benchmark_id": 9315,
    "analysis_method": null,
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab133"
    },
    "model_benchmark_id": 9316,
    "analysis_method": null,
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU1-Retail",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.609,
    "score": 0.609,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Retail",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab135"
    },
    "model_benchmark_id": 9317,
    "analysis_method": null,
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU1-Airline",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.44,
    "score": 0.44,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "TAU1-Airline",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab137"
    },
    "model_benchmark_id": 9318,
    "analysis_method": null,
    "benchmark_id": "tau2-retail",
    "benchmark_name": "TAU2-Retail",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.573,
    "score": 0.573,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab139"
    },
    "model_benchmark_id": 9319,
    "analysis_method": null,
    "benchmark_id": "tau2-airline",
    "benchmark_name": "TAU2-Airline",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.455,
    "score": 0.455,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab13b"
    },
    "model_benchmark_id": 9320,
    "analysis_method": null,
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "TAU2-Telecom",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.132,
    "score": 0.132,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab13d"
    },
    "model_benchmark_id": 9321,
    "analysis_method": null,
    "benchmark_id": "multi-if",
    "benchmark_name": "MultiIF",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MultiIF",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab13f"
    },
    "model_benchmark_id": 9322,
    "analysis_method": null,
    "benchmark_id": "mmlu-prox",
    "benchmark_name": "MMLU-ProX",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.767,
    "score": 0.767,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "MMLU-ProX",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab141"
    },
    "model_benchmark_id": 9323,
    "analysis_method": null,
    "benchmark_id": "include",
    "benchmark_name": "INCLUDE",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab143"
    },
    "model_benchmark_id": 9324,
    "analysis_method": null,
    "benchmark_id": "polymath",
    "benchmark_name": "PolyMATH",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "qwen3-next-80b-a3b-instruct",
    "normalized_score": 0.459,
    "score": 0.459,
    "self_reported_source_link": "https://qwenlm.github.io/blog/qwen3-next/",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab145"
    },
    "model_benchmark_id": 1255,
    "analysis_method": "Score",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.635049+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:13.635049+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab147"
    },
    "model_benchmark_id": 1703,
    "analysis_method": "EM",
    "benchmark_id": "aitz-em",
    "benchmark_name": "AITZ_EM",
    "created_at": "2025-07-19T19:56:14.789425+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.832,
    "score": 0.832,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.789425+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab149"
    },
    "model_benchmark_id": 1706,
    "analysis_method": "EM",
    "benchmark_id": "android-control-high-em",
    "benchmark_name": "Android Control High_EM",
    "created_at": "2025-07-19T19:56:14.796411+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.6736,
    "score": 0.6736,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.796411+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab14b"
    },
    "model_benchmark_id": 1709,
    "analysis_method": "EM",
    "benchmark_id": "android-control-low-em",
    "benchmark_name": "Android Control Low_EM",
    "created_at": "2025-07-19T19:56:14.805303+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.937,
    "score": 0.937,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.805303+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab14d"
    },
    "model_benchmark_id": 1712,
    "analysis_method": "SR",
    "benchmark_id": "androidworld-sr",
    "benchmark_name": "AndroidWorld_SR",
    "created_at": "2025-07-19T19:56:14.813492+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.35,
    "score": 0.35,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.813492+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab14f"
    },
    "model_benchmark_id": 1657,
    "analysis_method": "Score",
    "benchmark_id": "cc-ocr",
    "benchmark_name": "CC-OCR",
    "created_at": "2025-07-19T19:56:14.657333+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.798,
    "score": 0.798,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.657333+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab151"
    },
    "model_benchmark_id": 867,
    "analysis_method": "Score",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.811401+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.895,
    "score": 0.895,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:12.811401+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab153"
    },
    "model_benchmark_id": 888,
    "analysis_method": "Score",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.848273+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.964,
    "score": 0.964,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:12.848273+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab155"
    },
    "model_benchmark_id": 925,
    "analysis_method": "Score",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.933582+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.762,
    "score": 0.762,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:12.933582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab157"
    },
    "model_benchmark_id": 1673,
    "analysis_method": "Score",
    "benchmark_id": "hallusion-bench",
    "benchmark_name": "Hallusion Bench",
    "created_at": "2025-07-19T19:56:14.694733+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.5516,
    "score": 0.5516,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.694733+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab159"
    },
    "model_benchmark_id": 829,
    "analysis_method": "Score",
    "benchmark_id": "lvbench",
    "benchmark_name": "LVBench",
    "created_at": "2025-07-19T19:56:12.731476+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.473,
    "score": 0.473,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:12.731476+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab15b"
    },
    "model_benchmark_id": 1677,
    "analysis_method": "Score",
    "benchmark_id": "mathvision",
    "benchmark_name": "MathVision",
    "created_at": "2025-07-19T19:56:14.705119+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.381,
    "score": 0.381,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.705119+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab15d"
    },
    "model_benchmark_id": 1271,
    "analysis_method": "Score",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.666379+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.748,
    "score": 0.748,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:13.666379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab15f"
    },
    "model_benchmark_id": 1746,
    "analysis_method": "Score",
    "benchmark_id": "mlvu-m",
    "benchmark_name": "MLVU-M",
    "created_at": "2025-07-19T19:56:14.934328+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.746,
    "score": 0.746,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.934328+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab161"
    },
    "model_benchmark_id": 1512,
    "analysis_method": "Score",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.243543+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.243543+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab163"
    },
    "model_benchmark_id": 1689,
    "analysis_method": "Score",
    "benchmark_id": "mmbench-video",
    "benchmark_name": "MMBench-Video",
    "created_at": "2025-07-19T19:56:14.744558+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.0202,
    "score": 0.0202,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.744558+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab165"
    },
    "model_benchmark_id": 572,
    "analysis_method": "Score",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.177290+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:12.177290+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab167"
    },
    "model_benchmark_id": 1535,
    "analysis_method": "Score",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.297757+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.511,
    "score": 0.511,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.297757+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab169"
    },
    "model_benchmark_id": 1661,
    "analysis_method": "Score",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.666719+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.666719+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab16b"
    },
    "model_benchmark_id": 1671,
    "analysis_method": "Score",
    "benchmark_id": "mmvet",
    "benchmark_name": "MMVet",
    "created_at": "2025-07-19T19:56:14.688513+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.7619,
    "score": 0.7619,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.688513+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab16d"
    },
    "model_benchmark_id": 1715,
    "analysis_method": "SR",
    "benchmark_id": "mobileminiwob++-sr",
    "benchmark_name": "MobileMiniWob++_SR",
    "created_at": "2025-07-19T19:56:14.820961+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.820961+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab16f"
    },
    "model_benchmark_id": 1644,
    "analysis_method": "Score",
    "benchmark_id": "mvbench",
    "benchmark_name": "MVBench",
    "created_at": "2025-07-19T19:56:14.623550+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.623550+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab171"
    },
    "model_benchmark_id": 1541,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.318110+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.318110+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab173"
    },
    "model_benchmark_id": 1744,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench-v2-(en)",
    "benchmark_name": "OCRBench-V2 (en)",
    "created_at": "2025-07-19T19:56:14.928710+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.615,
    "score": 0.615,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.928710+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab175"
    },
    "model_benchmark_id": 1747,
    "analysis_method": "Score",
    "benchmark_id": "osworld",
    "benchmark_name": "OSWorld",
    "created_at": "2025-07-19T19:56:14.937610+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.0883,
    "score": 0.0883,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.937610+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab177"
    },
    "model_benchmark_id": 1680,
    "analysis_method": "Score",
    "benchmark_id": "perceptiontest",
    "benchmark_name": "PerceptionTest",
    "created_at": "2025-07-19T19:56:14.713944+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.732,
    "score": 0.732,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.713944+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab179"
    },
    "model_benchmark_id": 1697,
    "analysis_method": "Score",
    "benchmark_id": "screenspot",
    "benchmark_name": "ScreenSpot",
    "created_at": "2025-07-19T19:56:14.773284+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.773284+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab17b"
    },
    "model_benchmark_id": 1700,
    "analysis_method": "Score",
    "benchmark_id": "screenspot-pro",
    "benchmark_name": "ScreenSpot Pro",
    "created_at": "2025-07-19T19:56:14.780898+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.436,
    "score": 0.436,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.780898+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab17d"
    },
    "model_benchmark_id": 1692,
    "analysis_method": "Score",
    "benchmark_id": "tempcompass",
    "benchmark_name": "TempCompass",
    "created_at": "2025-07-19T19:56:14.754032+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.748,
    "score": 0.748,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.754032+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab17f"
    },
    "model_benchmark_id": 1682,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-o-sub.",
    "benchmark_name": "VideoMME w/o sub.",
    "created_at": "2025-07-19T19:56:14.720259+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-72b",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct",
    "updated_at": "2025-07-19T19:56:14.720259+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab181"
    },
    "model_benchmark_id": 22,
    "analysis_method": "Accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.129146+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.129146+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab183"
    },
    "model_benchmark_id": 973,
    "analysis_method": "Accuracy",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.045120+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.824,
    "score": 0.824,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:13.045120+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab185"
    },
    "model_benchmark_id": 437,
    "analysis_method": "Accuracy",
    "benchmark_id": "c-eval",
    "benchmark_name": "C-Eval",
    "created_at": "2025-07-19T19:56:11.926225+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.838,
    "score": 0.838,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.926225+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab187"
    },
    "model_benchmark_id": 1749,
    "analysis_method": "Accuracy",
    "benchmark_id": "cmmlu",
    "benchmark_name": "CMMLU",
    "created_at": "2025-07-19T19:56:14.943893+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.901,
    "score": 0.901,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:14.943893+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab189"
    },
    "model_benchmark_id": 372,
    "analysis_method": "Pass@1",
    "benchmark_id": "evalplus",
    "benchmark_name": "EvalPlus",
    "created_at": "2025-07-19T19:56:11.802955+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.802955+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab18b"
    },
    "model_benchmark_id": 307,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.687633+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.424,
    "score": 0.424,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.687633+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab18d"
    },
    "model_benchmark_id": 999,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.089706+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.911,
    "score": 0.911,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:13.089706+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab18f"
    },
    "model_benchmark_id": 48,
    "analysis_method": "Accuracy",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.184833+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.876,
    "score": 0.876,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.184833+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab191"
    },
    "model_benchmark_id": 790,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.653267+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:12.653267+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab193"
    },
    "model_benchmark_id": 409,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.871582+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.597,
    "score": 0.597,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.871582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab195"
    },
    "model_benchmark_id": 1190,
    "analysis_method": "Pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.508406+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:13.508406+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab197"
    },
    "model_benchmark_id": 91,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.272629+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.823,
    "score": 0.823,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.272629+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab199"
    },
    "model_benchmark_id": 199,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.480879+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.644,
    "score": 0.644,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.480879+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab19b"
    },
    "model_benchmark_id": 647,
    "analysis_method": "Pass@1",
    "benchmark_id": "multipl-e",
    "benchmark_name": "MultiPL-E",
    "created_at": "2025-07-19T19:56:12.327331+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:12.327331+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab19d"
    },
    "model_benchmark_id": 1598,
    "analysis_method": "Accuracy",
    "benchmark_id": "theoremqa",
    "benchmark_name": "TheoremQA",
    "created_at": "2025-07-19T19:56:14.494165+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.444,
    "score": 0.444,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:14.494165+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab19f"
    },
    "model_benchmark_id": 139,
    "analysis_method": "Accuracy",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.356602+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.548,
    "score": 0.548,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.356602+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1a1"
    },
    "model_benchmark_id": 151,
    "analysis_method": "Accuracy",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.386216+00:00",
    "is_self_reported": true,
    "model_id": "qwen2-72b-instruct",
    "normalized_score": 0.851,
    "score": 0.851,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2-72B",
    "updated_at": "2025-07-19T19:56:11.386216+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1a3"
    },
    "model_benchmark_id": 1704,
    "analysis_method": "EM",
    "benchmark_id": "aitz-em",
    "benchmark_name": "AITZ_EM",
    "created_at": "2025-07-19T19:56:14.791493+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.831,
    "score": 0.831,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.791493+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1a5"
    },
    "model_benchmark_id": 1707,
    "analysis_method": "EM",
    "benchmark_id": "android-control-high-em",
    "benchmark_name": "Android Control High_EM",
    "created_at": "2025-07-19T19:56:14.798431+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.798431+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1a7"
    },
    "model_benchmark_id": 1710,
    "analysis_method": "EM",
    "benchmark_id": "android-control-low-em",
    "benchmark_name": "Android Control Low_EM",
    "created_at": "2025-07-19T19:56:14.807428+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.807428+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1a9"
    },
    "model_benchmark_id": 1713,
    "analysis_method": "SR",
    "benchmark_id": "androidworld-sr",
    "benchmark_name": "AndroidWorld_SR",
    "created_at": "2025-07-19T19:56:14.815734+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.22,
    "score": 0.22,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.815734+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1ab"
    },
    "model_benchmark_id": 1658,
    "analysis_method": "Score",
    "benchmark_id": "cc-ocr",
    "benchmark_name": "CC-OCR",
    "created_at": "2025-07-19T19:56:14.659496+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.771,
    "score": 0.771,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.659496+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1ad"
    },
    "model_benchmark_id": 1695,
    "analysis_method": "Score",
    "benchmark_id": "charadessta",
    "benchmark_name": "CharadesSTA",
    "created_at": "2025-07-19T19:56:14.765807+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.542,
    "score": 0.542,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.765807+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1af"
    },
    "model_benchmark_id": 889,
    "analysis_method": "Score",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.850117+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.948,
    "score": 0.948,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:12.850117+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1b1"
    },
    "model_benchmark_id": 1751,
    "analysis_method": "Score",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:14.953480+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.46,
    "score": 0.46,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.953480+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1b3"
    },
    "model_benchmark_id": 791,
    "analysis_method": "Score",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.655022+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.915,
    "score": 0.915,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:12.655022+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1b5"
    },
    "model_benchmark_id": 1243,
    "analysis_method": "Score",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.612560+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:13.612560+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1b7"
    },
    "model_benchmark_id": 830,
    "analysis_method": "Score",
    "benchmark_id": "lvbench",
    "benchmark_name": "LVBench",
    "created_at": "2025-07-19T19:56:12.733525+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.49,
    "score": 0.49,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:12.733525+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1b9"
    },
    "model_benchmark_id": 410,
    "analysis_method": "Score",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.873375+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.822,
    "score": 0.822,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:11.873375+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1bb"
    },
    "model_benchmark_id": 1678,
    "analysis_method": "Score",
    "benchmark_id": "mathvision",
    "benchmark_name": "MathVision",
    "created_at": "2025-07-19T19:56:14.707439+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.384,
    "score": 0.384,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.707439+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1bd"
    },
    "model_benchmark_id": 1272,
    "analysis_method": "Score",
    "benchmark_id": "mathvista-mini",
    "benchmark_name": "MathVista-Mini",
    "created_at": "2025-07-19T19:56:13.668155+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.747,
    "score": 0.747,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:13.668155+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1bf"
    },
    "model_benchmark_id": 1191,
    "analysis_method": "Score",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.509907+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.84,
    "score": 0.84,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:13.509907+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1c1"
    },
    "model_benchmark_id": 1690,
    "analysis_method": "Score",
    "benchmark_id": "mmbench-video",
    "benchmark_name": "MMBench-Video",
    "created_at": "2025-07-19T19:56:14.747059+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.0193,
    "score": 0.0193,
    "self_reported_source_link": "https://github.com/QwenLM/Qwen2.5-VL",
    "updated_at": "2025-07-19T19:56:14.747059+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1c3"
    },
    "model_benchmark_id": 92,
    "analysis_method": "Score",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.274441+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.784,
    "score": 0.784,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:11.274441+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1c5"
    },
    "model_benchmark_id": 200,
    "analysis_method": "Score",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.482355+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.688,
    "score": 0.688,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:11.482355+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1c7"
    },
    "model_benchmark_id": 573,
    "analysis_method": "Score",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.179390+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.7,
    "score": 0.7,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:12.179390+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1c9"
    },
    "model_benchmark_id": 1536,
    "analysis_method": "Score",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-19T19:56:14.299391+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.495,
    "score": 0.495,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.299391+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1cb"
    },
    "model_benchmark_id": 1662,
    "analysis_method": "Score",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.668445+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.695,
    "score": 0.695,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.668445+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1cd"
    },
    "model_benchmark_id": 1745,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench-v2-(en)",
    "benchmark_name": "OCRBench-V2 (en)",
    "created_at": "2025-07-19T19:56:14.930331+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.930331+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1cf"
    },
    "model_benchmark_id": 1750,
    "analysis_method": "Score",
    "benchmark_id": "ocrbench-v2-(zh)",
    "benchmark_name": "OCRBench-V2 (zh)",
    "created_at": "2025-07-19T19:56:14.947420+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.591,
    "score": 0.591,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.947420+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1d1"
    },
    "model_benchmark_id": 1748,
    "analysis_method": "Score",
    "benchmark_id": "osworld",
    "benchmark_name": "OSWorld",
    "created_at": "2025-07-19T19:56:14.939263+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.0592,
    "score": 0.0592,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.939263+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1d3"
    },
    "model_benchmark_id": 1698,
    "analysis_method": "Score",
    "benchmark_id": "screenspot",
    "benchmark_name": "ScreenSpot",
    "created_at": "2025-07-19T19:56:14.775538+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.775538+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1d5"
    },
    "model_benchmark_id": 1701,
    "analysis_method": "Score",
    "benchmark_id": "screenspot-pro",
    "benchmark_name": "ScreenSpot Pro",
    "created_at": "2025-07-19T19:56:14.783897+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.394,
    "score": 0.394,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.783897+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1d7"
    },
    "model_benchmark_id": 1683,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-o-sub.",
    "benchmark_name": "VideoMME w/o sub.",
    "created_at": "2025-07-19T19:56:14.722056+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.722056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1d9"
    },
    "model_benchmark_id": 1686,
    "analysis_method": "Score",
    "benchmark_id": "videomme-w-sub.",
    "benchmark_name": "VideoMME w sub.",
    "created_at": "2025-07-19T19:56:14.729388+00:00",
    "is_self_reported": true,
    "model_id": "qwen2.5-vl-32b",
    "normalized_score": 0.779,
    "score": 0.779,
    "self_reported_source_link": "https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct",
    "updated_at": "2025-07-19T19:56:14.729388+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1db"
    },
    "model_benchmark_id": 9601,
    "analysis_method": "Thinking mode",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.934,
    "score": 0.934,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1dd"
    },
    "model_benchmark_id": 9602,
    "analysis_method": "Thinking mode",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.85,
    "score": 0.85,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1df"
    },
    "model_benchmark_id": 9603,
    "analysis_method": "Pass@1, Thinking mode",
    "benchmark_id": "gpqa-diamond",
    "benchmark_name": "GPQA-Diamond",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1e1"
    },
    "model_benchmark_id": 9604,
    "analysis_method": "Pass@1, Thinking mode, text-only subset",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.177,
    "score": 0.177,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Text-only subset evaluation",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1e3"
    },
    "model_benchmark_id": 9605,
    "analysis_method": "Search agent with pre-defined workflow",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.089,
    "score": 0.089,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with pre-defined workflow",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1e5"
    },
    "model_benchmark_id": 9606,
    "analysis_method": "Search agent with pre-defined workflow",
    "benchmark_id": "browsecomp-zh",
    "benchmark_name": "BrowseComp-zh",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.357,
    "score": 0.357,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with pre-defined workflow",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1e7"
    },
    "model_benchmark_id": 9607,
    "analysis_method": "Search agent evaluation",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1e9"
    },
    "model_benchmark_id": 9608,
    "analysis_method": "Pass@1, 2408-2505, Thinking mode",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1eb"
    },
    "model_benchmark_id": 9609,
    "analysis_method": "Div1 Rating, Thinking mode",
    "benchmark_id": "codeforces",
    "benchmark_name": "Codeforces",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.6433,
    "score": 0.6433,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1ed"
    },
    "model_benchmark_id": 9610,
    "analysis_method": "Thinking mode",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1ef"
    },
    "model_benchmark_id": 9611,
    "analysis_method": "Agent mode",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.446,
    "score": 0.446,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with internal code agent framework",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1f1"
    },
    "model_benchmark_id": 9612,
    "analysis_method": "Agent mode",
    "benchmark_id": "swe-bench-multilingual",
    "benchmark_name": "SWE-Bench Multilingual",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.305,
    "score": 0.305,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with internal code agent framework",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1f3"
    },
    "model_benchmark_id": 9613,
    "analysis_method": "Terminus 1 framework",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-Bench",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.057,
    "score": 0.057,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1f5"
    },
    "model_benchmark_id": 9614,
    "analysis_method": "Pass@1, Thinking mode",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.914,
    "score": 0.914,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1f7"
    },
    "model_benchmark_id": 9615,
    "analysis_method": "Pass@1, Thinking mode",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1f9"
    },
    "model_benchmark_id": 9616,
    "analysis_method": "Pass@1, Thinking mode",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-05-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-0528",
    "normalized_score": 0.794,
    "score": 0.794,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1fb"
    },
    "model_benchmark_id": 1256,
    "analysis_method": "test",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.636398+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.636398+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1fd"
    },
    "model_benchmark_id": 868,
    "analysis_method": "test",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.812840+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.812840+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab1ff"
    },
    "model_benchmark_id": 890,
    "analysis_method": "test",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.852402+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.852402+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab201"
    },
    "model_benchmark_id": 1244,
    "analysis_method": "test",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.614094+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.781,
    "score": 0.781,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.614094+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab203"
    },
    "model_benchmark_id": 528,
    "analysis_method": "testmini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.096047+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.628,
    "score": 0.628,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.096047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab205"
    },
    "model_benchmark_id": 1513,
    "analysis_method": "en test",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.245378+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.796,
    "score": 0.796,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.247008+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab207"
    },
    "model_benchmark_id": 1727,
    "analysis_method": "cn test",
    "benchmark_id": "mmbench-v1.1",
    "benchmark_name": "MMBench-V1.1",
    "created_at": "2025-07-19T19:56:14.873346+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.792,
    "score": 0.792,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.873346+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab209"
    },
    "model_benchmark_id": 1784,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mme",
    "benchmark_name": "MME",
    "created_at": "2025-07-19T19:56:15.025040+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.2253,
    "score": 0.2253,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:15.025040+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab20b"
    },
    "model_benchmark_id": 574,
    "analysis_method": "val",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.181251+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.511,
    "score": 0.511,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.181251+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab20d"
    },
    "model_benchmark_id": 1663,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.669907+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.613,
    "score": 0.613,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.669907+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab20f"
    },
    "model_benchmark_id": 1667,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmt-bench",
    "benchmark_name": "MMT-Bench",
    "created_at": "2025-07-19T19:56:14.678247+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.636,
    "score": 0.636,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.678247+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab211"
    },
    "model_benchmark_id": 1542,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.320020+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.320020+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab213"
    },
    "model_benchmark_id": 1635,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.601290+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.601290+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab215"
    },
    "model_benchmark_id": 912,
    "analysis_method": "val",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.902069+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2",
    "normalized_score": 0.842,
    "score": 0.842,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.902069+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab217"
    },
    "model_benchmark_id": 1257,
    "analysis_method": "test",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.638556+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.716,
    "score": 0.716,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.638556+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab219"
    },
    "model_benchmark_id": 869,
    "analysis_method": "test",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.814592+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.814592+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab21b"
    },
    "model_benchmark_id": 891,
    "analysis_method": "test",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.854588+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.889,
    "score": 0.889,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.854588+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab21d"
    },
    "model_benchmark_id": 1245,
    "analysis_method": "test",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.616113+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.661,
    "score": 0.661,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.616113+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab21f"
    },
    "model_benchmark_id": 529,
    "analysis_method": "testmini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.098477+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.098477+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab221"
    },
    "model_benchmark_id": 1515,
    "analysis_method": "en test",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.249349+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.251060+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab223"
    },
    "model_benchmark_id": 1728,
    "analysis_method": "cn test",
    "benchmark_id": "mmbench-v1.1",
    "benchmark_name": "MMBench-V1.1",
    "created_at": "2025-07-19T19:56:14.875207+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.683,
    "score": 0.683,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.875207+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab225"
    },
    "model_benchmark_id": 1785,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mme",
    "benchmark_name": "MME",
    "created_at": "2025-07-19T19:56:15.026734+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.1915,
    "score": 0.1915,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:15.026734+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab227"
    },
    "model_benchmark_id": 575,
    "analysis_method": "val",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.183016+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.407,
    "score": 0.407,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.183016+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab229"
    },
    "model_benchmark_id": 1664,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.671412+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.459,
    "score": 0.459,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.671412+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab22b"
    },
    "model_benchmark_id": 1668,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmt-bench",
    "benchmark_name": "MMT-Bench",
    "created_at": "2025-07-19T19:56:14.681683+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.532,
    "score": 0.532,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.681683+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab22d"
    },
    "model_benchmark_id": 1543,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.321888+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.809,
    "score": 0.809,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.321888+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab22f"
    },
    "model_benchmark_id": 1636,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.602948+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.642,
    "score": 0.642,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.602948+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab231"
    },
    "model_benchmark_id": 913,
    "analysis_method": "val",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.904238+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-tiny",
    "normalized_score": 0.807,
    "score": 0.807,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.904238+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab233"
    },
    "model_benchmark_id": 457,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.970600+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-zero",
    "normalized_score": 0.867,
    "score": 0.867,
    "self_reported_source_link": "https://arxiv.org/abs/2501.12948",
    "updated_at": "2025-07-19T19:56:11.972162+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab235"
    },
    "model_benchmark_id": 309,
    "analysis_method": "Pass@1 Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.691175+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-zero",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://arxiv.org/abs/2501.12948",
    "updated_at": "2025-07-19T19:56:11.691175+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab237"
    },
    "model_benchmark_id": 1128,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.357962+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-zero",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://arxiv.org/abs/2501.12948",
    "updated_at": "2025-07-19T19:56:13.357962+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab239"
    },
    "model_benchmark_id": 497,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.038172+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-zero",
    "normalized_score": 0.959,
    "score": 0.959,
    "self_reported_source_link": "https://arxiv.org/abs/2501.12948",
    "updated_at": "2025-07-19T19:56:12.038172+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab23b"
    },
    "model_benchmark_id": 1258,
    "analysis_method": "test",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.640145+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.640145+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab23d"
    },
    "model_benchmark_id": 870,
    "analysis_method": "test",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.816278+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.845,
    "score": 0.845,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.816278+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab23f"
    },
    "model_benchmark_id": 892,
    "analysis_method": "test",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.857733+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.857733+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab241"
    },
    "model_benchmark_id": 1246,
    "analysis_method": "test",
    "benchmark_id": "infovqa",
    "benchmark_name": "InfoVQA",
    "created_at": "2025-07-19T19:56:13.617970+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:13.617970+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab243"
    },
    "model_benchmark_id": 530,
    "analysis_method": "testmini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.100314+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.607,
    "score": 0.607,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.100314+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab245"
    },
    "model_benchmark_id": 1517,
    "analysis_method": "en test",
    "benchmark_id": "mmbench",
    "benchmark_name": "MMBench",
    "created_at": "2025-07-19T19:56:14.252930+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.803,
    "score": 0.803,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.254459+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab247"
    },
    "model_benchmark_id": 1729,
    "analysis_method": "cn test",
    "benchmark_id": "mmbench-v1.1",
    "benchmark_name": "MMBench-V1.1",
    "created_at": "2025-07-19T19:56:14.876824+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.793,
    "score": 0.793,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.876824+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab249"
    },
    "model_benchmark_id": 1786,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mme",
    "benchmark_name": "MME",
    "created_at": "2025-07-19T19:56:15.028315+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.2123,
    "score": 0.2123,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:15.028315+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab24b"
    },
    "model_benchmark_id": 576,
    "analysis_method": "val",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.184966+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.48,
    "score": 0.48,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.184966+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab24d"
    },
    "model_benchmark_id": 1665,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmstar",
    "benchmark_name": "MMStar",
    "created_at": "2025-07-19T19:56:14.672978+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.57,
    "score": 0.57,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.672978+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab24f"
    },
    "model_benchmark_id": 1669,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "mmt-bench",
    "benchmark_name": "MMT-Bench",
    "created_at": "2025-07-19T19:56:14.683443+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.629,
    "score": 0.629,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.683443+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab251"
    },
    "model_benchmark_id": 1544,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "ocrbench",
    "benchmark_name": "OCRBench",
    "created_at": "2025-07-19T19:56:14.324965+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.324965+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab253"
    },
    "model_benchmark_id": 1637,
    "analysis_method": "Standard Evaluation",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.604508+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.654,
    "score": 0.654,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:14.604508+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab255"
    },
    "model_benchmark_id": 914,
    "analysis_method": "val",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.906237+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-vl2-small",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://arxiv.org/pdf/2412.10302",
    "updated_at": "2025-07-19T19:56:12.906237+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab257"
    },
    "model_benchmark_id": 459,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.973870+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-7b",
    "normalized_score": 0.833,
    "score": 0.833,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "updated_at": "2025-07-19T19:56:11.975371+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab259"
    },
    "model_benchmark_id": 310,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.692702+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-7b",
    "normalized_score": 0.491,
    "score": 0.491,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "updated_at": "2025-07-19T19:56:11.692702+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab25b"
    },
    "model_benchmark_id": 1129,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.360567+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-7b",
    "normalized_score": 0.376,
    "score": 0.376,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "updated_at": "2025-07-19T19:56:13.360567+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab25d"
    },
    "model_benchmark_id": 498,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.039853+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-7b",
    "normalized_score": 0.928,
    "score": 0.928,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "updated_at": "2025-07-19T19:56:12.039853+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab25f"
    },
    "model_benchmark_id": 461,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.976978+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-1.5b",
    "normalized_score": 0.527,
    "score": 0.527,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "updated_at": "2025-07-19T19:56:11.978475+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab261"
    },
    "model_benchmark_id": 311,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.694071+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-1.5b",
    "normalized_score": 0.338,
    "score": 0.338,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "updated_at": "2025-07-19T19:56:11.694071+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab263"
    },
    "model_benchmark_id": 1130,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.362673+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-1.5b",
    "normalized_score": 0.169,
    "score": 0.169,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "updated_at": "2025-07-19T19:56:13.362673+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab265"
    },
    "model_benchmark_id": 499,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.041592+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-1.5b",
    "normalized_score": 0.839,
    "score": 0.839,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "updated_at": "2025-07-19T19:56:12.041592+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab267"
    },
    "model_benchmark_id": 663,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.374175+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.496,
    "score": 0.496,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.374175+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab269"
    },
    "model_benchmark_id": 1330,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.796886+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:13.796886+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab26b"
    },
    "model_benchmark_id": 463,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.980196+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.392,
    "score": 0.392,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.980196+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab26d"
    },
    "model_benchmark_id": 438,
    "analysis_method": "Exact Match",
    "benchmark_id": "c-eval",
    "benchmark_name": "C-Eval",
    "created_at": "2025-07-19T19:56:11.928060+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.928060+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab26f"
    },
    "model_benchmark_id": 600,
    "analysis_method": "Exact Match",
    "benchmark_id": "cluewsc",
    "benchmark_name": "CLUEWSC",
    "created_at": "2025-07-19T19:56:12.237991+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.909,
    "score": 0.909,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.237991+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab271"
    },
    "model_benchmark_id": 711,
    "analysis_method": "Pass@1",
    "benchmark_id": "cnmo-2024",
    "benchmark_name": "CNMO 2024",
    "created_at": "2025-07-19T19:56:12.493124+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.432,
    "score": 0.432,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.493124+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab273"
    },
    "model_benchmark_id": 442,
    "analysis_method": "Correct",
    "benchmark_id": "csimpleqa",
    "benchmark_name": "CSimpleQA",
    "created_at": "2025-07-19T19:56:11.937598+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.648,
    "score": 0.648,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.937598+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab275"
    },
    "model_benchmark_id": 951,
    "analysis_method": "3-shot F1",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.005931+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:13.005931+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab277"
    },
    "model_benchmark_id": 1753,
    "analysis_method": "Accuracy",
    "benchmark_id": "frames",
    "benchmark_name": "FRAMES",
    "created_at": "2025-07-19T19:56:14.958906+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:14.958906+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab279"
    },
    "model_benchmark_id": 312,
    "analysis_method": "Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.695757+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.591,
    "score": 0.591,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.695757+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab27b"
    },
    "model_benchmark_id": 1788,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval-mul",
    "benchmark_name": "HumanEval-Mul",
    "created_at": "2025-07-19T19:56:15.035409+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.826,
    "score": 0.826,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:15.035409+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab27d"
    },
    "model_benchmark_id": 622,
    "analysis_method": "Prompt Strict",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.280659+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.861,
    "score": 0.861,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.280659+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab27f"
    },
    "model_benchmark_id": 1131,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.364940+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.376,
    "score": 0.376,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:13.372242+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab281"
    },
    "model_benchmark_id": 1787,
    "analysis_method": "Accuracy",
    "benchmark_id": "longbench-v2",
    "benchmark_name": "LongBench v2",
    "created_at": "2025-07-19T19:56:15.031520+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.487,
    "score": 0.487,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:15.031520+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab283"
    },
    "model_benchmark_id": 500,
    "analysis_method": "Exact Match",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.043125+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.043125+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab285"
    },
    "model_benchmark_id": 93,
    "analysis_method": "Exact Match",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.275957+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.275957+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab287"
    },
    "model_benchmark_id": 202,
    "analysis_method": "Exact Match",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.485394+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.759,
    "score": 0.759,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.485394+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab289"
    },
    "model_benchmark_id": 737,
    "analysis_method": "Exact Match",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-07-19T19:56:12.548864+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.891,
    "score": 0.891,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:12.548864+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab28b"
    },
    "model_benchmark_id": 235,
    "analysis_method": "Correct",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.549943+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.249,
    "score": 0.249,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:11.549943+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab28d"
    },
    "model_benchmark_id": 1344,
    "analysis_method": "Resolved",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.828562+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3",
    "normalized_score": 0.42,
    "score": 0.42,
    "self_reported_source_link": "https://github.com/deepseek-ai/DeepSeek-V3",
    "updated_at": "2025-07-19T19:56:13.828562+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab28f"
    },
    "model_benchmark_id": 1627,
    "analysis_method": "Score",
    "benchmark_id": "aider",
    "benchmark_name": "Aider",
    "created_at": "2025-07-19T19:56:14.574890+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:14.574890+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab291"
    },
    "model_benchmark_id": 1619,
    "analysis_method": "Score",
    "benchmark_id": "alignbench",
    "benchmark_name": "AlignBench",
    "created_at": "2025-07-19T19:56:14.550691+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:14.550691+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab293"
    },
    "model_benchmark_id": 1790,
    "analysis_method": "Score",
    "benchmark_id": "alpacaeval-2.0",
    "benchmark_name": "AlpacaEval 2.0",
    "created_at": "2025-07-19T19:56:15.041535+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.505,
    "score": 0.505,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:15.041535+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab295"
    },
    "model_benchmark_id": 1456,
    "analysis_method": "Score",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.104170+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.762,
    "score": 0.762,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:14.104170+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab297"
    },
    "model_benchmark_id": 974,
    "analysis_method": "Score",
    "benchmark_id": "bbh",
    "benchmark_name": "BBH",
    "created_at": "2025-07-19T19:56:13.046694+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.843,
    "score": 0.843,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:13.046694+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab299"
    },
    "model_benchmark_id": 1797,
    "analysis_method": "Score",
    "benchmark_id": "ds-arena-code",
    "benchmark_name": "DS-Arena-Code",
    "created_at": "2025-07-19T19:56:15.060324+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.631,
    "score": 0.631,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:15.060324+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab29b"
    },
    "model_benchmark_id": 1796,
    "analysis_method": "Score",
    "benchmark_id": "ds-fim-eval",
    "benchmark_name": "DS-FIM-Eval",
    "created_at": "2025-07-19T19:56:15.056487+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.783,
    "score": 0.783,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:15.056487+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab29d"
    },
    "model_benchmark_id": 1000,
    "analysis_method": "Score",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.091340+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.951,
    "score": 0.951,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:13.091340+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab29f"
    },
    "model_benchmark_id": 792,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.656959+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:12.656959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2a1"
    },
    "model_benchmark_id": 1789,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval-mul",
    "benchmark_name": "HumanEval-Mul",
    "created_at": "2025-07-19T19:56:15.037209+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.738,
    "score": 0.738,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:15.037209+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2a3"
    },
    "model_benchmark_id": 1795,
    "analysis_method": "Score",
    "benchmark_id": "livecodebench(01-09)",
    "benchmark_name": "LiveCodeBench(01-09)",
    "created_at": "2025-07-19T19:56:15.052983+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.418,
    "score": 0.418,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:15.052983+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2a5"
    },
    "model_benchmark_id": 411,
    "analysis_method": "Score",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.874944+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.747,
    "score": 0.747,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:11.874944+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2a7"
    },
    "model_benchmark_id": 94,
    "analysis_method": "Score",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.277903+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:11.277903+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2a9"
    },
    "model_benchmark_id": 1608,
    "analysis_method": "Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.525856+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://www.deepseek.com/",
    "updated_at": "2025-07-19T19:56:14.525856+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2ab"
    },
    "model_benchmark_id": 1345,
    "analysis_method": "Score",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.830793+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v2.5",
    "normalized_score": 0.168,
    "score": 0.168,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V2.5",
    "updated_at": "2025-07-19T19:56:13.830793+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2ad"
    },
    "model_benchmark_id": 465,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.984093+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-8b",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "updated_at": "2025-07-19T19:56:11.985582+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2af"
    },
    "model_benchmark_id": 314,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.699365+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-8b",
    "normalized_score": 0.49,
    "score": 0.49,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "updated_at": "2025-07-19T19:56:11.699365+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2b1"
    },
    "model_benchmark_id": 1134,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.384499+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-8b",
    "normalized_score": 0.396,
    "score": 0.396,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "updated_at": "2025-07-19T19:56:13.384499+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2b3"
    },
    "model_benchmark_id": 502,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.046427+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-8b",
    "normalized_score": 0.891,
    "score": 0.891,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "updated_at": "2025-07-19T19:56:12.046427+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2b5"
    },
    "model_benchmark_id": 467,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.987242+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-70b",
    "normalized_score": 0.867,
    "score": 0.867,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "updated_at": "2025-07-19T19:56:11.989505+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2b7"
    },
    "model_benchmark_id": 315,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.700874+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-70b",
    "normalized_score": 0.652,
    "score": 0.652,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "updated_at": "2025-07-19T19:56:11.700874+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2b9"
    },
    "model_benchmark_id": 1135,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.386337+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-70b",
    "normalized_score": 0.575,
    "score": 0.575,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "updated_at": "2025-07-19T19:56:13.386337+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2bb"
    },
    "model_benchmark_id": 503,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.048302+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-llama-70b",
    "normalized_score": 0.945,
    "score": 0.945,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "updated_at": "2025-07-19T19:56:12.048302+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2bd"
    },
    "model_benchmark_id": 469,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.991646+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-14b",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "updated_at": "2025-07-19T19:56:11.993518+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2bf"
    },
    "model_benchmark_id": 316,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.702334+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-14b",
    "normalized_score": 0.591,
    "score": 0.591,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "updated_at": "2025-07-19T19:56:11.702334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2c1"
    },
    "model_benchmark_id": 1136,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.387993+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-14b",
    "normalized_score": 0.531,
    "score": 0.531,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "updated_at": "2025-07-19T19:56:13.387993+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2c3"
    },
    "model_benchmark_id": 504,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.050287+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-14b",
    "normalized_score": 0.939,
    "score": 0.939,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "updated_at": "2025-07-19T19:56:12.050287+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2c5"
    },
    "model_benchmark_id": 471,
    "analysis_method": "Cons@64",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.995645+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-32b",
    "normalized_score": 0.833,
    "score": 0.833,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "updated_at": "2025-07-19T19:56:11.997517+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2c7"
    },
    "model_benchmark_id": 317,
    "analysis_method": "Diamond, Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.703902+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-32b",
    "normalized_score": 0.621,
    "score": 0.621,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "updated_at": "2025-07-19T19:56:11.703902+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2c9"
    },
    "model_benchmark_id": 1137,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.389729+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-32b",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "updated_at": "2025-07-19T19:56:13.389729+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2cb"
    },
    "model_benchmark_id": 505,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.051744+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-r1-distill-qwen-32b",
    "normalized_score": 0.943,
    "score": 0.943,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "updated_at": "2025-07-19T19:56:12.051744+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2cd"
    },
    "model_benchmark_id": 9501,
    "analysis_method": "Non-Thinking mode",
    "benchmark_id": "mmlu-redux",
    "benchmark_name": "MMLU-Redux",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.918,
    "score": 0.918,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 91.8%, Thinking: 93.7%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2cf"
    },
    "model_benchmark_id": 9502,
    "analysis_method": "Non-Thinking mode",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.837,
    "score": 0.837,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 83.7%, Thinking: 84.8%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2d1"
    },
    "model_benchmark_id": 9503,
    "analysis_method": "Pass@1, Non-Thinking mode",
    "benchmark_id": "gpqa-diamond",
    "benchmark_name": "GPQA-Diamond",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.749,
    "score": 0.749,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 74.9%, Thinking: 80.1%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2d3"
    },
    "model_benchmark_id": 9504,
    "analysis_method": "Pass@1, Thinking mode, text-only subset",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.159,
    "score": 0.159,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Thinking mode only, text-only subset",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2d5"
    },
    "model_benchmark_id": 9505,
    "analysis_method": "Thinking mode with search agent",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.3,
    "score": 0.3,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Search agent with commercial API + webpage filter + 128K context",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2d7"
    },
    "model_benchmark_id": 9506,
    "analysis_method": "Thinking mode with search agent",
    "benchmark_id": "browsecomp-zh",
    "benchmark_name": "BrowseComp-zh",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.492,
    "score": 0.492,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Search agent with commercial API + webpage filter + 128K context",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2d9"
    },
    "model_benchmark_id": 9507,
    "analysis_method": "Thinking mode with search agent",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.934,
    "score": 0.934,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Search agent evaluation",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2db"
    },
    "model_benchmark_id": 9508,
    "analysis_method": "Pass@1, 2408-2505, Non-Thinking mode",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.564,
    "score": 0.564,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 56.4%, Thinking: 74.8%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2dd"
    },
    "model_benchmark_id": 9509,
    "analysis_method": "Div1 Rating, Thinking mode",
    "benchmark_id": "codeforces",
    "benchmark_name": "Codeforces",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.697,
    "score": 0.697,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Codeforces Div1 rating in thinking mode",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2df"
    },
    "model_benchmark_id": 9510,
    "analysis_method": "Non-Thinking mode",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 68.4%, Thinking: 76.3%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2e1"
    },
    "model_benchmark_id": 9511,
    "analysis_method": "Agent mode, Non-Thinking",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.66,
    "score": 0.66,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with internal code agent framework",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2e3"
    },
    "model_benchmark_id": 9512,
    "analysis_method": "Agent mode, Non-Thinking",
    "benchmark_id": "swe-bench-multilingual",
    "benchmark_name": "SWE-Bench Multilingual",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.545,
    "score": 0.545,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Evaluated with internal code agent framework",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2e5"
    },
    "model_benchmark_id": 9513,
    "analysis_method": "Terminus 1 framework, Non-Thinking",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-Bench",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.313,
    "score": 0.313,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2e7"
    },
    "model_benchmark_id": 9514,
    "analysis_method": "Pass@1, Non-Thinking mode",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.663,
    "score": 0.663,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 66.3%, Thinking: 93.1%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2e9"
    },
    "model_benchmark_id": 9515,
    "analysis_method": "Pass@1, Non-Thinking mode",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.498,
    "score": 0.498,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 49.8%, Thinking: 88.4%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2eb"
    },
    "model_benchmark_id": 9516,
    "analysis_method": "Pass@1, Non-Thinking mode",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-01-10T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3.1",
    "normalized_score": 0.335,
    "score": 0.335,
    "self_reported_source_link": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1",
    "updated_at": "2025-09-15T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": "Non-thinking: 33.5%, Thinking: 84.2%",
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2ed"
    },
    "model_benchmark_id": 473,
    "analysis_method": "Pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:11.999879+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3-0324",
    "normalized_score": 0.594,
    "score": 0.594,
    "self_reported_source_link": "https://api-docs.deepseek.com/news/news250325",
    "updated_at": "2025-07-19T19:56:11.999879+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2ef"
    },
    "model_benchmark_id": 318,
    "analysis_method": "Pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.705537+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3-0324",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://api-docs.deepseek.com/news/news250325",
    "updated_at": "2025-07-19T19:56:11.705537+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2f1"
    },
    "model_benchmark_id": 1138,
    "analysis_method": "Pass@1",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.392232+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3-0324",
    "normalized_score": 0.492,
    "score": 0.492,
    "self_reported_source_link": "https://api-docs.deepseek.com/news/news250325",
    "updated_at": "2025-07-19T19:56:13.392232+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2f3"
    },
    "model_benchmark_id": 506,
    "analysis_method": "Pass@1",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.053333+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3-0324",
    "normalized_score": 0.94,
    "score": 0.94,
    "self_reported_source_link": "https://api-docs.deepseek.com/news/news250325",
    "updated_at": "2025-07-19T19:56:12.053333+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2f5"
    },
    "model_benchmark_id": 204,
    "analysis_method": "Exact Match",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.488686+00:00",
    "is_self_reported": true,
    "model_id": "deepseek-v3-0324",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://api-docs.deepseek.com/news/news250325",
    "updated_at": "2025-07-19T19:56:11.488686+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2f7"
    },
    "model_benchmark_id": 474,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.001587+00:00",
    "is_self_reported": true,
    "model_id": "grok-3-mini",
    "normalized_score": 0.958,
    "score": 0.958,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:12.001587+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2f9"
    },
    "model_benchmark_id": 693,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.452930+00:00",
    "is_self_reported": true,
    "model_id": "grok-3-mini",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:12.452930+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2fb"
    },
    "model_benchmark_id": 319,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.707259+00:00",
    "is_self_reported": true,
    "model_id": "grok-3-mini",
    "normalized_score": 0.84,
    "score": 0.84,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:11.707259+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2fd"
    },
    "model_benchmark_id": 1139,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.394024+00:00",
    "is_self_reported": true,
    "model_id": "grok-3-mini",
    "normalized_score": 0.804,
    "score": 0.804,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:13.394024+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab2ff"
    },
    "model_benchmark_id": 694,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.454500+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 1.0,
    "score": 1.0,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:12.454500+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab301"
    },
    "model_benchmark_id": 320,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.708827+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:11.708827+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab303"
    },
    "model_benchmark_id": 1798,
    "analysis_method": "accuracy",
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-07-19T19:56:15.063588+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 0.967,
    "score": 0.967,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:15.063588+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab305"
    },
    "model_benchmark_id": 722,
    "analysis_method": "accuracy",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.521361+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 0.507,
    "score": 0.507,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:12.521361+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab307"
    },
    "model_benchmark_id": 1140,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.396669+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 0.794,
    "score": 0.794,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.396669+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab309"
    },
    "model_benchmark_id": 1800,
    "analysis_method": "accuracy",
    "benchmark_id": "usamo25",
    "benchmark_name": "USAMO25",
    "created_at": "2025-07-19T19:56:15.070427+00:00",
    "is_self_reported": true,
    "model_id": "grok-4-heavy",
    "normalized_score": 0.619,
    "score": 0.619,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:15.070427+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab30b"
    },
    "model_benchmark_id": 893,
    "analysis_method": "accuracy",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.860093+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.932,
    "score": 0.932,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.860093+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab30d"
    },
    "model_benchmark_id": 321,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.710285+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.51,
    "score": 0.51,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.710285+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab30f"
    },
    "model_benchmark_id": 793,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.658802+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.658802+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab311"
    },
    "model_benchmark_id": 412,
    "analysis_method": "maj@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.876593+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.876593+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab313"
    },
    "model_benchmark_id": 531,
    "analysis_method": "accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.101817+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.681,
    "score": 0.681,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.101817+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab315"
    },
    "model_benchmark_id": 96,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.281643+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.862,
    "score": 0.862,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.281643+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab317"
    },
    "model_benchmark_id": 205,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.490630+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.490630+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab319"
    },
    "model_benchmark_id": 577,
    "analysis_method": "accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.186961+00:00",
    "is_self_reported": true,
    "model_id": "grok-2-mini",
    "normalized_score": 0.632,
    "score": 0.632,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.186961+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab31b"
    },
    "model_benchmark_id": 894,
    "analysis_method": "0-shot",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.861804+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.856,
    "score": 0.856,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.861804+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab31d"
    },
    "model_benchmark_id": 322,
    "analysis_method": "0-shot",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.711788+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.359,
    "score": 0.359,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.711788+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab31f"
    },
    "model_benchmark_id": 1001,
    "analysis_method": "8-shot",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.092882+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5",
    "updated_at": "2025-07-19T19:56:13.092882+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab321"
    },
    "model_benchmark_id": 794,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.660557+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.741,
    "score": 0.741,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5",
    "updated_at": "2025-07-19T19:56:12.660557+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab323"
    },
    "model_benchmark_id": 413,
    "analysis_method": "4-shot",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.878054+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.506,
    "score": 0.506,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5",
    "updated_at": "2025-07-19T19:56:11.878054+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab325"
    },
    "model_benchmark_id": 532,
    "analysis_method": "0-shot",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.103226+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.528,
    "score": 0.528,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.103226+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab327"
    },
    "model_benchmark_id": 97,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.283997+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.813,
    "score": 0.813,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5",
    "updated_at": "2025-07-19T19:56:11.283997+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab329"
    },
    "model_benchmark_id": 206,
    "analysis_method": "0-shot",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.492470+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.51,
    "score": 0.51,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.492470+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab32b"
    },
    "model_benchmark_id": 578,
    "analysis_method": "0-shot",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.189264+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.189264+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab32d"
    },
    "model_benchmark_id": 695,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.456102+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.917,
    "score": 0.917,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:12.456102+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab32f"
    },
    "model_benchmark_id": 1387,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-agi-v2",
    "benchmark_name": "ARC-AGI v2",
    "created_at": "2025-07-19T19:56:13.922021+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.159,
    "score": 0.159,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.922021+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab331"
    },
    "model_benchmark_id": 323,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.713248+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:11.713248+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab333"
    },
    "model_benchmark_id": 1799,
    "analysis_method": "accuracy",
    "benchmark_id": "hmmt25",
    "benchmark_name": "HMMT25",
    "created_at": "2025-07-19T19:56:15.065811+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:15.065811+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab335"
    },
    "model_benchmark_id": 723,
    "analysis_method": "accuracy",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.523105+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.4,
    "score": 0.4,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:12.523105+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab337"
    },
    "model_benchmark_id": 1141,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.399716+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.399716+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab339"
    },
    "model_benchmark_id": 1801,
    "analysis_method": "accuracy",
    "benchmark_id": "usamo25",
    "benchmark_name": "USAMO25",
    "created_at": "2025-07-19T19:56:15.071894+00:00",
    "is_self_reported": true,
    "model_id": "grok-4",
    "normalized_score": 0.375,
    "score": 0.375,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:15.071894+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab33b"
    },
    "model_benchmark_id": 475,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.003392+00:00",
    "is_self_reported": true,
    "model_id": "grok-3",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:12.003392+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab33d"
    },
    "model_benchmark_id": 696,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.457788+00:00",
    "is_self_reported": true,
    "model_id": "grok-3",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:12.457788+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab33f"
    },
    "model_benchmark_id": 324,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.714708+00:00",
    "is_self_reported": true,
    "model_id": "grok-3",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:11.714708+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab341"
    },
    "model_benchmark_id": 1142,
    "analysis_method": "accuracy",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.402422+00:00",
    "is_self_reported": true,
    "model_id": "grok-3",
    "normalized_score": 0.794,
    "score": 0.794,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:13.402422+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab343"
    },
    "model_benchmark_id": 579,
    "analysis_method": "accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.191844+00:00",
    "is_self_reported": true,
    "model_id": "grok-3",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://x.ai/blog/grok-3",
    "updated_at": "2025-07-19T19:56:12.191844+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab345"
    },
    "model_benchmark_id": 895,
    "analysis_method": "accuracy",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.863462+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.936,
    "score": 0.936,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.863462+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab347"
    },
    "model_benchmark_id": 325,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.716230+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.56,
    "score": 0.56,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.716230+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab349"
    },
    "model_benchmark_id": 795,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.662404+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.662404+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab34b"
    },
    "model_benchmark_id": 414,
    "analysis_method": "maj@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.880368+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.761,
    "score": 0.761,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.880368+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab34d"
    },
    "model_benchmark_id": 533,
    "analysis_method": "accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.104885+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.69,
    "score": 0.69,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.104885+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab34f"
    },
    "model_benchmark_id": 98,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.285517+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.285517+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab351"
    },
    "model_benchmark_id": 207,
    "analysis_method": "accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.494333+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.755,
    "score": 0.755,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:11.494333+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab353"
    },
    "model_benchmark_id": 580,
    "analysis_method": "accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.193698+00:00",
    "is_self_reported": true,
    "model_id": "grok-2",
    "normalized_score": 0.661,
    "score": 0.661,
    "self_reported_source_link": "https://x.ai/blog/grok-2",
    "updated_at": "2025-07-19T19:56:12.193698+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab355"
    },
    "model_benchmark_id": 1259,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.641849+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.883,
    "score": 0.883,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:13.641849+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab357"
    },
    "model_benchmark_id": 871,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.817786+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.761,
    "score": 0.761,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:12.817786+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab359"
    },
    "model_benchmark_id": 896,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.865566+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.856,
    "score": 0.856,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:12.865566+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab35b"
    },
    "model_benchmark_id": 534,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.106344+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.528,
    "score": 0.528,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:12.106344+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab35d"
    },
    "model_benchmark_id": 581,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.195047+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:12.195047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab35f"
    },
    "model_benchmark_id": 1638,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "realworldqa",
    "benchmark_name": "RealWorldQA",
    "created_at": "2025-07-19T19:56:14.606610+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.687,
    "score": 0.687,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:14.606610+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab361"
    },
    "model_benchmark_id": 915,
    "analysis_method": "zero-shot evaluation",
    "benchmark_id": "textvqa",
    "benchmark_name": "TextVQA",
    "created_at": "2025-07-19T19:56:12.908800+00:00",
    "is_self_reported": true,
    "model_id": "grok-1.5v",
    "normalized_score": 0.781,
    "score": 0.781,
    "self_reported_source_link": "https://x.ai/blog/grok-1.5v",
    "updated_at": "2025-07-19T19:56:12.908800+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab363"
    },
    "model_benchmark_id": 1792,
    "analysis_method": "Score",
    "benchmark_id": "alpacaeval-2.0",
    "benchmark_name": "AlpacaEval 2.0",
    "created_at": "2025-07-19T19:56:15.045290+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.3516,
    "score": 0.3516,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-4.0-tiny-preview",
    "updated_at": "2025-07-19T19:56:15.045290+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab365"
    },
    "model_benchmark_id": 1458,
    "analysis_method": "Score",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.108397+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.267,
    "score": 0.267,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-4.0-tiny-preview",
    "updated_at": "2025-07-19T19:56:14.108397+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab367"
    },
    "model_benchmark_id": 1805,
    "analysis_method": "Score",
    "benchmark_id": "attaq",
    "benchmark_name": "AttaQ",
    "created_at": "2025-07-19T19:56:15.083480+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.861,
    "score": 0.861,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:15.083480+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab369"
    },
    "model_benchmark_id": 1079,
    "analysis_method": "Score",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.247228+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.557,
    "score": 0.557,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:13.247228+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab36b"
    },
    "model_benchmark_id": 953,
    "analysis_method": "Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.009229+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.462,
    "score": 0.462,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:13.009229+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab36d"
    },
    "model_benchmark_id": 1002,
    "analysis_method": "Score",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.094422+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.701,
    "score": 0.701,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:13.094422+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab36f"
    },
    "model_benchmark_id": 796,
    "analysis_method": "Score",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.663900+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.824,
    "score": 0.824,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:12.663900+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab371"
    },
    "model_benchmark_id": 1442,
    "analysis_method": "Score",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.074105+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.783,
    "score": 0.783,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:14.074105+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab373"
    },
    "model_benchmark_id": 624,
    "analysis_method": "Score",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.285068+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.63,
    "score": 0.63,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:12.285068+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab375"
    },
    "model_benchmark_id": 99,
    "analysis_method": "Score",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.287184+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:11.287184+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab377"
    },
    "model_benchmark_id": 1802,
    "analysis_method": "Score",
    "benchmark_id": "popqa",
    "benchmark_name": "PopQA",
    "created_at": "2025-07-19T19:56:15.075622+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.229,
    "score": 0.229,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:15.075622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab379"
    },
    "model_benchmark_id": 140,
    "analysis_method": "Score",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.358910+00:00",
    "is_self_reported": true,
    "model_id": "granite-4.0-tiny-preview",
    "normalized_score": 0.581,
    "score": 0.581,
    "self_reported_source_link": "https://www.ibm.com/new/announcements/ibm-granite-4-0-tiny-preview-sneak-peek",
    "updated_at": "2025-07-19T19:56:11.358910+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab37b"
    },
    "model_benchmark_id": 476,
    "analysis_method": "Not specified",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.004852+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:12.004852+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab37d"
    },
    "model_benchmark_id": 1793,
    "analysis_method": "Score",
    "benchmark_id": "alpacaeval-2.0",
    "benchmark_name": "AlpacaEval 2.0",
    "created_at": "2025-07-19T19:56:15.046908+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.6268,
    "score": 0.6268,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:15.046908+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab37f"
    },
    "model_benchmark_id": 1459,
    "analysis_method": "Arena Hard benchmark evaluation",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.110277+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.5756,
    "score": 0.5756,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:14.110277+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab381"
    },
    "model_benchmark_id": 1806,
    "analysis_method": "Not specified (OLMES)",
    "benchmark_id": "attaq",
    "benchmark_name": "AttaQ",
    "created_at": "2025-07-19T19:56:15.085492+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:15.085492+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab383"
    },
    "model_benchmark_id": 1080,
    "analysis_method": "OLMES (Added regex for more efficient answer extraction)",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.249459+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.6913,
    "score": 0.6913,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:13.249459+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab385"
    },
    "model_benchmark_id": 954,
    "analysis_method": "OLMES (Modified implementation)",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.010691+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.5936,
    "score": 0.5936,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:13.010691+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab387"
    },
    "model_benchmark_id": 1003,
    "analysis_method": "OLMES",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.095998+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.8089,
    "score": 0.8089,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:13.095998+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab389"
    },
    "model_benchmark_id": 797,
    "analysis_method": "OLMES",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.665403+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.8973,
    "score": 0.8973,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:12.665403+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab38b"
    },
    "model_benchmark_id": 1443,
    "analysis_method": "OLMES",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.076877+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.8609,
    "score": 0.8609,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:14.076877+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab38d"
    },
    "model_benchmark_id": 625,
    "analysis_method": "OLMES",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.286600+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.7482,
    "score": 0.7482,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:12.286600+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab38f"
    },
    "model_benchmark_id": 507,
    "analysis_method": "Not specified",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.054762+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.6902,
    "score": 0.6902,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:12.054762+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab391"
    },
    "model_benchmark_id": 100,
    "analysis_method": "Score",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.288937+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.6554,
    "score": 0.6554,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:11.288937+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab393"
    },
    "model_benchmark_id": 1803,
    "analysis_method": "Score",
    "benchmark_id": "popqa",
    "benchmark_name": "PopQA",
    "created_at": "2025-07-19T19:56:15.077308+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.2617,
    "score": 0.2617,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:15.077308+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab395"
    },
    "model_benchmark_id": 141,
    "analysis_method": "Score",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.360858+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-instruct",
    "normalized_score": 0.6686,
    "score": 0.6686,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-instruct",
    "updated_at": "2025-07-19T19:56:11.360858+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab397"
    },
    "model_benchmark_id": 1409,
    "analysis_method": "Score",
    "benchmark_id": "agieval",
    "benchmark_name": "AGIEval",
    "created_at": "2025-07-19T19:56:13.976963+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.493,
    "score": 0.493,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:13.976963+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab399"
    },
    "model_benchmark_id": 477,
    "analysis_method": "Not specified",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.006332+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:12.006332+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab39b"
    },
    "model_benchmark_id": 1794,
    "analysis_method": "Score",
    "benchmark_id": "alpacaeval-2.0",
    "benchmark_name": "AlpacaEval 2.0",
    "created_at": "2025-07-19T19:56:15.048676+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.6268,
    "score": 0.6268,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:15.048676+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab39d"
    },
    "model_benchmark_id": 23,
    "analysis_method": "Score",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.131347+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.5084,
    "score": 0.5084,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.131347+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab39f"
    },
    "model_benchmark_id": 1460,
    "analysis_method": "Arena Hard",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.111734+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.5756,
    "score": 0.5756,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:14.111734+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3a1"
    },
    "model_benchmark_id": 1807,
    "analysis_method": "Not specified (OLMES)",
    "benchmark_id": "attaq",
    "benchmark_name": "AttaQ",
    "created_at": "2025-07-19T19:56:15.087212+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:15.087212+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3a3"
    },
    "model_benchmark_id": 1081,
    "analysis_method": "OLMES (Added regex for more efficient answer extraction)",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.251020+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.6913,
    "score": 0.6913,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:13.251020+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3a5"
    },
    "model_benchmark_id": 955,
    "analysis_method": "Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.012196+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.3614,
    "score": 0.3614,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:13.012196+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3a7"
    },
    "model_benchmark_id": 1004,
    "analysis_method": "Score",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.098078+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.59,
    "score": 0.59,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:13.098078+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3a9"
    },
    "model_benchmark_id": 49,
    "analysis_method": "Score",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.186799+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.801,
    "score": 0.801,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.186799+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3ab"
    },
    "model_benchmark_id": 798,
    "analysis_method": "OLMES",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.666882+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.8973,
    "score": 0.8973,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:12.666882+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3ad"
    },
    "model_benchmark_id": 1444,
    "analysis_method": "OLMES",
    "benchmark_id": "humaneval+",
    "benchmark_name": "HumanEval+",
    "created_at": "2025-07-19T19:56:14.078662+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.8609,
    "score": 0.8609,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:14.078662+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3af"
    },
    "model_benchmark_id": 626,
    "analysis_method": "OLMES",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.288064+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.7482,
    "score": 0.7482,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:12.288064+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3b1"
    },
    "model_benchmark_id": 508,
    "analysis_method": "Not specified",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.056690+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.6902,
    "score": 0.6902,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:12.056690+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3b3"
    },
    "model_benchmark_id": 101,
    "analysis_method": "Score",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.290899+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.6389,
    "score": 0.6389,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.290899+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3b5"
    },
    "model_benchmark_id": 1808,
    "analysis_method": "Score",
    "benchmark_id": "nq",
    "benchmark_name": "NQ",
    "created_at": "2025-07-19T19:56:15.090844+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.365,
    "score": 0.365,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:15.090844+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3b7"
    },
    "model_benchmark_id": 1804,
    "analysis_method": "Score",
    "benchmark_id": "popqa",
    "benchmark_name": "PopQA",
    "created_at": "2025-07-19T19:56:15.078883+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.2617,
    "score": 0.2617,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:15.078883+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3b9"
    },
    "model_benchmark_id": 250,
    "analysis_method": "Score",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.577753+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.7818,
    "score": 0.7818,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.577753+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3bb"
    },
    "model_benchmark_id": 142,
    "analysis_method": "Score",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.362380+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.5215,
    "score": 0.5215,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.362380+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3bd"
    },
    "model_benchmark_id": 152,
    "analysis_method": "Score",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.387990+00:00",
    "is_self_reported": true,
    "model_id": "granite-3.3-8b-base",
    "normalized_score": 0.744,
    "score": 0.744,
    "self_reported_source_link": "https://huggingface.co/ibm-granite/granite-3.3-8b-base",
    "updated_at": "2025-07-19T19:56:11.387990+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3bf"
    },
    "model_benchmark_id": 7101,
    "analysis_method": "standard",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3c1"
    },
    "model_benchmark_id": 7102,
    "analysis_method": "Avg@32",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME24",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.894,
    "score": 0.894,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3c3"
    },
    "model_benchmark_id": 7103,
    "analysis_method": "standard",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.981,
    "score": 0.981,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3c5"
    },
    "model_benchmark_id": 7104,
    "analysis_method": "standard",
    "benchmark_id": "scicode",
    "benchmark_name": "SciCode",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.373,
    "score": 0.373,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3c7"
    },
    "model_benchmark_id": 7105,
    "analysis_method": "Avg@8",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3c9"
    },
    "model_benchmark_id": 7106,
    "analysis_method": "2407-2501",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.707,
    "score": 0.707,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3cb"
    },
    "model_benchmark_id": 7107,
    "analysis_method": "OpenHands v0.34.0",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-bench-Verified",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.576,
    "score": 0.576,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3cd"
    },
    "model_benchmark_id": 7108,
    "analysis_method": "optimized user simulator",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench-Retail",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.779,
    "score": 0.779,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3cf"
    },
    "model_benchmark_id": 7109,
    "analysis_method": "Full",
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3d1"
    },
    "model_benchmark_id": 7110,
    "analysis_method": "optimized user simulator",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench-Airline",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.608,
    "score": 0.608,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3d3"
    },
    "model_benchmark_id": 7111,
    "analysis_method": "standard",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.213,
    "score": 0.213,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3d5"
    },
    "model_benchmark_id": 7112,
    "analysis_method": "text-based questions only",
    "benchmark_id": "hle",
    "benchmark_name": "HLE",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.106,
    "score": 0.106,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3d7"
    },
    "model_benchmark_id": 7113,
    "analysis_method": "Estimated",
    "benchmark_id": "aa-index",
    "benchmark_name": "AA-Index",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.648,
    "score": 0.648,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3d9"
    },
    "model_benchmark_id": 7114,
    "analysis_method": "Terminus framework",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-Bench",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5-air",
    "normalized_score": 0.3,
    "score": 0.3,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3db"
    },
    "model_benchmark_id": 7001,
    "analysis_method": "standard",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3dd"
    },
    "model_benchmark_id": 7002,
    "analysis_method": "Avg@32",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME24",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.91,
    "score": 0.91,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3df"
    },
    "model_benchmark_id": 7003,
    "analysis_method": "standard",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.982,
    "score": 0.982,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3e1"
    },
    "model_benchmark_id": 7004,
    "analysis_method": "standard",
    "benchmark_id": "scicode",
    "benchmark_name": "SciCode",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.417,
    "score": 0.417,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3e3"
    },
    "model_benchmark_id": 7005,
    "analysis_method": "Avg@8",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.791,
    "score": 0.791,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3e5"
    },
    "model_benchmark_id": 7006,
    "analysis_method": "2407-2501",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.729,
    "score": 0.729,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3e7"
    },
    "model_benchmark_id": 7007,
    "analysis_method": "OpenHands v0.34.0",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-bench-Verified",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.642,
    "score": 0.642,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3e9"
    },
    "model_benchmark_id": 7008,
    "analysis_method": "optimized user simulator",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench-Retail",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3eb"
    },
    "model_benchmark_id": 7009,
    "analysis_method": "Full",
    "benchmark_id": "bfcl-v3",
    "benchmark_name": "BFCL-v3",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.778,
    "score": 0.778,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3ed"
    },
    "model_benchmark_id": 7010,
    "analysis_method": "optimized user simulator",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench-Airline",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3ef"
    },
    "model_benchmark_id": 7011,
    "analysis_method": "standard",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.264,
    "score": 0.264,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3f1"
    },
    "model_benchmark_id": 7012,
    "analysis_method": "text-based questions only",
    "benchmark_id": "hle",
    "benchmark_name": "HLE",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.144,
    "score": 0.144,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3f3"
    },
    "model_benchmark_id": 7013,
    "analysis_method": "Estimated",
    "benchmark_id": "aa-index",
    "benchmark_name": "AA-Index",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.677,
    "score": 0.677,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3f5"
    },
    "model_benchmark_id": 7014,
    "analysis_method": "Terminus framework",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-Bench",
    "created_at": "2025-07-28T00:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "glm-4.5",
    "normalized_score": 0.375,
    "score": 0.375,
    "self_reported_source_link": "https://z.ai/blog/glm-4.5",
    "updated_at": "2025-07-28T00:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3f7"
    },
    "model_benchmark_id": 697,
    "analysis_method": "Pass@1, Reasoning On",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.459628+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.584,
    "score": 0.584,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.459628+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3f9"
    },
    "model_benchmark_id": 1461,
    "analysis_method": "Score, Reasoning Off",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.113375+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.883,
    "score": 0.883,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.113375+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3fb"
    },
    "model_benchmark_id": 1585,
    "analysis_method": "Score, Reasoning On",
    "benchmark_id": "bfcl-v2",
    "benchmark_name": "BFCL v2",
    "created_at": "2025-07-19T19:56:14.452681+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.737,
    "score": 0.737,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.452681+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3fd"
    },
    "model_benchmark_id": 326,
    "analysis_method": "Pass@1, Reasoning On",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.717785+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.6667,
    "score": 0.6667,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:11.717785+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab3ff"
    },
    "model_benchmark_id": 509,
    "analysis_method": "Pass@1, Reasoning On",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.058280+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.966,
    "score": 0.966,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.058280+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab401"
    },
    "model_benchmark_id": 1192,
    "analysis_method": "Pass@1, Reasoning On",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.511549+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.913,
    "score": 0.913,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:13.511549+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab403"
    },
    "model_benchmark_id": 1609,
    "analysis_method": "Score, Reasoning On",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.527840+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.3-nemotron-super-49b-v1",
    "normalized_score": 0.917,
    "score": 0.917,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.527840+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab405"
    },
    "model_benchmark_id": 698,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.461794+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.471,
    "score": 0.471,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.461794+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab407"
    },
    "model_benchmark_id": 1586,
    "analysis_method": "Score, Reasoning",
    "benchmark_id": "bfcl-v2",
    "benchmark_name": "BFCL v2",
    "created_at": "2025-07-19T19:56:14.454860+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.636,
    "score": 0.636,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.454860+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab409"
    },
    "model_benchmark_id": 327,
    "analysis_method": "Diamond, Pass@1, Reasoning",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.719213+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.541,
    "score": 0.541,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:11.719213+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab40b"
    },
    "model_benchmark_id": 627,
    "analysis_method": "Strict Accuracy, Reasoning",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.289960+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.793,
    "score": 0.793,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.289960+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab40d"
    },
    "model_benchmark_id": 510,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.059893+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.954,
    "score": 0.954,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.059893+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab40f"
    },
    "model_benchmark_id": 1193,
    "analysis_method": "0-shot, Pass@1, Reasoning",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.512976+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:13.512976+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab411"
    },
    "model_benchmark_id": 1610,
    "analysis_method": "Score, Reasoning",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.530016+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-nano-8b-v1",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-nano-8b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.530016+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab413"
    },
    "model_benchmark_id": 699,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.463355+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.725,
    "score": 0.725,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.463355+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab415"
    },
    "model_benchmark_id": 1587,
    "analysis_method": "Score, Reasoning",
    "benchmark_id": "bfcl-v2",
    "benchmark_name": "BFCL v2",
    "created_at": "2025-07-19T19:56:14.456840+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.741,
    "score": 0.741,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:14.456840+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab417"
    },
    "model_benchmark_id": 328,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.721348+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.7601,
    "score": 0.7601,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:11.721348+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab419"
    },
    "model_benchmark_id": 628,
    "analysis_method": "Strict Accuracy, Reasoning",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.292359+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.8945,
    "score": 0.8945,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.292359+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab41b"
    },
    "model_benchmark_id": 1143,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.404565+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.6631,
    "score": 0.6631,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:13.404565+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab41d"
    },
    "model_benchmark_id": 511,
    "analysis_method": "Pass@1, Reasoning",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.061892+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-ultra-253b-v1",
    "normalized_score": 0.97,
    "score": 0.97,
    "self_reported_source_link": "https://build.nvidia.com/nvidia/llama-3_1-nemotron-ultra-253b-v1/modelcard",
    "updated_at": "2025-07-19T19:56:12.061892+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab41f"
    },
    "model_benchmark_id": 24,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.133318+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:11.133318+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab421"
    },
    "model_benchmark_id": 1005,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.099846+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.9143,
    "score": 0.9143,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:13.099846+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab423"
    },
    "model_benchmark_id": 1811,
    "analysis_method": "Chat evaluation",
    "benchmark_id": "gsm8k-chat",
    "benchmark_name": "GSM8K Chat",
    "created_at": "2025-07-19T19:56:15.104394+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.8188,
    "score": 0.8188,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:15.104394+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab425"
    },
    "model_benchmark_id": 50,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.188734+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.8558,
    "score": 0.8558,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:11.188734+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab427"
    },
    "model_benchmark_id": 1812,
    "analysis_method": "Code evaluation (n=20)",
    "benchmark_id": "instruct-humaneval",
    "benchmark_name": "Instruct HumanEval",
    "created_at": "2025-07-19T19:56:15.108307+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.7384,
    "score": 0.7384,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:15.108307+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab429"
    },
    "model_benchmark_id": 102,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.292516+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:11.292516+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab42b"
    },
    "model_benchmark_id": 1810,
    "analysis_method": "Chat evaluation",
    "benchmark_id": "mmlu-chat",
    "benchmark_name": "MMLU Chat",
    "created_at": "2025-07-19T19:56:15.100072+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.8058,
    "score": 0.8058,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:15.100072+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab42d"
    },
    "model_benchmark_id": 1611,
    "analysis_method": "Chat evaluation",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.532800+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.0899,
    "score": 0.0899,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:14.532800+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab42f"
    },
    "model_benchmark_id": 143,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.363751+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.5863,
    "score": 0.5863,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:11.363751+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab431"
    },
    "model_benchmark_id": 153,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.390043+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.8453,
    "score": 0.8453,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:11.390043+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab433"
    },
    "model_benchmark_id": 1809,
    "analysis_method": "Standard evaluation",
    "benchmark_id": "xlsum-english",
    "benchmark_name": "XLSum English",
    "created_at": "2025-07-19T19:56:15.094560+00:00",
    "is_self_reported": true,
    "model_id": "llama-3.1-nemotron-70b-instruct",
    "normalized_score": 0.3161,
    "score": 0.3161,
    "self_reported_source_link": "https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b/",
    "updated_at": "2025-07-19T19:56:15.094560+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab435"
    },
    "model_benchmark_id": 25,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.134917+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.964,
    "score": 0.964,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.134917+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab437"
    },
    "model_benchmark_id": 1082,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.252820+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.252820+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab439"
    },
    "model_benchmark_id": 956,
    "analysis_method": "3-shot, F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.013702+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.831,
    "score": 0.831,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.013702+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab43b"
    },
    "model_benchmark_id": 329,
    "analysis_method": "0-shot CoT - Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.722913+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.504,
    "score": 0.504,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.722913+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab43d"
    },
    "model_benchmark_id": 1006,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.101310+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.95,
    "score": 0.95,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.101310+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab43f"
    },
    "model_benchmark_id": 51,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.190975+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.954,
    "score": 0.954,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.190975+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab441"
    },
    "model_benchmark_id": 799,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.668395+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.849,
    "score": 0.849,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:12.668395+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab443"
    },
    "model_benchmark_id": 415,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.882261+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.601,
    "score": 0.601,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.882261+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab445"
    },
    "model_benchmark_id": 1290,
    "analysis_method": "0-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.701952+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.907,
    "score": 0.907,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.701952+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab447"
    },
    "model_benchmark_id": 103,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.294591+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.294591+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab449"
    },
    "model_benchmark_id": 208,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.496438+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-opus-20240229",
    "normalized_score": 0.685,
    "score": 0.685,
    "self_reported_source_link": "https://arxiv.org/pdf/2406.01574",
    "updated_at": "2025-07-19T19:56:11.496438+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab44b"
    },
    "model_benchmark_id": 2001,
    "analysis_method": "OpenAI o3 with thinking mode enabled (Python + browser tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.243,
    "score": 0.243,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab44d"
    },
    "model_benchmark_id": 2002,
    "analysis_method": "OpenAI o3 with thinking mode enabled (no tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.147,
    "score": 0.147,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab44f"
    },
    "model_benchmark_id": 2003,
    "analysis_method": "GPT-4o without thinking mode (no tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.053,
    "score": 0.053,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab451"
    },
    "model_benchmark_id": 2004,
    "analysis_method": "OpenAI o3 with thinking mode enabled - Multi-turn instruction following benchmark.",
    "benchmark_id": "scale-multichallenge",
    "benchmark_name": "Scale MultiChallenge",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab453"
    },
    "model_benchmark_id": 2005,
    "analysis_method": "GPT-4o without thinking mode - Multi-turn instruction following benchmark.",
    "benchmark_id": "scale-multichallenge",
    "benchmark_name": "Scale MultiChallenge",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.403,
    "score": 0.403,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab455"
    },
    "model_benchmark_id": 2006,
    "analysis_method": "OpenAI o3 with thinking mode enabled - Instruction-following in freeform writing.",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.984,
    "score": 0.984,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab457"
    },
    "model_benchmark_id": 2007,
    "analysis_method": "OpenAI o3 with thinking mode - Function calling benchmark (airline domain).",
    "benchmark_id": "tau2-airline",
    "benchmark_name": "Tau2 airline",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.648,
    "score": 0.648,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab459"
    },
    "model_benchmark_id": 2008,
    "analysis_method": "OpenAI o3 with thinking mode - Function calling benchmark (retail domain).",
    "benchmark_id": "tau2-retail",
    "benchmark_name": "Tau2 retail",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.802,
    "score": 0.802,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab45b"
    },
    "model_benchmark_id": 26,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.136363+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.932,
    "score": 0.932,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.136363+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab45d"
    },
    "model_benchmark_id": 1083,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.254531+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.829,
    "score": 0.829,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.254531+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab45f"
    },
    "model_benchmark_id": 957,
    "analysis_method": "3-shot, F1 score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.015601+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.789,
    "score": 0.789,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.015601+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab461"
    },
    "model_benchmark_id": 330,
    "analysis_method": "0-shot CoT - Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.724379+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.404,
    "score": 0.404,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.724379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab463"
    },
    "model_benchmark_id": 1007,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.102758+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.923,
    "score": 0.923,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.102758+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab465"
    },
    "model_benchmark_id": 52,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.193193+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.193193+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab467"
    },
    "model_benchmark_id": 800,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.670119+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.73,
    "score": 0.73,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:12.670119+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab469"
    },
    "model_benchmark_id": 416,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.884160+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.884160+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab46b"
    },
    "model_benchmark_id": 1291,
    "analysis_method": "0-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.703593+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.835,
    "score": 0.835,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:13.703593+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab46d"
    },
    "model_benchmark_id": 104,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.296409+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-family",
    "updated_at": "2025-07-19T19:56:11.296409+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab46f"
    },
    "model_benchmark_id": 209,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.498008+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-sonnet-20240229",
    "normalized_score": 0.568,
    "score": 0.568,
    "self_reported_source_link": "https://arxiv.org/pdf/2406.01574",
    "updated_at": "2025-07-19T19:56:11.498008+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab471"
    },
    "model_benchmark_id": 958,
    "analysis_method": "3-shot F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.017079+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.831,
    "score": 0.831,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:13.017079+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab473"
    },
    "model_benchmark_id": 331,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.725835+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.416,
    "score": 0.416,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:11.725835+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab475"
    },
    "model_benchmark_id": 801,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.671817+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.881,
    "score": 0.881,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:12.671817+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab477"
    },
    "model_benchmark_id": 417,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.885732+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.694,
    "score": 0.694,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:11.885732+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab479"
    },
    "model_benchmark_id": 1292,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.705114+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.856,
    "score": 0.856,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:13.705114+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab47b"
    },
    "model_benchmark_id": 210,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.499754+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.65,
    "score": 0.65,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:11.499754+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab47d"
    },
    "model_benchmark_id": 1347,
    "analysis_method": "standard",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.836974+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.406,
    "score": 0.406,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:13.836974+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab47f"
    },
    "model_benchmark_id": 1771,
    "analysis_method": "standard",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:14.997081+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.228,
    "score": 0.228,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:14.997081+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab481"
    },
    "model_benchmark_id": 1757,
    "analysis_method": "standard",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.970473+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-haiku-20241022",
    "normalized_score": 0.51,
    "score": 0.51,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-haiku",
    "updated_at": "2025-07-19T19:56:14.970473+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab483"
    },
    "model_benchmark_id": 478,
    "analysis_method": "",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.007831+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.8,
    "score": 0.8,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:12.007831+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab485"
    },
    "model_benchmark_id": 700,
    "analysis_method": "Parallel test-time compute (footnotes 4, 5)",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.464908+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.548,
    "score": 0.548,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.464908+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab487"
    },
    "model_benchmark_id": 332,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.727330+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:11.727330+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab489"
    },
    "model_benchmark_id": 629,
    "analysis_method": "",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.294010+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.932,
    "score": 0.932,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:12.294010+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab48b"
    },
    "model_benchmark_id": 512,
    "analysis_method": "",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.063685+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.962,
    "score": 0.962,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:12.063685+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab48d"
    },
    "model_benchmark_id": 1478,
    "analysis_method": "Average over 14 non-English languages (footnote 3)",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.152773+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.861,
    "score": 0.861,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:14.152773+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab48f"
    },
    "model_benchmark_id": 582,
    "analysis_method": "validation",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.197283+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:12.197283+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab491"
    },
    "model_benchmark_id": 1348,
    "analysis_method": "With multiple parallel attempts and advanced scaffolding",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.838599+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.703,
    "score": 0.703,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:13.838599+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab493"
    },
    "model_benchmark_id": 1772,
    "analysis_method": "With prompt addendum to better utilize planning",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:14.999875+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.584,
    "score": 0.584,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:14.999875+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab495"
    },
    "model_benchmark_id": 1758,
    "analysis_method": "With prompt addendum to better utilize planning",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.971988+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-7-sonnet",
    "updated_at": "2025-07-19T19:56:14.971988+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab497"
    },
    "model_benchmark_id": 653,
    "analysis_method": "Parallel test-time compute, Claude Code agent framework (footnotes 2, 5)",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-bench",
    "created_at": "2025-07-19T19:56:12.350298+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-7-sonnet-20250219",
    "normalized_score": 0.352,
    "score": 0.352,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.350298+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab499"
    },
    "model_benchmark_id": 701,
    "analysis_method": "Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Nucleus sampling (top_p 0.95). Based on footnotes 4, 5 and blog appendix.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.466833+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.705,
    "score": 0.705,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.466833+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab49b"
    },
    "model_benchmark_id": 333,
    "analysis_method": "Diamond: Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Based on footnote 5 and blog appendix.",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.728759+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.754,
    "score": 0.754,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:11.728759+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab49d"
    },
    "model_benchmark_id": 1479,
    "analysis_method": "Extended thinking (up to 64K tokens). Average over 14 non-English languages. Based on blog appendix and footnote 3.",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.154357+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:14.154357+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab49f"
    },
    "model_benchmark_id": 583,
    "analysis_method": "Extended thinking (up to 64K tokens). Based on blog appendix.",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.199608+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.744,
    "score": 0.744,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.199608+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4a1"
    },
    "model_benchmark_id": 1349,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Based on footnote 5 and SWE-bench methodology for high compute.",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.840540+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.727,
    "score": 0.727,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:13.840540+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4a3"
    },
    "model_benchmark_id": 1773,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.002282+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.6,
    "score": 0.6,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:15.002282+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4a5"
    },
    "model_benchmark_id": 1759,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.973668+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:14.973668+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4a7"
    },
    "model_benchmark_id": 654,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Claude Code as agent framework. Based on footnotes 2 and 5.",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-bench",
    "created_at": "2025-07-19T19:56:12.353338+00:00",
    "is_self_reported": true,
    "model_id": "claude-sonnet-4-20250514",
    "normalized_score": 0.355,
    "score": 0.355,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.353338+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4a9"
    },
    "model_benchmark_id": 1260,
    "analysis_method": "test",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.643744+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.947,
    "score": 0.947,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:13.643744+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4ab"
    },
    "model_benchmark_id": 1084,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.256021+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.931,
    "score": 0.931,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:13.256021+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4ad"
    },
    "model_benchmark_id": 872,
    "analysis_method": "test, relaxed accuracy",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.819413+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:12.819413+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4af"
    },
    "model_benchmark_id": 897,
    "analysis_method": "test, ANLS score",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.867423+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.952,
    "score": 0.952,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:12.867423+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4b1"
    },
    "model_benchmark_id": 959,
    "analysis_method": "3-shot F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.018623+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:13.018623+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4b3"
    },
    "model_benchmark_id": 334,
    "analysis_method": "Maj@32 5-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.730271+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.672,
    "score": 0.672,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:11.730271+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4b5"
    },
    "model_benchmark_id": 1008,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.104248+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.964,
    "score": 0.964,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:13.104248+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4b7"
    },
    "model_benchmark_id": 802,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.673295+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.937,
    "score": 0.937,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:12.673295+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4b9"
    },
    "model_benchmark_id": 418,
    "analysis_method": "standard",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.887521+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.783,
    "score": 0.783,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:11.887521+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4bb"
    },
    "model_benchmark_id": 535,
    "analysis_method": "testmini",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.108158+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.677,
    "score": 0.677,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:12.108158+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4bd"
    },
    "model_benchmark_id": 1293,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.707042+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:13.707042+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4bf"
    },
    "model_benchmark_id": 105,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.298011+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.904,
    "score": 0.904,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:11.298011+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4c1"
    },
    "model_benchmark_id": 211,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.501331+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro",
    "updated_at": "2025-07-19T19:56:11.501331+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4c3"
    },
    "model_benchmark_id": 584,
    "analysis_method": "validation",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.201491+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.683,
    "score": 0.683,
    "self_reported_source_link": "https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf",
    "updated_at": "2025-07-19T19:56:12.201491+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4c5"
    },
    "model_benchmark_id": 1814,
    "analysis_method": "standard",
    "benchmark_id": "osworld-extended",
    "benchmark_name": "OSWorld Extended",
    "created_at": "2025-07-19T19:56:15.117020+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.22,
    "score": 0.22,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:15.117020+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4c7"
    },
    "model_benchmark_id": 1813,
    "analysis_method": "standard",
    "benchmark_id": "osworld-screenshot-only",
    "benchmark_name": "OSWorld Screenshot-only",
    "created_at": "2025-07-19T19:56:15.112291+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.149,
    "score": 0.149,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:15.112291+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4c9"
    },
    "model_benchmark_id": 1350,
    "analysis_method": "standard",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.842061+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.49,
    "score": 0.49,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:13.842061+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4cb"
    },
    "model_benchmark_id": 1774,
    "analysis_method": "standard",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.003886+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.46,
    "score": 0.46,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:15.003886+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4cd"
    },
    "model_benchmark_id": 1760,
    "analysis_method": "standard",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.975456+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20241022",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://www.anthropic.com/news/3-5-models-and-computer-use",
    "updated_at": "2025-07-19T19:56:14.975456+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4cf"
    },
    "model_benchmark_id": 27,
    "analysis_method": "25-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.137830+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.892,
    "score": 0.892,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:11.137830+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4d1"
    },
    "model_benchmark_id": 1085,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.257814+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.737,
    "score": 0.737,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:13.257814+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4d3"
    },
    "model_benchmark_id": 960,
    "analysis_method": "3-shot, F1 score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.020609+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.784,
    "score": 0.784,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:13.020609+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4d5"
    },
    "model_benchmark_id": 335,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.731729+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.333,
    "score": 0.333,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:11.731729+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4d7"
    },
    "model_benchmark_id": 1009,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.105970+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.889,
    "score": 0.889,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:13.105970+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4d9"
    },
    "model_benchmark_id": 53,
    "analysis_method": "10-shot",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.195028+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.859,
    "score": 0.859,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:11.195028+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4db"
    },
    "model_benchmark_id": 803,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.674804+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.759,
    "score": 0.759,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:12.674804+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4dd"
    },
    "model_benchmark_id": 419,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.889123+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.389,
    "score": 0.389,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:11.889123+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4df"
    },
    "model_benchmark_id": 1294,
    "analysis_method": "0-shot",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.709200+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.751,
    "score": 0.751,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:13.709200+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4e1"
    },
    "model_benchmark_id": 106,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.299416+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-haiku-20240307",
    "normalized_score": 0.752,
    "score": 0.752,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-haiku",
    "updated_at": "2025-07-19T19:56:11.299416+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4e3"
    },
    "model_benchmark_id": 1086,
    "analysis_method": "3-shot CoT",
    "benchmark_id": "big-bench-hard",
    "benchmark_name": "BIG-Bench Hard",
    "created_at": "2025-07-19T19:56:13.259482+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.931,
    "score": 0.931,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:13.259482+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4e5"
    },
    "model_benchmark_id": 961,
    "analysis_method": "3-shot F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.021997+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:13.021997+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4e7"
    },
    "model_benchmark_id": 336,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.733246+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.594,
    "score": 0.594,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:11.733246+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4e9"
    },
    "model_benchmark_id": 1010,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.107479+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.964,
    "score": 0.964,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:13.107479+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4eb"
    },
    "model_benchmark_id": 804,
    "analysis_method": "0-shot",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.676235+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.92,
    "score": 0.92,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:12.676235+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4ed"
    },
    "model_benchmark_id": 420,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.891344+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.711,
    "score": 0.711,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:11.891344+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4ef"
    },
    "model_benchmark_id": 1295,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.710814+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:13.710814+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4f1"
    },
    "model_benchmark_id": 107,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.300996+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.904,
    "score": 0.904,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-3-5-sonnet",
    "updated_at": "2025-07-19T19:56:11.300996+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4f3"
    },
    "model_benchmark_id": 212,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.503274+00:00",
    "is_self_reported": true,
    "model_id": "claude-3-5-sonnet-20240620",
    "normalized_score": 0.761,
    "score": 0.761,
    "self_reported_source_link": "https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro",
    "updated_at": "2025-07-19T19:56:11.503274+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4f5"
    },
    "model_benchmark_id": 702,
    "analysis_method": "Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Nucleus sampling (top_p 0.95). Based on footnotes 4, 5 and blog appendix.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.468994+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.755,
    "score": 0.755,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.468994+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4f7"
    },
    "model_benchmark_id": 1388,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-agi-v2",
    "benchmark_name": "ARC-AGI v2",
    "created_at": "2025-07-19T19:56:13.923803+00:00",
    "is_self_reported": false,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.086,
    "score": 0.086,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.923803+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4f9"
    },
    "model_benchmark_id": 337,
    "analysis_method": "Diamond: Extended thinking (up to 64K tokens) with parallel test-time compute (multiple attempts, internal scoring model selection). Based on footnote 5 and blog appendix.",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.734764+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.796,
    "score": 0.796,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:11.734764+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4fb"
    },
    "model_benchmark_id": 1480,
    "analysis_method": "Extended thinking (up to 64K tokens). Average over 14 non-English languages. Based on blog appendix and footnote 3.",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.155829+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.888,
    "score": 0.888,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:14.155829+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4fd"
    },
    "model_benchmark_id": 1815,
    "analysis_method": "Extended thinking (up to 64K tokens). Based on blog appendix.",
    "benchmark_id": "mmmu-(validation)",
    "benchmark_name": "MMMU (validation)",
    "created_at": "2025-07-19T19:56:15.120938+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.765,
    "score": 0.765,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:15.120938+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab4ff"
    },
    "model_benchmark_id": 1351,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Based on footnote 5 and SWE-bench methodology for high compute.",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.843719+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.725,
    "score": 0.725,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:13.843719+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab501"
    },
    "model_benchmark_id": 1775,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.005622+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.596,
    "score": 0.596,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:15.005622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab503"
    },
    "model_benchmark_id": 1761,
    "analysis_method": "Extended thinking with tool use (up to 64K tokens, prompt addendum, increased max steps). Based on blog appendix and TAU-bench methodology.",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.977090+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:14.977090+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab505"
    },
    "model_benchmark_id": 655,
    "analysis_method": "Parallel test-time compute (multiple attempts, internal scoring model selection). No extended thinking. Claude Code as agent framework. Based on footnotes 2 and 5.",
    "benchmark_id": "terminal-bench",
    "benchmark_name": "Terminal-bench",
    "created_at": "2025-07-19T19:56:12.354970+00:00",
    "is_self_reported": true,
    "model_id": "claude-opus-4-20250514",
    "normalized_score": 0.392,
    "score": 0.392,
    "self_reported_source_link": "https://www.anthropic.com/news/claude-4",
    "updated_at": "2025-07-19T19:56:12.354970+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab507"
    },
    "model_benchmark_id": 28,
    "analysis_method": "Accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.139664+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.93,
    "score": 0.93,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:11.139664+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab509"
    },
    "model_benchmark_id": 1462,
    "analysis_method": "Accuracy",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.114965+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.654,
    "score": 0.654,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:14.114965+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab50b"
    },
    "model_benchmark_id": 338,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.736664+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.369,
    "score": 0.369,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:11.736664+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab50d"
    },
    "model_benchmark_id": 1011,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.109009+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.87,
    "score": 0.87,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:13.109009+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab50f"
    },
    "model_benchmark_id": 108,
    "analysis_method": "Chain-of-Thought accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.302578+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.812,
    "score": 0.812,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:11.302578+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab511"
    },
    "model_benchmark_id": 213,
    "analysis_method": "Chain-of-Thought accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.505024+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.535,
    "score": 0.535,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:11.505024+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab513"
    },
    "model_benchmark_id": 144,
    "analysis_method": "Accuracy",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.365684+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.583,
    "score": 0.583,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:11.365684+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab515"
    },
    "model_benchmark_id": 1816,
    "analysis_method": "Accuracy",
    "benchmark_id": "wild-bench",
    "benchmark_name": "Wild Bench",
    "created_at": "2025-07-19T19:56:15.125090+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-large",
    "normalized_score": 0.485,
    "score": 0.485,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Large",
    "updated_at": "2025-07-19T19:56:15.125090+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab517"
    },
    "model_benchmark_id": 29,
    "analysis_method": "Accuracy",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.141043+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:11.141043+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab519"
    },
    "model_benchmark_id": 1463,
    "analysis_method": "Accuracy",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.117178+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.461,
    "score": 0.461,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:14.117178+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab51b"
    },
    "model_benchmark_id": 339,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.739037+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.323,
    "score": 0.323,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:11.739037+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab51d"
    },
    "model_benchmark_id": 1012,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.110443+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.758,
    "score": 0.758,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:13.110443+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab51f"
    },
    "model_benchmark_id": 109,
    "analysis_method": "Chain-of-Thought accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.304017+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.697,
    "score": 0.697,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:11.304017+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab521"
    },
    "model_benchmark_id": 214,
    "analysis_method": "Chain-of-Thought accuracy",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.506893+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.425,
    "score": 0.425,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:11.506893+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab523"
    },
    "model_benchmark_id": 145,
    "analysis_method": "Accuracy",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.367476+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.541,
    "score": 0.541,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:11.367476+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab525"
    },
    "model_benchmark_id": 1817,
    "analysis_method": "Accuracy",
    "benchmark_id": "wild-bench",
    "benchmark_name": "Wild Bench",
    "created_at": "2025-07-19T19:56:15.127075+00:00",
    "is_self_reported": true,
    "model_id": "jamba-1.5-mini",
    "normalized_score": 0.424,
    "score": 0.424,
    "self_reported_source_link": "https://huggingface.co/ai21labs/AI21-Jamba-1.5-Mini",
    "updated_at": "2025-07-19T19:56:15.127075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab527"
    },
    "model_benchmark_id": 340,
    "analysis_method": "Diamond, 5-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.740584+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.4596,
    "score": 0.4596,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.741944+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab529"
    },
    "model_benchmark_id": 805,
    "analysis_method": "standard",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.677771+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.8841,
    "score": 0.8841,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:12.677771+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab52b"
    },
    "model_benchmark_id": 421,
    "analysis_method": "standard",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.893255+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.693,
    "score": 0.693,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.893255+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab52d"
    },
    "model_benchmark_id": 1194,
    "analysis_method": "standard",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.514872+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.7471,
    "score": 0.7471,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:13.514872+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab52f"
    },
    "model_benchmark_id": 110,
    "analysis_method": "-",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.306426+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.8062,
    "score": 0.8062,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.306426+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab531"
    },
    "model_benchmark_id": 215,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.508555+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.6676,
    "score": 0.6676,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.508555+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab533"
    },
    "model_benchmark_id": 585,
    "analysis_method": "CoT accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.203401+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.5927,
    "score": 0.5927,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:12.203401+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab535"
    },
    "model_benchmark_id": 237,
    "analysis_method": "TotalAcc, Correct",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.552923+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.1043,
    "score": 0.1043,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.552923+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab537"
    },
    "model_benchmark_id": 251,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.579482+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-instruct-2503",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503",
    "updated_at": "2025-07-19T19:56:11.579482+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab539"
    },
    "model_benchmark_id": 1819,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "commonsenseqa",
    "benchmark_name": "CommonSenseQA",
    "created_at": "2025-07-19T19:56:15.133096+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.704,
    "score": 0.704,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:15.133096+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab53b"
    },
    "model_benchmark_id": 54,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.196732+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.835,
    "score": 0.835,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:11.196732+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab53d"
    },
    "model_benchmark_id": 111,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.308247+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:11.308247+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab53f"
    },
    "model_benchmark_id": 1050,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "natural-questions",
    "benchmark_name": "Natural Questions",
    "created_at": "2025-07-19T19:56:13.191770+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.312,
    "score": 0.312,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:13.191770+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab541"
    },
    "model_benchmark_id": 1472,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "openbookqa",
    "benchmark_name": "OpenBookQA",
    "created_at": "2025-07-19T19:56:14.138075+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.606,
    "score": 0.606,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:14.138075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab543"
    },
    "model_benchmark_id": 252,
    "analysis_method": "5-shot evaluation",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.581108+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.738,
    "score": 0.738,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:11.581108+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab545"
    },
    "model_benchmark_id": 146,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "truthfulqa",
    "benchmark_name": "TruthfulQA",
    "created_at": "2025-07-19T19:56:11.369082+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.503,
    "score": 0.503,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:11.369082+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab547"
    },
    "model_benchmark_id": 154,
    "analysis_method": "0-shot evaluation",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.392106+00:00",
    "is_self_reported": true,
    "model_id": "mistral-nemo-instruct-2407",
    "normalized_score": 0.768,
    "score": 0.768,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407",
    "updated_at": "2025-07-19T19:56:11.392106+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab549"
    },
    "model_benchmark_id": 479,
    "analysis_method": "Score",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.009597+00:00",
    "is_self_reported": true,
    "model_id": "magistral-small-2506",
    "normalized_score": 0.7068,
    "score": 0.7068,
    "self_reported_source_link": "https://huggingface.co/mistralai/Magistral-Small-2506",
    "updated_at": "2025-07-19T19:56:12.009597+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab54b"
    },
    "model_benchmark_id": 703,
    "analysis_method": "Score",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.471565+00:00",
    "is_self_reported": true,
    "model_id": "magistral-small-2506",
    "normalized_score": 0.6276,
    "score": 0.6276,
    "self_reported_source_link": "https://huggingface.co/mistralai/Magistral-Small-2506",
    "updated_at": "2025-07-19T19:56:12.471565+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab54d"
    },
    "model_benchmark_id": 342,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.743610+00:00",
    "is_self_reported": true,
    "model_id": "magistral-small-2506",
    "normalized_score": 0.6818,
    "score": 0.6818,
    "self_reported_source_link": "https://huggingface.co/mistralai/Magistral-Small-2506",
    "updated_at": "2025-07-19T19:56:11.743610+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab54f"
    },
    "model_benchmark_id": 1144,
    "analysis_method": "v5",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.406640+00:00",
    "is_self_reported": true,
    "model_id": "magistral-small-2506",
    "normalized_score": 0.513,
    "score": 0.513,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:13.406640+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab551"
    },
    "model_benchmark_id": 665,
    "analysis_method": "accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.379075+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.471,
    "score": 0.471,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:12.379075+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab553"
    },
    "model_benchmark_id": 480,
    "analysis_method": "pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.011044+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.736,
    "score": 0.736,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:12.011044+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab555"
    },
    "model_benchmark_id": 704,
    "analysis_method": "pass@1",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.473748+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.649,
    "score": 0.649,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:12.473748+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab557"
    },
    "model_benchmark_id": 343,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.745089+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:11.745089+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab559"
    },
    "model_benchmark_id": 724,
    "analysis_method": "text subset",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.525031+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.09,
    "score": 0.09,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:12.525031+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab55b"
    },
    "model_benchmark_id": 1145,
    "analysis_method": "v6",
    "benchmark_id": "livecodebench",
    "benchmark_name": "LiveCodeBench",
    "created_at": "2025-07-19T19:56:13.408465+00:00",
    "is_self_reported": true,
    "model_id": "magistral-medium",
    "normalized_score": 0.503,
    "score": 0.503,
    "self_reported_source_link": "https://arxiv.org/pdf/2506.10910",
    "updated_at": "2025-07-19T19:56:13.410002+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab55d"
    },
    "model_benchmark_id": 1352,
    "analysis_method": "N/A",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.845635+00:00",
    "is_self_reported": true,
    "model_id": "devstral-medium-2507",
    "normalized_score": 0.616,
    "score": 0.616,
    "self_reported_source_link": "https://mistral.ai/news/devstral-2507",
    "updated_at": "2025-07-19T19:56:13.845635+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab55f"
    },
    "model_benchmark_id": 1261,
    "analysis_method": "BBox",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.645378+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.938,
    "score": 0.938,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:13.645378+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab561"
    },
    "model_benchmark_id": 873,
    "analysis_method": "CoT",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.820802+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.881,
    "score": 0.881,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:12.820802+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab563"
    },
    "model_benchmark_id": 898,
    "analysis_method": "ANLS",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.869454+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:12.869454+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab565"
    },
    "model_benchmark_id": 536,
    "analysis_method": "CoT",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.109764+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.694,
    "score": 0.694,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:12.109764+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab567"
    },
    "model_benchmark_id": 1732,
    "analysis_method": "GPT-4o Judge",
    "benchmark_id": "mm-mt-bench",
    "benchmark_name": "MM-MT-Bench",
    "created_at": "2025-07-19T19:56:14.885715+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.74,
    "score": 0.74,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:14.885715+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab569"
    },
    "model_benchmark_id": 586,
    "analysis_method": "CoT",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.205240+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:12.205240+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab56b"
    },
    "model_benchmark_id": 1574,
    "analysis_method": "VQA Match",
    "benchmark_id": "vqav2",
    "benchmark_name": "VQAv2",
    "created_at": "2025-07-19T19:56:14.414450+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-large",
    "normalized_score": 0.809,
    "score": 0.809,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-large/",
    "updated_at": "2025-07-19T19:56:14.414450+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab56d"
    },
    "model_benchmark_id": 1410,
    "analysis_method": "-",
    "benchmark_id": "agieval",
    "benchmark_name": "AGIEval",
    "created_at": "2025-07-19T19:56:13.978647+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.483,
    "score": 0.483,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:13.978647+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab56f"
    },
    "model_benchmark_id": 30,
    "analysis_method": "-",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.142536+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.719,
    "score": 0.719,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:11.142536+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab571"
    },
    "model_benchmark_id": 1464,
    "analysis_method": "",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.118772+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.709,
    "score": 0.709,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:14.118772+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab573"
    },
    "model_benchmark_id": 1820,
    "analysis_method": "-",
    "benchmark_id": "french-mmlu",
    "benchmark_name": "French MMLU",
    "created_at": "2025-07-19T19:56:15.137792+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.575,
    "score": 0.575,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:15.137792+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab575"
    },
    "model_benchmark_id": 806,
    "analysis_method": "-",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.681246+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.348,
    "score": 0.348,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:12.681246+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab577"
    },
    "model_benchmark_id": 422,
    "analysis_method": "-",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.895272+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.545,
    "score": 0.545,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:11.895272+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab579"
    },
    "model_benchmark_id": 1821,
    "analysis_method": "-",
    "benchmark_id": "mbpp-pass@1",
    "benchmark_name": "MBPP pass@1",
    "created_at": "2025-07-19T19:56:15.141858+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.7,
    "score": 0.7,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:15.141858+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab57b"
    },
    "model_benchmark_id": 112,
    "analysis_method": "-",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.309619+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.65,
    "score": 0.65,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:11.309619+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab57d"
    },
    "model_benchmark_id": 1612,
    "analysis_method": "Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.535003+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.83,
    "score": 0.83,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:14.535003+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab57f"
    },
    "model_benchmark_id": 253,
    "analysis_method": "-",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.582765+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.655,
    "score": 0.655,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:11.582765+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab581"
    },
    "model_benchmark_id": 155,
    "analysis_method": "-",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.394106+00:00",
    "is_self_reported": true,
    "model_id": "ministral-8b-instruct-2410",
    "normalized_score": 0.753,
    "score": 0.753,
    "self_reported_source_link": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410",
    "updated_at": "2025-07-19T19:56:11.394106+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab583"
    },
    "model_benchmark_id": 1465,
    "analysis_method": "Score",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-07-19T19:56:14.120697+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.876,
    "score": 0.876,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:14.120697+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab585"
    },
    "model_benchmark_id": 344,
    "analysis_method": "5 shot COT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.746578+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.453,
    "score": 0.453,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:11.746578+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab587"
    },
    "model_benchmark_id": 807,
    "analysis_method": "5 shot COT",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.682647+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.848,
    "score": 0.848,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:12.682647+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab589"
    },
    "model_benchmark_id": 630,
    "analysis_method": "Score",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.295754+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.829,
    "score": 0.829,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:12.295754+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab58b"
    },
    "model_benchmark_id": 423,
    "analysis_method": "instruct",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.896887+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.706,
    "score": 0.706,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:11.896887+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab58d"
    },
    "model_benchmark_id": 216,
    "analysis_method": "5 shot COT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.510254+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.663,
    "score": 0.663,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:11.510254+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab58f"
    },
    "model_benchmark_id": 1613,
    "analysis_method": "Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.537073+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.835,
    "score": 0.835,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:14.537073+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab591"
    },
    "model_benchmark_id": 1818,
    "analysis_method": "Score",
    "benchmark_id": "wild-bench",
    "benchmark_name": "Wild Bench",
    "created_at": "2025-07-19T19:56:15.128734+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-instruct-2501",
    "normalized_score": 0.522,
    "score": 0.522,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501",
    "updated_at": "2025-07-19T19:56:15.128734+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab593"
    },
    "model_benchmark_id": 1411,
    "analysis_method": "-",
    "benchmark_id": "agieval",
    "benchmark_name": "AGIEval",
    "created_at": "2025-07-19T19:56:13.980585+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:13.980585+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab595"
    },
    "model_benchmark_id": 31,
    "analysis_method": "0-shot",
    "benchmark_id": "arc-c",
    "benchmark_name": "ARC-C",
    "created_at": "2025-07-19T19:56:11.143960+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.9129,
    "score": 0.9129,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.143960+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab597"
    },
    "model_benchmark_id": 345,
    "analysis_method": "5-shot, CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.748111+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.3437,
    "score": 0.3437,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.748111+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab599"
    },
    "model_benchmark_id": 1013,
    "analysis_method": "5-shot, maj@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.111924+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.8073,
    "score": 0.8073,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:13.111924+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab59b"
    },
    "model_benchmark_id": 424,
    "analysis_method": "5-shot, MaJ",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.898806+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.4598,
    "score": 0.4598,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.898806+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab59d"
    },
    "model_benchmark_id": 1195,
    "analysis_method": "Pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.516399+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.6964,
    "score": 0.6964,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:13.516399+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab59f"
    },
    "model_benchmark_id": 113,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.311218+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.8073,
    "score": 0.8073,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.311218+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5a1"
    },
    "model_benchmark_id": 217,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.511957+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.5437,
    "score": 0.5437,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.511957+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5a3"
    },
    "model_benchmark_id": 254,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.585944+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-24b-base-2501",
    "normalized_score": 0.8032,
    "score": 0.8032,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501",
    "updated_at": "2025-07-19T19:56:11.585944+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5a5"
    },
    "model_benchmark_id": 346,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.749533+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-base-2503",
    "normalized_score": 0.375,
    "score": 0.375,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503",
    "updated_at": "2025-07-19T19:56:11.749533+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5a7"
    },
    "model_benchmark_id": 114,
    "analysis_method": "-",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.312907+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-base-2503",
    "normalized_score": 0.8101,
    "score": 0.8101,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503",
    "updated_at": "2025-07-19T19:56:11.312907+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5a9"
    },
    "model_benchmark_id": 218,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.513719+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-base-2503",
    "normalized_score": 0.5603,
    "score": 0.5603,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503",
    "updated_at": "2025-07-19T19:56:11.513719+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5ab"
    },
    "model_benchmark_id": 587,
    "analysis_method": "CoT accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.207080+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-base-2503",
    "normalized_score": 0.5927,
    "score": 0.5927,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503",
    "updated_at": "2025-07-19T19:56:12.207080+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5ad"
    },
    "model_benchmark_id": 255,
    "analysis_method": "5-shot",
    "benchmark_id": "triviaqa",
    "benchmark_name": "TriviaQA",
    "created_at": "2025-07-19T19:56:11.587622+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.1-24b-base-2503",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Base-2503",
    "updated_at": "2025-07-19T19:56:11.587622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5af"
    },
    "model_benchmark_id": 1353,
    "analysis_method": "OpenHands scaffold",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.847228+00:00",
    "is_self_reported": true,
    "model_id": "devstral-small-2507",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://huggingface.co/mistralai/Devstral-Small-2507",
    "updated_at": "2025-07-19T19:56:13.847228+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5b1"
    },
    "model_benchmark_id": 874,
    "analysis_method": "Chain of Thought (CoT)",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.822444+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.818,
    "score": 0.818,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.822444+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5b3"
    },
    "model_benchmark_id": 899,
    "analysis_method": "ANLS",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.871485+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.907,
    "score": 0.907,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.871485+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5b5"
    },
    "model_benchmark_id": 808,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.684555+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.684555+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5b7"
    },
    "model_benchmark_id": 631,
    "analysis_method": "Text Instruction Following Score",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.297384+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.613,
    "score": 0.613,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.297384+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5b9"
    },
    "model_benchmark_id": 425,
    "analysis_method": "Pass@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.900275+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.481,
    "score": 0.481,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:11.900275+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5bb"
    },
    "model_benchmark_id": 537,
    "analysis_method": "Chain of Thought (CoT)",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.111272+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.58,
    "score": 0.58,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.111272+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5bd"
    },
    "model_benchmark_id": 1822,
    "analysis_method": "Multimodal Instruction Following Score",
    "benchmark_id": "mm-if-eval",
    "benchmark_name": "MM IF-Eval",
    "created_at": "2025-07-19T19:56:15.145578+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.527,
    "score": 0.527,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:15.145578+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5bf"
    },
    "model_benchmark_id": 115,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.314507+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:11.314507+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5c1"
    },
    "model_benchmark_id": 1733,
    "analysis_method": "Multimodal MT-Bench Score",
    "benchmark_id": "mm-mt-bench",
    "benchmark_name": "MM-MT-Bench",
    "created_at": "2025-07-19T19:56:14.887276+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.605,
    "score": 0.605,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:14.887276+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5c3"
    },
    "model_benchmark_id": 588,
    "analysis_method": "Chain of Thought (CoT)",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.209409+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.525,
    "score": 0.525,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:12.209409+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5c5"
    },
    "model_benchmark_id": 1614,
    "analysis_method": "Text MT-Bench Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.539185+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.768,
    "score": 0.768,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:14.539185+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5c7"
    },
    "model_benchmark_id": 1575,
    "analysis_method": "VQA Match",
    "benchmark_id": "vqav2",
    "benchmark_name": "VQAv2",
    "created_at": "2025-07-19T19:56:14.416120+00:00",
    "is_self_reported": true,
    "model_id": "pixtral-12b-2409",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://mistral.ai/news/pixtral-12b/",
    "updated_at": "2025-07-19T19:56:14.416120+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5c9"
    },
    "model_benchmark_id": 1823,
    "analysis_method": "pass@1",
    "benchmark_id": "cruxeval-o",
    "benchmark_name": "CruxEval-O",
    "created_at": "2025-07-19T19:56:15.151317+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.513,
    "score": 0.513,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:15.151317+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5cb"
    },
    "model_benchmark_id": 809,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.685855+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:12.685855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5cd"
    },
    "model_benchmark_id": 1827,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval-average",
    "benchmark_name": "HumanEval-Average",
    "created_at": "2025-07-19T19:56:15.174206+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.615,
    "score": 0.615,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:15.174206+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5cf"
    },
    "model_benchmark_id": 1826,
    "analysis_method": "pass@1",
    "benchmark_id": "humanevalfim-average",
    "benchmark_name": "HumanEvalFIM-Average",
    "created_at": "2025-07-19T19:56:15.169908+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:15.169908+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5d1"
    },
    "model_benchmark_id": 1196,
    "analysis_method": "pass@1",
    "benchmark_id": "mbpp",
    "benchmark_name": "MBPP",
    "created_at": "2025-07-19T19:56:13.517772+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.782,
    "score": 0.782,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:13.517772+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5d3"
    },
    "model_benchmark_id": 1824,
    "analysis_method": "pass@1",
    "benchmark_id": "repobench",
    "benchmark_name": "RepoBench",
    "created_at": "2025-07-19T19:56:15.155008+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.34,
    "score": 0.34,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:15.155008+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5d5"
    },
    "model_benchmark_id": 1825,
    "analysis_method": "pass@1",
    "benchmark_id": "spider",
    "benchmark_name": "Spider",
    "created_at": "2025-07-19T19:56:15.159626+00:00",
    "is_self_reported": true,
    "model_id": "codestral-22b",
    "normalized_score": 0.635,
    "score": 0.635,
    "self_reported_source_link": "https://mistral.ai/news/codestral/",
    "updated_at": "2025-07-19T19:56:15.159626+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5d7"
    },
    "model_benchmark_id": 16767,
    "analysis_method": "-",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-08-03T22:06:15.105841+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.9291,
    "score": 0.9291,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.105841+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5d9"
    },
    "model_benchmark_id": 16768,
    "analysis_method": "v2",
    "benchmark_id": "arena-hard",
    "benchmark_name": "Arena Hard",
    "created_at": "2025-08-03T22:06:15.107885+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.107885+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5db"
    },
    "model_benchmark_id": 16769,
    "analysis_method": "-",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-08-03T22:06:15.109760+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.874,
    "score": 0.874,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.109760+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5dd"
    },
    "model_benchmark_id": 16770,
    "analysis_method": "-",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-08-03T22:06:15.111977+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.9486,
    "score": 0.9486,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.111977+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5df"
    },
    "model_benchmark_id": 16771,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-08-03T22:06:15.113518+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.4422,
    "score": 0.4422,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.113518+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5e1"
    },
    "model_benchmark_id": 16772,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-08-03T22:06:15.115179+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.4613,
    "score": 0.4613,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.115179+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5e3"
    },
    "model_benchmark_id": 16773,
    "analysis_method": "Pass@5",
    "benchmark_id": "humaneval-plus",
    "benchmark_name": "HumanEval Plus",
    "created_at": "2025-08-03T22:06:15.116763+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.929,
    "score": 0.929,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.116763+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5e5"
    },
    "model_benchmark_id": 16774,
    "analysis_method": "-",
    "benchmark_id": "if",
    "benchmark_name": "IF",
    "created_at": "2025-08-03T22:06:15.118250+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.8478,
    "score": 0.8478,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.118250+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5e7"
    },
    "model_benchmark_id": 16775,
    "analysis_method": "5-shot",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-08-03T22:06:15.119723+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.6942,
    "score": 0.6942,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.119723+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5e9"
    },
    "model_benchmark_id": 16776,
    "analysis_method": "-",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-08-03T22:06:15.121246+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.6709,
    "score": 0.6709,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.121246+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5eb"
    },
    "model_benchmark_id": 16777,
    "analysis_method": "Pass@5",
    "benchmark_id": "mbpp-plus",
    "benchmark_name": "MBPP Plus",
    "created_at": "2025-08-03T22:06:15.122828+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.7833,
    "score": 0.7833,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.122828+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5ed"
    },
    "model_benchmark_id": 16778,
    "analysis_method": "5-shot",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-08-03T22:06:15.124220+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.805,
    "score": 0.805,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.124220+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5ef"
    },
    "model_benchmark_id": 16779,
    "analysis_method": "5-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-08-03T22:06:15.125972+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.6906,
    "score": 0.6906,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.125972+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5f1"
    },
    "model_benchmark_id": 16780,
    "analysis_method": "-",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-08-03T22:06:15.127425+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.625,
    "score": 0.625,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.127425+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5f3"
    },
    "model_benchmark_id": 16781,
    "analysis_method": "TotalAcc",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-08-03T22:06:15.129114+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.121,
    "score": 0.121,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.129114+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5f5"
    },
    "model_benchmark_id": 16782,
    "analysis_method": "v2",
    "benchmark_id": "wild-bench",
    "benchmark_name": "Wild Bench",
    "created_at": "2025-08-03T22:06:15.130665+00:00",
    "is_self_reported": true,
    "model_id": "mistral-small-3.2-24b-instruct-2506",
    "normalized_score": 0.6533,
    "score": 0.6533,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "updated_at": "2025-08-03T22:06:15.130665+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5f7"
    },
    "model_benchmark_id": 1014,
    "analysis_method": "Accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.113392+00:00",
    "is_self_reported": true,
    "model_id": "mistral-large-2-2407",
    "normalized_score": 0.93,
    "score": 0.93,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Large-Instruct-2407",
    "updated_at": "2025-07-19T19:56:13.113392+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5f9"
    },
    "model_benchmark_id": 810,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.687406+00:00",
    "is_self_reported": true,
    "model_id": "mistral-large-2-2407",
    "normalized_score": 0.92,
    "score": 0.92,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Large-Instruct-2407",
    "updated_at": "2025-07-19T19:56:12.687406+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5fb"
    },
    "model_benchmark_id": 116,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.316024+00:00",
    "is_self_reported": true,
    "model_id": "mistral-large-2-2407",
    "normalized_score": 0.84,
    "score": 0.84,
    "self_reported_source_link": "https://mistral.ai/news/mistral-large-2407/",
    "updated_at": "2025-07-19T19:56:11.316024+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5fd"
    },
    "model_benchmark_id": 1828,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu-french",
    "benchmark_name": "MMLU French",
    "created_at": "2025-07-19T19:56:15.178056+00:00",
    "is_self_reported": true,
    "model_id": "mistral-large-2-2407",
    "normalized_score": 0.828,
    "score": 0.828,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Large-Instruct-2407",
    "updated_at": "2025-07-19T19:56:15.178056+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab5ff"
    },
    "model_benchmark_id": 1615,
    "analysis_method": "Score",
    "benchmark_id": "mt-bench",
    "benchmark_name": "MT-Bench",
    "created_at": "2025-07-19T19:56:14.541051+00:00",
    "is_self_reported": true,
    "model_id": "mistral-large-2-2407",
    "normalized_score": 0.863,
    "score": 0.863,
    "self_reported_source_link": "https://huggingface.co/mistralai/Mistral-Large-Instruct-2407",
    "updated_at": "2025-07-19T19:56:14.541051+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab607"
    },
    "model_benchmark_id": 2226,
    "analysis_method": "Diamond (without tools)",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-08-05T19:49:05.852855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-oss-20b",
    "normalized_score": 0.715,
    "score": 0.715,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-oss/",
    "updated_at": "2025-08-05T19:49:05.852855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab609"
    },
    "model_benchmark_id": 22226,
    "analysis_method": "Function calling",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail benchmark",
    "created_at": "2025-08-05T19:49:05.852855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-oss-20b",
    "normalized_score": 0.548,
    "score": 0.548,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-oss/",
    "updated_at": "2025-08-05T19:49:05.852855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab60c"
    },
    "model_benchmark_id": 666,
    "analysis_method": "accuracy (whole)",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.380617+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.813,
    "score": 0.813,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.380617+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab60e"
    },
    "model_benchmark_id": 481,
    "analysis_method": "accuracy (no tools)",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.012342+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.916,
    "score": 0.916,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.012342+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab610"
    },
    "model_benchmark_id": 705,
    "analysis_method": "pass@1 (no tools)",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.475926+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.475926+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab612"
    },
    "model_benchmark_id": 1832,
    "analysis_method": "test set evaluation",
    "benchmark_id": "arc-agi",
    "benchmark_name": "ARC-AGI",
    "created_at": "2025-07-19T19:56:15.190370+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://www.youtube.com/live/SKBG1sqdyIU?si=lWccKHt8bnttuYta",
    "updated_at": "2025-07-19T19:56:15.190370+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab614"
    },
    "model_benchmark_id": 1389,
    "analysis_method": "accuracy",
    "benchmark_id": "arc-agi-v2",
    "benchmark_name": "ARC-AGI v2",
    "created_at": "2025-07-19T19:56:13.925569+00:00",
    "is_self_reported": false,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.065,
    "score": 0.065,
    "self_reported_source_link": "https://x.com/xai/status/1943158495588815072",
    "updated_at": "2025-07-19T19:56:13.925569+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab616"
    },
    "model_benchmark_id": 1842,
    "analysis_method": "accuracy (with python + browsing)",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-07-19T19:56:15.215315+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.497,
    "score": 0.497,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.215315+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab618"
    },
    "model_benchmark_id": 1833,
    "analysis_method": "OpenAI o3 with thinking mode - Scientific figure reasoning and interpretation.",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.193874+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.786,
    "score": 0.786,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:15.193874+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab61a"
    },
    "model_benchmark_id": 1829,
    "analysis_method": "accuracy",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-19T19:56:15.181554+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.158,
    "score": 0.158,
    "self_reported_source_link": "https://www.youtube.com/live/SKBG1sqdyIU?si=lWccKHt8bnttuYta",
    "updated_at": "2025-07-19T19:56:15.181554+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab61c"
    },
    "model_benchmark_id": 347,
    "analysis_method": "OpenAI o3 - Diamond thinking no tools",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.750986+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.833,
    "score": 0.833,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:11.750986+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab61e"
    },
    "model_benchmark_id": 725,
    "analysis_method": "accuracy (no tools)",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.526631+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.202,
    "score": 0.202,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.526631+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab622"
    },
    "model_benchmark_id": 538,
    "analysis_method": "accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.112692+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.112692+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab624"
    },
    "model_benchmark_id": 589,
    "analysis_method": "OpenAI o3 with thinking mode - College-level visual problem-solving with multimodal reasoning.",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.211231+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.829,
    "score": 0.829,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:12.211231+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab626"
    },
    "model_benchmark_id": 1840,
    "analysis_method": "accuracy",
    "benchmark_id": "scale-multichallenge",
    "benchmark_name": "Scale MultiChallenge",
    "created_at": "2025-07-19T19:56:15.208929+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.565,
    "score": 0.565,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.208929+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab62c"
    },
    "model_benchmark_id": 2009,
    "analysis_method": "OpenAI o3 with thinking mode - Function calling benchmark (telecom domain).",
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "Tau2 telecom",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.582,
    "score": 0.582,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab62e"
    },
    "model_benchmark_id": 2010,
    "analysis_method": "OpenAI o3 with thinking mode - Graduate-level visual problem-solving with advanced multimodal reasoning.",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.764,
    "score": 0.764,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab630"
    },
    "model_benchmark_id": 2011,
    "analysis_method": "OpenAI o3 with thinking mode - Video-based multimodal reasoning (max frame 256).",
    "benchmark_id": "videommmu",
    "benchmark_name": "VideoMMMU",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.833,
    "score": 0.833,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab632"
    },
    "model_benchmark_id": 2012,
    "analysis_method": "OpenAI o3 with thinking mode - Multimodal spatial reasoning.",
    "benchmark_id": "erqa",
    "benchmark_name": "ERQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab634"
    },
    "model_benchmark_id": 1354,
    "analysis_method": "accuracy",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.851256+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.691,
    "score": 0.691,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:13.851256+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab636"
    },
    "model_benchmark_id": 1844,
    "analysis_method": "accuracy (avg Airline/Retail)",
    "benchmark_id": "tau-bench",
    "benchmark_name": "Tau-bench",
    "created_at": "2025-07-19T19:56:15.221470+00:00",
    "is_self_reported": true,
    "model_id": "o3-2025-04-16",
    "normalized_score": 0.63,
    "score": 0.63,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.221470+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab641"
    },
    "model_benchmark_id": 667,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.382631+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.347,
    "score": 0.347,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.382631+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab643"
    },
    "model_benchmark_id": 1331,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.801113+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.316,
    "score": 0.316,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:13.801113+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab645"
    },
    "model_benchmark_id": 482,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.013761+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.496,
    "score": 0.496,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.013761+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab647"
    },
    "model_benchmark_id": 1887,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-d",
    "benchmark_name": "CharXiv-D",
    "created_at": "2025-07-19T19:56:15.327509+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.884,
    "score": 0.884,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.327509+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab649"
    },
    "model_benchmark_id": 1834,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.195563+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.568,
    "score": 0.568,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.195563+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab64b"
    },
    "model_benchmark_id": 1857,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.255006+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.546,
    "score": 0.546,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.255006+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab64d"
    },
    "model_benchmark_id": 1892,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.339307+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.493,
    "score": 0.493,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.339307+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab64f"
    },
    "model_benchmark_id": 348,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.752534+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.65,
    "score": 0.65,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:11.752534+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab651"
    },
    "model_benchmark_id": 1872,
    "analysis_method": "GPT-4o without thinking mode - Multimodal spatial reasoning.",
    "benchmark_id": "erqa",
    "benchmark_name": "ERQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.352,
    "score": 0.352,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab653"
    },
    "model_benchmark_id": 1875,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-bfs->128k",
    "benchmark_name": "Graphwalks BFS >128k",
    "created_at": "2025-07-19T19:56:15.298708+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.15,
    "score": 0.15,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.298708+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab655"
    },
    "model_benchmark_id": 1878,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.306151+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.605,
    "score": 0.605,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.306151+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab657"
    },
    "model_benchmark_id": 1884,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents->128k",
    "benchmark_name": "Graphwalks parents >128k",
    "created_at": "2025-07-19T19:56:15.319823+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.11,
    "score": 0.11,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.319823+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab659"
    },
    "model_benchmark_id": 632,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.299050+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.841,
    "score": 0.841,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.299050+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab65b"
    },
    "model_benchmark_id": 1845,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.225405+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.451,
    "score": 0.451,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.225405+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab65d"
    },
    "model_benchmark_id": 539,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.114367+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.731,
    "score": 0.731,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.114367+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab65f"
    },
    "model_benchmark_id": 117,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.317652+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:11.317652+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab661"
    },
    "model_benchmark_id": 1481,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.157799+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.785,
    "score": 0.785,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.157799+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab663"
    },
    "model_benchmark_id": 590,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.217019+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.727,
    "score": 0.727,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.217019+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab665"
    },
    "model_benchmark_id": 740,
    "analysis_method": "Standard benchmark (GPT-4o grader)",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.555824+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.358,
    "score": 0.358,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.555824+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab667"
    },
    "model_benchmark_id": 1851,
    "analysis_method": "Standard benchmark (o3-mini grader, see footnote [3])",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.239021+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.422,
    "score": 0.422,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.239021+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab669"
    },
    "model_benchmark_id": 1650,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.643303+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.643303+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab66b"
    },
    "model_benchmark_id": 1863,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.270008+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.472,
    "score": 0.472,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.270008+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab66d"
    },
    "model_benchmark_id": 1869,
    "analysis_method": "GPT-4o without thinking mode - Function calling benchmark (telecom domain).",
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "Tau2 telecom",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.235,
    "score": 0.235,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab66f"
    },
    "model_benchmark_id": 1355,
    "analysis_method": "Internal methodology, see source footnote [2]",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.852737+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.236,
    "score": 0.236,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:13.852737+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab671"
    },
    "model_benchmark_id": 1776,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4])",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.007636+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.36,
    "score": 0.36,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.007636+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab673"
    },
    "model_benchmark_id": 1762,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4], GPT-4o user model)",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.978528+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "normalized_score": 0.558,
    "score": 0.558,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.978528+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab67b"
    },
    "model_benchmark_id": 9020,
    "analysis_method": "GPT-5 standard with thinking mode enabled (no tools) - competition mathematics.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.946,
    "score": 0.946,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab67d"
    },
    "model_benchmark_id": 9009,
    "analysis_method": "GPT-5 with thinking mode - College-level visual problem-solving with multimodal reasoning.",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.842,
    "score": 0.842,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab680"
    },
    "model_benchmark_id": 9007,
    "analysis_method": "Code generation benchmark with function completion tasks in Python.",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.934,
    "score": 0.934,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab682"
    },
    "model_benchmark_id": 9008,
    "analysis_method": "Thinking mode enabled with step-by-step mathematical problem solving and verification.",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.847,
    "score": 0.847,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab684"
    },
    "model_benchmark_id": 9013,
    "analysis_method": "Thinking mode enabled for medical hallucination detection. Measured inaccuracies on challenging healthcare conversations.",
    "benchmark_id": "healthbench-hard",
    "benchmark_name": "HealthBench Hard",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.016,
    "score": 0.016,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab686"
    },
    "model_benchmark_id": 9024,
    "analysis_method": "GPT-5 standard with thinking mode enabled (with python tool only) - FrontierMath Tier 1-3 expert-level mathematics.",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.263,
    "score": 0.263,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab688"
    },
    "model_benchmark_id": 9028,
    "analysis_method": "GPT-5 standard with thinking mode enabled (no tools) - Harvard-MIT Mathematics Tournament.",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.933,
    "score": 0.933,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab68a"
    },
    "model_benchmark_id": 9032,
    "analysis_method": "GPT-5 - Diamond thinking no tools",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab68c"
    },
    "model_benchmark_id": 9037,
    "analysis_method": "GPT-5 standard with thinking mode (no tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.248,
    "score": 0.248,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab68e"
    },
    "model_benchmark_id": 9041,
    "analysis_method": "GPT-5 with thinking mode enabled - Multi-turn instruction following benchmark.",
    "benchmark_id": "scale-multichallenge",
    "benchmark_name": "Scale MultiChallenge",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab690"
    },
    "model_benchmark_id": 9043,
    "analysis_method": "GPT-5 with thinking mode enabled - Agentic search & browsing benchmark.",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.549,
    "score": 0.549,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab692"
    },
    "model_benchmark_id": 9045,
    "analysis_method": "GPT-5 with thinking mode enabled - Instruction-following in freeform writing.",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.99,
    "score": 0.99,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab694"
    },
    "model_benchmark_id": 10034,
    "analysis_method": "GPT-5 with o3-mini grader - Multi-turn instruction following benchmark with improved grading accuracy.",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.696,
    "score": 0.696,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ba6d7100bb5dab696"
    },
    "model_benchmark_id": 10035,
    "analysis_method": "GPT-5 - Internal API instruction following evaluation (hard difficulty).",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.64,
    "score": 0.64,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab698"
    },
    "model_benchmark_id": 9047,
    "analysis_method": "GPT-5 - Function calling benchmark (airline domain).",
    "benchmark_id": "tau2-airline",
    "benchmark_name": "Tau2 airline",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.626,
    "score": 0.626,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab69a"
    },
    "model_benchmark_id": 9049,
    "analysis_method": "GPT-5 with thinking mode - Function calling benchmark (retail domain).",
    "benchmark_id": "tau2-retail",
    "benchmark_name": "Tau2 retail",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab69c"
    },
    "model_benchmark_id": 9051,
    "analysis_method": "GPT-5 with thinking mode - Function calling benchmark (telecom domain).",
    "benchmark_id": "tau2-telecom",
    "benchmark_name": "Tau2 telecom",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.967,
    "score": 0.967,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab69e"
    },
    "model_benchmark_id": 9053,
    "analysis_method": "GPT-5 with thinking mode - Graduate-level visual problem-solving with advanced multimodal reasoning.",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.784,
    "score": 0.784,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6a0"
    },
    "model_benchmark_id": 9055,
    "analysis_method": "GPT-5 with thinking mode - Video-based multimodal reasoning (max frame 256).",
    "benchmark_id": "videommmu",
    "benchmark_name": "VideoMMMU",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6a2"
    },
    "model_benchmark_id": 9057,
    "analysis_method": "GPT-5 with thinking mode - Scientific figure reasoning and interpretation.",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.811,
    "score": 0.811,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6a4"
    },
    "model_benchmark_id": 9059,
    "analysis_method": "GPT-5 with thinking mode - Multimodal spatial reasoning.",
    "benchmark_id": "erqa",
    "benchmark_name": "ERQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.657,
    "score": 0.657,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6a6"
    },
    "model_benchmark_id": 10048,
    "analysis_method": "OpenAI-MRCR 2-needle retrieval at 128k tokens.",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.952,
    "score": 0.952,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6a8"
    },
    "model_benchmark_id": 10049,
    "analysis_method": "OpenAI-MRCR 2-needle retrieval at 256k tokens.",
    "benchmark_id": "openai-mrcr:-2-needle-256k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 256k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.868,
    "score": 0.868,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6aa"
    },
    "model_benchmark_id": 10050,
    "analysis_method": "Graphwalks BFS (<128k) long-context reasoning.",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.783,
    "score": 0.783,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ac"
    },
    "model_benchmark_id": 10051,
    "analysis_method": "Graphwalks parents (<128k) long-context reasoning.",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ae"
    },
    "model_benchmark_id": 10052,
    "analysis_method": "BrowseComp long-context 128k variant.",
    "benchmark_id": "browsecomp-long-128k",
    "benchmark_name": "BrowseComp Long Context 128k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6b0"
    },
    "model_benchmark_id": 10053,
    "analysis_method": "BrowseComp long-context 256k variant.",
    "benchmark_id": "browsecomp-long-256k",
    "benchmark_name": "BrowseComp Long Context 256k",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.888,
    "score": 0.888,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6b2"
    },
    "model_benchmark_id": 10054,
    "analysis_method": "VideoMME (long) with subtitles category.",
    "benchmark_id": "videomme-w-sub.",
    "benchmark_name": "VideoMME w sub.",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.867,
    "score": 0.867,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6b4"
    },
    "model_benchmark_id": 10069,
    "analysis_method": "Thinking mode enabled for hallucination detection. Measured on open-source prompts for concept-based factual queries.",
    "benchmark_id": "longfact-concepts",
    "benchmark_name": "LongFact-Concepts",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.007,
    "score": 0.007,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6b6"
    },
    "model_benchmark_id": 10070,
    "analysis_method": "Thinking mode enabled for hallucination detection. Measured on open-source prompts for object-based factual queries.",
    "benchmark_id": "longfact-objects",
    "benchmark_name": "LongFact-Objects",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.008,
    "score": 0.008,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6b8"
    },
    "model_benchmark_id": 10071,
    "analysis_method": "Thinking mode enabled for factual accuracy assessment. Measured hallucination rate on open-source prompts.",
    "benchmark_id": "factscore",
    "benchmark_name": "FactScore",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-2025-08-07",
    "normalized_score": 0.01,
    "score": 0.01,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ba"
    },
    "model_benchmark_id": 668,
    "analysis_method": "accuracy (whole, o4-mini-high)",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.384371+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.689,
    "score": 0.689,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.384371+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6bc"
    },
    "model_benchmark_id": 1332,
    "analysis_method": "accuracy (diff, o4-mini-high)",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.803065+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.582,
    "score": 0.582,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:13.803065+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6be"
    },
    "model_benchmark_id": 483,
    "analysis_method": "accuracy (no tools)",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.015345+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.934,
    "score": 0.934,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.015345+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6c0"
    },
    "model_benchmark_id": 706,
    "analysis_method": "accuracy (no tools)",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-19T19:56:12.477657+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.927,
    "score": 0.927,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.477657+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6c2"
    },
    "model_benchmark_id": 1843,
    "analysis_method": "accuracy (with python + browsing)",
    "benchmark_id": "browsecomp",
    "benchmark_name": "BrowseComp",
    "created_at": "2025-07-19T19:56:15.217475+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.515,
    "score": 0.515,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.217475+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6c4"
    },
    "model_benchmark_id": 1835,
    "analysis_method": "accuracy",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.197036+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.197036+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6c6"
    },
    "model_benchmark_id": 349,
    "analysis_method": "diamond accuracy (no tools)",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.754610+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:11.754610+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6c8"
    },
    "model_benchmark_id": 726,
    "analysis_method": "accuracy (no tools)",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-19T19:56:12.528160+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.147,
    "score": 0.147,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.528160+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ca"
    },
    "model_benchmark_id": 540,
    "analysis_method": "accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.115868+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.843,
    "score": 0.843,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.115868+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6cc"
    },
    "model_benchmark_id": 591,
    "analysis_method": "accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.218993+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.816,
    "score": 0.816,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:12.218993+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ce"
    },
    "model_benchmark_id": 1841,
    "analysis_method": "accuracy",
    "benchmark_id": "scale-multichallenge",
    "benchmark_name": "Scale MultiChallenge",
    "created_at": "2025-07-19T19:56:15.211372+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.43,
    "score": 0.43,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.211372+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6d0"
    },
    "model_benchmark_id": 1356,
    "analysis_method": "accuracy",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.854236+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.681,
    "score": 0.681,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:13.854236+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6d2"
    },
    "model_benchmark_id": 1777,
    "analysis_method": "accuracy (o4-mini-high)",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.009611+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.492,
    "score": 0.492,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:15.009611+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6d4"
    },
    "model_benchmark_id": 1763,
    "analysis_method": "accuracy (o4-mini-high)",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.980200+00:00",
    "is_self_reported": true,
    "model_id": "o4-mini",
    "normalized_score": 0.718,
    "score": 0.718,
    "self_reported_source_link": "https://openai.com/index/introducing-o3-and-o4-mini/",
    "updated_at": "2025-07-19T19:56:14.980200+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6d6"
    },
    "model_benchmark_id": 669,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.385924+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.098,
    "score": 0.098,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.385924+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6d8"
    },
    "model_benchmark_id": 1333,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.804864+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.062,
    "score": 0.062,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.804864+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6da"
    },
    "model_benchmark_id": 484,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.016856+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.294,
    "score": 0.294,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.016856+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6dc"
    },
    "model_benchmark_id": 1888,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-d",
    "benchmark_name": "CharXiv-D",
    "created_at": "2025-07-19T19:56:15.329021+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.739,
    "score": 0.739,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.329021+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6de"
    },
    "model_benchmark_id": 1836,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.199274+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.405,
    "score": 0.405,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.199274+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6e0"
    },
    "model_benchmark_id": 1858,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.257208+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.425,
    "score": 0.425,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.257208+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6e2"
    },
    "model_benchmark_id": 1893,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.341699+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.057,
    "score": 0.057,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.341699+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6e4"
    },
    "model_benchmark_id": 350,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.756178+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.503,
    "score": 0.503,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.756178+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6e6"
    },
    "model_benchmark_id": 1873,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-19T19:56:15.291775+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.25,
    "score": 0.25,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.291775+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6e8"
    },
    "model_benchmark_id": 1876,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-bfs->128k",
    "benchmark_name": "Graphwalks BFS >128k",
    "created_at": "2025-07-19T19:56:15.300453+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.029,
    "score": 0.029,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.300453+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ea"
    },
    "model_benchmark_id": 1879,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.308330+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.094,
    "score": 0.094,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.308330+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ec"
    },
    "model_benchmark_id": 1885,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents->128k",
    "benchmark_name": "Graphwalks parents >128k",
    "created_at": "2025-07-19T19:56:15.322097+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.056,
    "score": 0.056,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.322097+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6ee"
    },
    "model_benchmark_id": 633,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.300562+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.745,
    "score": 0.745,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.300562+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6f0"
    },
    "model_benchmark_id": 1846,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.227248+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.316,
    "score": 0.316,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.227248+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6f2"
    },
    "model_benchmark_id": 541,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.117553+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.562,
    "score": 0.562,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.117553+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6f4"
    },
    "model_benchmark_id": 118,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.319012+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.801,
    "score": 0.801,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.319012+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6f6"
    },
    "model_benchmark_id": 1482,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.159419+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.669,
    "score": 0.669,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.159419+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6f8"
    },
    "model_benchmark_id": 592,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.220951+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.554,
    "score": 0.554,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.220951+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6fa"
    },
    "model_benchmark_id": 741,
    "analysis_method": "Standard benchmark (GPT-4o grader)",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.557571+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.15,
    "score": 0.15,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.557571+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6fc"
    },
    "model_benchmark_id": 1852,
    "analysis_method": "Standard benchmark (o3-mini grader, see footnote [3])",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.241054+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.311,
    "score": 0.311,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.241054+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab6fe"
    },
    "model_benchmark_id": 1651,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.645047+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.645047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab700"
    },
    "model_benchmark_id": 1864,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.272341+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.366,
    "score": 0.366,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.272341+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab702"
    },
    "model_benchmark_id": 1870,
    "analysis_method": "GPT-4o without thinking mode - Graduate-level visual problem-solving with advanced multimodal reasoning.",
    "benchmark_id": "mmmu-pro",
    "benchmark_name": "MMMU-Pro",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.599,
    "score": 0.599,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab704"
    },
    "model_benchmark_id": 1778,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4])",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.011934+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.14,
    "score": 0.14,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.011934+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab706"
    },
    "model_benchmark_id": 1764,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4], GPT-4o user model)",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.982239+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "normalized_score": 0.226,
    "score": 0.226,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.982239+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab708"
    },
    "model_benchmark_id": 670,
    "analysis_method": "benchmark score",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.387419+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.667,
    "score": 0.667,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.387419+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab70a"
    },
    "model_benchmark_id": 1334,
    "analysis_method": "benchmark score",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.806560+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.604,
    "score": 0.604,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.806560+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab70c"
    },
    "model_benchmark_id": 485,
    "analysis_method": "test set evaluation",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.018382+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.873,
    "score": 0.873,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:12.018382+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab70e"
    },
    "model_benchmark_id": 1859,
    "analysis_method": "benchmark score",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.259314+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.987,
    "score": 0.987,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.259314+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab710"
    },
    "model_benchmark_id": 1894,
    "analysis_method": "benchmark score",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.344047+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.176,
    "score": 0.176,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.344047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab712"
    },
    "model_benchmark_id": 1830,
    "analysis_method": "pass @ 1",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-19T19:56:15.183728+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.092,
    "score": 0.092,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:15.183728+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab714"
    },
    "model_benchmark_id": 351,
    "analysis_method": "diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.758026+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.772,
    "score": 0.772,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.758026+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab716"
    },
    "model_benchmark_id": 1904,
    "analysis_method": "benchmark score",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-19T19:56:15.368369+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.51,
    "score": 0.51,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.368369+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab718"
    },
    "model_benchmark_id": 1880,
    "analysis_method": "benchmark score",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.310391+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.583,
    "score": 0.583,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.310391+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab71a"
    },
    "model_benchmark_id": 634,
    "analysis_method": "benchmark score",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.302770+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.939,
    "score": 0.939,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.302770+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab71c"
    },
    "model_benchmark_id": 1847,
    "analysis_method": "benchmark score",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.228737+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.228737+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab71e"
    },
    "model_benchmark_id": 754,
    "analysis_method": "o3-mini high",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.585789+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.846,
    "score": 0.846,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:12.585789+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab720"
    },
    "model_benchmark_id": 426,
    "analysis_method": "o3-mini high",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.901889+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.979,
    "score": 0.979,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:11.901889+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab722"
    },
    "model_benchmark_id": 1296,
    "analysis_method": "o3-mini high",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.712633+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.92,
    "score": 0.92,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:13.712633+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab724"
    },
    "model_benchmark_id": 119,
    "analysis_method": "o3-mini high",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.320589+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.869,
    "score": 0.869,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:11.320589+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab726"
    },
    "model_benchmark_id": 742,
    "analysis_method": "benchmark score",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.560158+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.399,
    "score": 0.399,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.560158+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab728"
    },
    "model_benchmark_id": 1853,
    "analysis_method": "benchmark score",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.243415+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.502,
    "score": 0.502,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.243415+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab72a"
    },
    "model_benchmark_id": 1652,
    "analysis_method": "benchmark score",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.646496+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.795,
    "score": 0.795,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.646496+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab72c"
    },
    "model_benchmark_id": 1474,
    "analysis_method": "benchmark score",
    "benchmark_id": "multilingual-mmlu",
    "benchmark_name": "Multilingual MMLU",
    "created_at": "2025-07-19T19:56:14.143822+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.807,
    "score": 0.807,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.143822+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab72e"
    },
    "model_benchmark_id": 1865,
    "analysis_method": "benchmark score",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.274261+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.187,
    "score": 0.187,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.274261+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab730"
    },
    "model_benchmark_id": 238,
    "analysis_method": "accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.554563+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.15,
    "score": 0.15,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:11.554563+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab732"
    },
    "model_benchmark_id": 1357,
    "analysis_method": "verified",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.856039+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.493,
    "score": 0.493,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:13.856039+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab734"
    },
    "model_benchmark_id": 1898,
    "analysis_method": "percentage score",
    "benchmark_id": "swe-lancer",
    "benchmark_name": "SWE-Lancer",
    "created_at": "2025-07-19T19:56:15.355089+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.18,
    "score": 0.18,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.355089+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab736"
    },
    "model_benchmark_id": 1901,
    "analysis_method": "percentage score",
    "benchmark_id": "swe-lancer-(ic-diamond-subset)",
    "benchmark_name": "SWE-Lancer (IC-Diamond subset)",
    "created_at": "2025-07-19T19:56:15.362026+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.074,
    "score": 0.074,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.362026+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab738"
    },
    "model_benchmark_id": 1779,
    "analysis_method": "benchmark score",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.013372+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.324,
    "score": 0.324,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.013372+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab73a"
    },
    "model_benchmark_id": 1765,
    "analysis_method": "benchmark score",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.984653+00:00",
    "is_self_reported": true,
    "model_id": "o3-mini",
    "normalized_score": 0.576,
    "score": 0.576,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.984653+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab73c"
    },
    "model_benchmark_id": 962,
    "analysis_method": "F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.023727+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.834,
    "score": 0.834,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:13.023727+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab73e"
    },
    "model_benchmark_id": 352,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.759539+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.536,
    "score": 0.536,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:11.759539+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab740"
    },
    "model_benchmark_id": 811,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.689969+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:12.689969+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab742"
    },
    "model_benchmark_id": 427,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.903446+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.766,
    "score": 0.766,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:11.903446+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab744"
    },
    "model_benchmark_id": 542,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.119289+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.638,
    "score": 0.638,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:12.119289+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab746"
    },
    "model_benchmark_id": 1297,
    "analysis_method": "Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.714155+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.905,
    "score": 0.905,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:13.714155+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab748"
    },
    "model_benchmark_id": 120,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.322163+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.887,
    "score": 0.887,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:11.322163+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab74a"
    },
    "model_benchmark_id": 219,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.515262+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-05-13",
    "normalized_score": 0.726,
    "score": 0.726,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o",
    "updated_at": "2025-07-19T19:56:11.515262+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab74c"
    },
    "model_benchmark_id": 671,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.389292+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.516,
    "score": 0.516,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.389292+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab74e"
    },
    "model_benchmark_id": 1335,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.808732+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.529,
    "score": 0.529,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:13.808732+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab750"
    },
    "model_benchmark_id": 486,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.019979+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.481,
    "score": 0.481,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.019979+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab752"
    },
    "model_benchmark_id": 1889,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-d",
    "benchmark_name": "CharXiv-D",
    "created_at": "2025-07-19T19:56:15.330689+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.879,
    "score": 0.879,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.330689+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab754"
    },
    "model_benchmark_id": 1837,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.201588+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.567,
    "score": 0.567,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.201588+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab756"
    },
    "model_benchmark_id": 1860,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.261360+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.658,
    "score": 0.658,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.261360+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab758"
    },
    "model_benchmark_id": 1895,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.348011+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.655,
    "score": 0.655,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.348011+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab75a"
    },
    "model_benchmark_id": 353,
    "analysis_method": "Diamond",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.761405+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.663,
    "score": 0.663,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:11.761405+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab75c"
    },
    "model_benchmark_id": 1874,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-19T19:56:15.294683+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.617,
    "score": 0.617,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.294683+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab75e"
    },
    "model_benchmark_id": 1877,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-bfs->128k",
    "benchmark_name": "Graphwalks BFS >128k",
    "created_at": "2025-07-19T19:56:15.302353+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.19,
    "score": 0.19,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.302353+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab760"
    },
    "model_benchmark_id": 1881,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.312231+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.58,
    "score": 0.58,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.312231+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab762"
    },
    "model_benchmark_id": 1886,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "graphwalks-parents->128k",
    "benchmark_name": "Graphwalks parents >128k",
    "created_at": "2025-07-19T19:56:15.324002+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.25,
    "score": 0.25,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.324002+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab764"
    },
    "model_benchmark_id": 635,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.304284+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.874,
    "score": 0.874,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.304284+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab766"
    },
    "model_benchmark_id": 1848,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.230360+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.491,
    "score": 0.491,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.230360+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab768"
    },
    "model_benchmark_id": 543,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.121168+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.121168+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab76a"
    },
    "model_benchmark_id": 121,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.323612+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.902,
    "score": 0.902,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:11.323612+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab76c"
    },
    "model_benchmark_id": 1483,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.161058+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.873,
    "score": 0.873,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.161058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab76e"
    },
    "model_benchmark_id": 593,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.222754+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.748,
    "score": 0.748,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.222754+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab770"
    },
    "model_benchmark_id": 743,
    "analysis_method": "Standard benchmark (GPT-4o grader)",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.561934+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.383,
    "score": 0.383,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:12.561934+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab772"
    },
    "model_benchmark_id": 1854,
    "analysis_method": "Standard benchmark (o3-mini grader, see footnote [3])",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.244951+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.462,
    "score": 0.462,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.244951+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab774"
    },
    "model_benchmark_id": 1653,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.648170+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.648170+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab776"
    },
    "model_benchmark_id": 1866,
    "analysis_method": "Internal benchmark",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.275855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.572,
    "score": 0.572,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.275855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab778"
    },
    "model_benchmark_id": 1871,
    "analysis_method": "GPT-4o without thinking mode - Video-based multimodal reasoning (max frame 256).",
    "benchmark_id": "videommmu",
    "benchmark_name": "VideoMMMU",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.612,
    "score": 0.612,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab77a"
    },
    "model_benchmark_id": 1358,
    "analysis_method": "Internal methodology, see source footnote [2]",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.858938+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.546,
    "score": 0.546,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:13.858938+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab77c"
    },
    "model_benchmark_id": 1780,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4])",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.015514+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.494,
    "score": 0.494,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.015514+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab77e"
    },
    "model_benchmark_id": 1766,
    "analysis_method": "Avg 5 runs, no custom tools/prompting (footnote [4], GPT-4o user model)",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.986496+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:14.986496+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab780"
    },
    "model_benchmark_id": 1907,
    "analysis_method": "Standard benchmark",
    "benchmark_id": "video-mme-(long,-no-subtitles)",
    "benchmark_name": "Video-MME (long, no subtitles)",
    "created_at": "2025-07-19T19:56:15.377204+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.1-2025-04-14",
    "normalized_score": 0.72,
    "score": 0.72,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-5-for-developers/",
    "updated_at": "2025-07-19T19:56:15.377204+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab785"
    },
    "model_benchmark_id": 487,
    "analysis_method": "Pass@1 accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.021363+00:00",
    "is_self_reported": true,
    "model_id": "o1-pro",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://openai.com/index/introducing-chatgpt-pro/",
    "updated_at": "2025-07-19T19:56:12.021363+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab787"
    },
    "model_benchmark_id": 354,
    "analysis_method": "Diamond, Pass@1 accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.762804+00:00",
    "is_self_reported": true,
    "model_id": "o1-pro",
    "normalized_score": 0.79,
    "score": 0.79,
    "self_reported_source_link": "https://openai.com/index/introducing-chatgpt-pro/",
    "updated_at": "2025-07-19T19:56:11.762804+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab789"
    },
    "model_benchmark_id": 1908,
    "analysis_method": "test set evaluation",
    "benchmark_id": "activitynet",
    "benchmark_name": "ActivityNet",
    "created_at": "2025-07-19T19:56:15.381219+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.619,
    "score": 0.619,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:15.381219+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab78b"
    },
    "model_benchmark_id": 1262,
    "analysis_method": "test set evaluation",
    "benchmark_id": "ai2d",
    "benchmark_name": "AI2D",
    "created_at": "2025-07-19T19:56:13.646808+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.942,
    "score": 0.942,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:13.646808+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab78d"
    },
    "model_benchmark_id": 672,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot",
    "benchmark_name": "Aider-Polyglot",
    "created_at": "2025-07-19T19:56:12.391433+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.307,
    "score": 0.307,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.391433+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab78f"
    },
    "model_benchmark_id": 1336,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.810263+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.182,
    "score": 0.182,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.810263+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab791"
    },
    "model_benchmark_id": 488,
    "analysis_method": "Accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.022775+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.131,
    "score": 0.131,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.022775+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab793"
    },
    "model_benchmark_id": 875,
    "analysis_method": "test set evaluation",
    "benchmark_id": "chartqa",
    "benchmark_name": "ChartQA",
    "created_at": "2025-07-19T19:56:12.824155+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:12.824155+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab795"
    },
    "model_benchmark_id": 1890,
    "analysis_method": "Accuracy",
    "benchmark_id": "charxiv-d",
    "benchmark_name": "CharXiv-D",
    "created_at": "2025-07-19T19:56:15.333294+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.853,
    "score": 0.853,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.333294+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab797"
    },
    "model_benchmark_id": 1838,
    "analysis_method": "GPT-4o without thinking mode - Scientific figure reasoning and interpretation.",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.203285+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.588,
    "score": 0.588,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:15.203285+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab799"
    },
    "model_benchmark_id": 1861,
    "analysis_method": "GPT-4o without thinking mode - Instruction-following in freeform writing.",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.262884+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.61,
    "score": 0.61,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:15.262884+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab79b"
    },
    "model_benchmark_id": 1867,
    "analysis_method": "Accuracy",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.277538+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.319,
    "score": 0.319,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.277538+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab79d"
    },
    "model_benchmark_id": 1868,
    "analysis_method": "Accuracy",
    "benchmark_id": "openai-mrcr:-2-needle-128k",
    "benchmark_name": "OpenAI-MRCR: 2 needle 128k",
    "created_at": "2025-07-19T19:56:15.279311+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.385,
    "score": 0.385,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.279311+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7a3"
    },
    "model_benchmark_id": 1896,
    "analysis_method": "Accuracy",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.349679+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.665,
    "score": 0.665,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.349679+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7a5"
    },
    "model_benchmark_id": 900,
    "analysis_method": "test set evaluation",
    "benchmark_id": "docvqa",
    "benchmark_name": "DocVQA",
    "created_at": "2025-07-19T19:56:12.873722+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.928,
    "score": 0.928,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:12.873722+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7a7"
    },
    "model_benchmark_id": 926,
    "analysis_method": "test set evaluation",
    "benchmark_id": "egoschema",
    "benchmark_name": "EgoSchema",
    "created_at": "2025-07-19T19:56:12.935728+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:12.935728+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7a9"
    },
    "model_benchmark_id": 355,
    "analysis_method": "GPT-4o - Diamond no thinking no tools",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.764329+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.701,
    "score": 0.701,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:11.764329+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ab"
    },
    "model_benchmark_id": 1905,
    "analysis_method": "Accuracy",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-19T19:56:15.370259+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.417,
    "score": 0.417,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.370259+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ad"
    },
    "model_benchmark_id": 1882,
    "analysis_method": "Accuracy",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.314044+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.354,
    "score": 0.354,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.314044+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7af"
    },
    "model_benchmark_id": 636,
    "analysis_method": "Accuracy",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.306083+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.81,
    "score": 0.81,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.306083+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7b1"
    },
    "model_benchmark_id": 1849,
    "analysis_method": "Accuracy",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.232334+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.292,
    "score": 0.292,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.232334+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7b3"
    },
    "model_benchmark_id": 544,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.122558+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.614,
    "score": 0.614,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.122558+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7b5"
    },
    "model_benchmark_id": 122,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.325082+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.857,
    "score": 0.857,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.325082+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7b7"
    },
    "model_benchmark_id": 220,
    "analysis_method": "0-shot CoT",
    "benchmark_id": "mmlu-pro",
    "benchmark_name": "MMLU-Pro",
    "created_at": "2025-07-19T19:56:11.517058+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.747,
    "score": 0.747,
    "self_reported_source_link": "https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro",
    "updated_at": "2025-07-19T19:56:11.517058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7b9"
    },
    "model_benchmark_id": 1484,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.162717+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.814,
    "score": 0.814,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.162717+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7bb"
    },
    "model_benchmark_id": 594,
    "analysis_method": "GPT-4o without thinking mode - College-level visual problem-solving with multimodal reasoning.",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.224513+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.722,
    "score": 0.722,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-19T19:56:12.224513+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7bd"
    },
    "model_benchmark_id": 1855,
    "analysis_method": "Accuracy",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.246431+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.399,
    "score": 0.399,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.246431+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7bf"
    },
    "model_benchmark_id": 1654,
    "analysis_method": "Accuracy",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.650416+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.609,
    "score": 0.609,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.650416+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7c2"
    },
    "model_benchmark_id": 239,
    "analysis_method": "accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.557852+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.382,
    "score": 0.382,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:11.557852+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7c4"
    },
    "model_benchmark_id": 1359,
    "analysis_method": "Accuracy",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.861280+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.332,
    "score": 0.332,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.861280+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7c6"
    },
    "model_benchmark_id": 1899,
    "analysis_method": "percentage score",
    "benchmark_id": "swe-lancer",
    "benchmark_name": "SWE-Lancer",
    "created_at": "2025-07-19T19:56:15.356738+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.326,
    "score": 0.326,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.356738+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7c8"
    },
    "model_benchmark_id": 1902,
    "analysis_method": "percentage score",
    "benchmark_id": "swe-lancer-(ic-diamond-subset)",
    "benchmark_name": "SWE-Lancer (IC-Diamond subset)",
    "created_at": "2025-07-19T19:56:15.363614+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.124,
    "score": 0.124,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.363614+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ca"
    },
    "model_benchmark_id": 1781,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.017725+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.428,
    "score": 0.428,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.017725+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7cc"
    },
    "model_benchmark_id": 1767,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.988086+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-2024-08-06",
    "normalized_score": 0.603,
    "score": 0.603,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.988086+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7d0"
    },
    "model_benchmark_id": 1910,
    "analysis_method": "Pass@12 accuracy",
    "benchmark_id": "cybersecurity-ctfs",
    "benchmark_name": "Cybersecurity CTFs",
    "created_at": "2025-07-19T19:56:15.390045+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.287,
    "score": 0.287,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:15.390045+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7d2"
    },
    "model_benchmark_id": 356,
    "analysis_method": "Diamond, 0-shot Chain of Thought",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.765864+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.6,
    "score": 0.6,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:11.765864+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7d4"
    },
    "model_benchmark_id": 812,
    "analysis_method": "Pass@1 accuracy",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.692107+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.924,
    "score": 0.924,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:12.692107+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7d6"
    },
    "model_benchmark_id": 513,
    "analysis_method": "0-shot Chain of Thought",
    "benchmark_id": "math-500",
    "benchmark_name": "MATH-500",
    "created_at": "2025-07-19T19:56:12.065288+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:12.065288+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7d8"
    },
    "model_benchmark_id": 123,
    "analysis_method": "0-shot Chain of Thought",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.327239+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.852,
    "score": 0.852,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:11.327239+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7da"
    },
    "model_benchmark_id": 1909,
    "analysis_method": "Evaluation on validation set",
    "benchmark_id": "superglue",
    "benchmark_name": "SuperGLUE",
    "created_at": "2025-07-19T19:56:15.385801+00:00",
    "is_self_reported": true,
    "model_id": "o1-mini",
    "normalized_score": 0.75,
    "score": 0.75,
    "self_reported_source_link": "https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/",
    "updated_at": "2025-07-19T19:56:15.385801+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7dc"
    },
    "model_benchmark_id": 9022,
    "analysis_method": "GPT-5 nano with thinking mode enabled (no tools) - competition mathematics.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "normalized_score": 0.852,
    "score": 0.852,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7de"
    },
    "model_benchmark_id": 9026,
    "analysis_method": "GPT-5 nano with thinking mode enabled (with python tool only) - FrontierMath Tier 1-3 expert-level mathematics.",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "normalized_score": 0.096,
    "score": 0.096,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7e0"
    },
    "model_benchmark_id": 9034,
    "analysis_method": "GPT-5 nano - Diamond thinking no tools",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "normalized_score": 0.712,
    "score": 0.712,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7e2"
    },
    "model_benchmark_id": 9039,
    "analysis_method": "GPT-5 nano with thinking mode (no tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "normalized_score": 0.087,
    "score": 0.087,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7e4"
    },
    "model_benchmark_id": 9030,
    "analysis_method": "GPT-5 nano with thinking mode enabled (no tools) - Harvard-MIT Mathematics Tournament.",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "normalized_score": 0.756,
    "score": 0.756,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7e6"
    },
    "model_benchmark_id": 1337,
    "analysis_method": "Accuracy",
    "benchmark_id": "aider-polyglot-edit",
    "benchmark_name": "Aider-Polyglot Edit",
    "created_at": "2025-07-19T19:56:13.811839+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.449,
    "score": 0.449,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.811839+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7e8"
    },
    "model_benchmark_id": 489,
    "analysis_method": "Accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.024273+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.367,
    "score": 0.367,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.024273+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ea"
    },
    "model_benchmark_id": 1891,
    "analysis_method": "Accuracy",
    "benchmark_id": "charxiv-d",
    "benchmark_name": "CharXiv-D",
    "created_at": "2025-07-19T19:56:15.335527+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.335527+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ec"
    },
    "model_benchmark_id": 1839,
    "analysis_method": "Accuracy",
    "benchmark_id": "charxiv-r",
    "benchmark_name": "CharXiv-R",
    "created_at": "2025-07-19T19:56:15.204875+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.554,
    "score": 0.554,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.204875+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7ee"
    },
    "model_benchmark_id": 1862,
    "analysis_method": "Accuracy",
    "benchmark_id": "collie",
    "benchmark_name": "COLLIE",
    "created_at": "2025-07-19T19:56:15.265565+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.723,
    "score": 0.723,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.265565+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7f0"
    },
    "model_benchmark_id": 1897,
    "analysis_method": "Accuracy",
    "benchmark_id": "complexfuncbench",
    "benchmark_name": "ComplexFuncBench",
    "created_at": "2025-07-19T19:56:15.351430+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.63,
    "score": 0.63,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.351430+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7f2"
    },
    "model_benchmark_id": 357,
    "analysis_method": "Accuracy (Diamond)",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.767414+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.695,
    "score": 0.695,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.767414+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7f4"
    },
    "model_benchmark_id": 1906,
    "analysis_method": "Accuracy",
    "benchmark_id": "graphwalks-bfs-<128k",
    "benchmark_name": "Graphwalks BFS <128k",
    "created_at": "2025-07-19T19:56:15.372855+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.723,
    "score": 0.723,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.372855+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7f6"
    },
    "model_benchmark_id": 1883,
    "analysis_method": "Accuracy",
    "benchmark_id": "graphwalks-parents-<128k",
    "benchmark_name": "Graphwalks parents <128k",
    "created_at": "2025-07-19T19:56:15.315697+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.726,
    "score": 0.726,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.315697+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7f8"
    },
    "model_benchmark_id": 1015,
    "analysis_method": "Answer accuracy",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.114869+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.97,
    "score": 0.97,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:13.114869+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7fa"
    },
    "model_benchmark_id": 813,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.694244+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:12.694244+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7fc"
    },
    "model_benchmark_id": 637,
    "analysis_method": "Accuracy",
    "benchmark_id": "ifeval",
    "benchmark_name": "IFEval",
    "created_at": "2025-07-19T19:56:12.307682+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.882,
    "score": 0.882,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.307682+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab7fe"
    },
    "model_benchmark_id": 1850,
    "analysis_method": "Accuracy",
    "benchmark_id": "internal-api-instruction-following-(hard)",
    "benchmark_name": "Internal API instruction following (hard)",
    "created_at": "2025-07-19T19:56:15.234022+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.54,
    "score": 0.54,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.234022+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab800"
    },
    "model_benchmark_id": 545,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.124115+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.723,
    "score": 0.723,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.124115+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab802"
    },
    "model_benchmark_id": 124,
    "analysis_method": "Multiple-choice accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.328688+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:11.328688+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab804"
    },
    "model_benchmark_id": 1485,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.164320+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.851,
    "score": 0.851,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.164320+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab806"
    },
    "model_benchmark_id": 595,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.226731+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.752,
    "score": 0.752,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.226731+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab808"
    },
    "model_benchmark_id": 744,
    "analysis_method": "Accuracy",
    "benchmark_id": "multichallenge",
    "benchmark_name": "MultiChallenge",
    "created_at": "2025-07-19T19:56:12.563438+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.438,
    "score": 0.438,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.563438+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab80a"
    },
    "model_benchmark_id": 1856,
    "analysis_method": "Accuracy",
    "benchmark_id": "multichallenge-(o3-mini-grader)",
    "benchmark_name": "MultiChallenge (o3-mini grader)",
    "created_at": "2025-07-19T19:56:15.249385+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.501,
    "score": 0.501,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.249385+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab80c"
    },
    "model_benchmark_id": 1655,
    "analysis_method": "Accuracy",
    "benchmark_id": "multi-if",
    "benchmark_name": "Multi-IF",
    "created_at": "2025-07-19T19:56:14.652033+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.652033+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab80f"
    },
    "model_benchmark_id": 240,
    "analysis_method": "accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.559622+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.625,
    "score": 0.625,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:11.559622+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab811"
    },
    "model_benchmark_id": 1360,
    "analysis_method": "Success rate",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.863719+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.38,
    "score": 0.38,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.863719+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab813"
    },
    "model_benchmark_id": 1900,
    "analysis_method": "Success rate ($186K equivalent)",
    "benchmark_id": "swe-lancer",
    "benchmark_name": "SWE-Lancer",
    "created_at": "2025-07-19T19:56:15.358579+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.373,
    "score": 0.373,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.358579+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab815"
    },
    "model_benchmark_id": 1903,
    "analysis_method": "Success rate ($41K equivalent)",
    "benchmark_id": "swe-lancer-(ic-diamond-subset)",
    "benchmark_name": "SWE-Lancer (IC-Diamond subset)",
    "created_at": "2025-07-19T19:56:15.365353+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.174,
    "score": 0.174,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.365353+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab817"
    },
    "model_benchmark_id": 1782,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.020093+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.020093+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab819"
    },
    "model_benchmark_id": 1768,
    "analysis_method": "Accuracy",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.989887+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4.5",
    "normalized_score": 0.684,
    "score": 0.684,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.989887+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab81b"
    },
    "model_benchmark_id": 9021,
    "analysis_method": "GPT-5 mini with thinking mode enabled (no tools) - competition mathematics.",
    "benchmark_id": "aime-2025",
    "benchmark_name": "AIME 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "normalized_score": 0.911,
    "score": 0.911,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab81d"
    },
    "model_benchmark_id": 9025,
    "analysis_method": "GPT-5 mini with thinking mode enabled (with python tool only) - FrontierMath Tier 1-3 expert-level mathematics.",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "normalized_score": 0.221,
    "score": 0.221,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab81f"
    },
    "model_benchmark_id": 9033,
    "analysis_method": "GPT-5 mini - Diamond thinking no tools",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "normalized_score": 0.823,
    "score": 0.823,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab821"
    },
    "model_benchmark_id": 9038,
    "analysis_method": "GPT-5 mini with thinking mode (no tools) - Full set of expert-level questions across subjects.",
    "benchmark_id": "humanity's-last-exam",
    "benchmark_name": "Humanity's Last Exam",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "normalized_score": 0.167,
    "score": 0.167,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab823"
    },
    "model_benchmark_id": 9029,
    "analysis_method": "GPT-5 mini with thinking mode enabled (no tools) - Harvard-MIT Mathematics Tournament.",
    "benchmark_id": "hmmt-2025",
    "benchmark_name": "HMMT 2025",
    "created_at": "2025-07-24T12:00:00.000000+00:00",
    "is_self_reported": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "normalized_score": 0.878,
    "score": 0.878,
    "self_reported_source_link": "https://openai.com/index/gpt-5/",
    "updated_at": "2025-07-24T12:00:00.000000+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab825"
    },
    "model_benchmark_id": 490,
    "analysis_method": "accuracy",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.025628+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.743,
    "score": 0.743,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.025628+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab827"
    },
    "model_benchmark_id": 1831,
    "analysis_method": "pass@1",
    "benchmark_id": "frontiermath",
    "benchmark_name": "FrontierMath",
    "created_at": "2025-07-19T19:56:15.186673+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.055,
    "score": 0.055,
    "self_reported_source_link": "https://openai.com/index/o1-and-new-tools-for-developers/",
    "updated_at": "2025-07-19T19:56:15.186673+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab829"
    },
    "model_benchmark_id": 358,
    "analysis_method": "accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.768954+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.78,
    "score": 0.78,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini/",
    "updated_at": "2025-07-19T19:56:11.768954+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab82b"
    },
    "model_benchmark_id": 1911,
    "analysis_method": "pass@1",
    "benchmark_id": "gpqa-biology",
    "benchmark_name": "GPQA Biology",
    "created_at": "2025-07-19T19:56:15.394088+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.692,
    "score": 0.692,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:15.394088+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab82d"
    },
    "model_benchmark_id": 1912,
    "analysis_method": "pass@1",
    "benchmark_id": "gpqa-chemistry",
    "benchmark_name": "GPQA Chemistry",
    "created_at": "2025-07-19T19:56:15.399030+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.647,
    "score": 0.647,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:15.399030+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab82f"
    },
    "model_benchmark_id": 1913,
    "analysis_method": "pass@1",
    "benchmark_id": "gpqa-physics",
    "benchmark_name": "GPQA Physics",
    "created_at": "2025-07-19T19:56:15.403790+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.928,
    "score": 0.928,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:15.403790+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab831"
    },
    "model_benchmark_id": 1016,
    "analysis_method": "pass@1",
    "benchmark_id": "gsm8k",
    "benchmark_name": "GSM8k",
    "created_at": "2025-07-19T19:56:13.116437+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.971,
    "score": 0.971,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:13.116437+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab833"
    },
    "model_benchmark_id": 814,
    "analysis_method": "pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.696047+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.881,
    "score": 0.881,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:12.696047+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab835"
    },
    "model_benchmark_id": 755,
    "analysis_method": "coding",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.587814+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://openai.com/index/openai-o3-mini//",
    "updated_at": "2025-07-19T19:56:12.587814+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab837"
    },
    "model_benchmark_id": 428,
    "analysis_method": "pass@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.905279+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.964,
    "score": 0.964,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:11.905279+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab839"
    },
    "model_benchmark_id": 546,
    "analysis_method": "pass@1",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.126058+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.718,
    "score": 0.718,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.126058+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab83b"
    },
    "model_benchmark_id": 1298,
    "analysis_method": "pass@1",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.715686+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.893,
    "score": 0.893,
    "self_reported_source_link": "https://openai.com/index/o1-and-new-tools-for-developers/",
    "updated_at": "2025-07-19T19:56:13.715686+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab83d"
    },
    "model_benchmark_id": 125,
    "analysis_method": "pass@1",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.330211+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.918,
    "score": 0.918,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:11.330211+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab83f"
    },
    "model_benchmark_id": 1486,
    "analysis_method": "accuracy",
    "benchmark_id": "mmmlu",
    "benchmark_name": "MMMLU",
    "created_at": "2025-07-19T19:56:14.165932+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.877,
    "score": 0.877,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.165932+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab841"
    },
    "model_benchmark_id": 596,
    "analysis_method": "pass@1",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.228467+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.776,
    "score": 0.776,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:12.228467+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab843"
    },
    "model_benchmark_id": 241,
    "analysis_method": "accuracy",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.561209+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.47,
    "score": 0.47,
    "self_reported_source_link": "https://openai.com/index/introducing-gpt-4-5/",
    "updated_at": "2025-07-19T19:56:11.561209+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab845"
    },
    "model_benchmark_id": 1361,
    "analysis_method": "verified",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.865799+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.41,
    "score": 0.41,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.865799+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab847"
    },
    "model_benchmark_id": 1783,
    "analysis_method": "agents",
    "benchmark_id": "tau-bench-airline",
    "benchmark_name": "TAU-bench Airline",
    "created_at": "2025-07-19T19:56:15.021642+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.5,
    "score": 0.5,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:15.021642+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab849"
    },
    "model_benchmark_id": 1769,
    "analysis_method": "agents",
    "benchmark_id": "tau-bench-retail",
    "benchmark_name": "TAU-bench Retail",
    "created_at": "2025-07-19T19:56:14.992114+00:00",
    "is_self_reported": true,
    "model_id": "o1-2024-12-17",
    "normalized_score": 0.708,
    "score": 0.708,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:14.992114+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab84b"
    },
    "model_benchmark_id": 963,
    "analysis_method": "Accuracy",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.025267+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:13.025267+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab84d"
    },
    "model_benchmark_id": 359,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.770449+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.308,
    "score": 0.308,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.770449+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab84f"
    },
    "model_benchmark_id": 815,
    "analysis_method": "Accuracy",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.697970+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.68,
    "score": 0.68,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:12.697970+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab851"
    },
    "model_benchmark_id": 429,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.906977+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.431,
    "score": 0.431,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.906977+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab853"
    },
    "model_benchmark_id": 547,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.127494+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.0,
    "score": 0.0,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:12.127494+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab855"
    },
    "model_benchmark_id": 1299,
    "analysis_method": "Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.717321+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.563,
    "score": 0.563,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:13.717321+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab857"
    },
    "model_benchmark_id": 126,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.331664+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.698,
    "score": 0.698,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:11.331664+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab859"
    },
    "model_benchmark_id": 597,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.230222+00:00",
    "is_self_reported": false,
    "model_id": "gpt-3.5-turbo-0125",
    "normalized_score": 0.0,
    "score": 0.0,
    "self_reported_source_link": "https://example.com/benchmark-image",
    "updated_at": "2025-07-19T19:56:12.230222+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab85b"
    },
    "model_benchmark_id": 491,
    "analysis_method": "pass@1",
    "benchmark_id": "aime-2024",
    "benchmark_name": "AIME 2024",
    "created_at": "2025-07-19T19:56:12.027037+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.42,
    "score": 0.42,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:12.027037+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab85d"
    },
    "model_benchmark_id": 360,
    "analysis_method": "pass@1",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.772534+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.733,
    "score": 0.733,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:11.772534+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab85f"
    },
    "model_benchmark_id": 756,
    "analysis_method": "Coding",
    "benchmark_id": "livebench",
    "benchmark_name": "LiveBench",
    "created_at": "2025-07-19T19:56:12.589687+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.523,
    "score": 0.523,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:12.589687+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab861"
    },
    "model_benchmark_id": 430,
    "analysis_method": "pass@1",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.910412+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.855,
    "score": 0.855,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms",
    "updated_at": "2025-07-19T19:56:11.910412+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab863"
    },
    "model_benchmark_id": 1300,
    "analysis_method": "pass@1",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.718867+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:13.718867+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab865"
    },
    "model_benchmark_id": 127,
    "analysis_method": "pass@1",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.333269+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.908,
    "score": 0.908,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms",
    "updated_at": "2025-07-19T19:56:11.333269+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab867"
    },
    "model_benchmark_id": 242,
    "analysis_method": "Factuality",
    "benchmark_id": "simpleqa",
    "benchmark_name": "SimpleQA",
    "created_at": "2025-07-19T19:56:11.562695+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.424,
    "score": 0.424,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:11.562695+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab869"
    },
    "model_benchmark_id": 1362,
    "analysis_method": "Verified",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.867753+00:00",
    "is_self_reported": true,
    "model_id": "o1-preview",
    "normalized_score": 0.413,
    "score": 0.413,
    "self_reported_source_link": "https://openai.com/index/learning-to-reason-with-llms/",
    "updated_at": "2025-07-19T19:56:13.867753+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab86b"
    },
    "model_benchmark_id": 964,
    "analysis_method": "F1 Score",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.026741+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.797,
    "score": 0.797,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:13.026741+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab86d"
    },
    "model_benchmark_id": 361,
    "analysis_method": "Accuracy",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.774361+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.402,
    "score": 0.402,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:11.774361+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab86f"
    },
    "model_benchmark_id": 816,
    "analysis_method": "Pass@1",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.700095+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.872,
    "score": 0.872,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:12.700095+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab871"
    },
    "model_benchmark_id": 431,
    "analysis_method": "Accuracy",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.911917+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.702,
    "score": 0.702,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:11.911917+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab873"
    },
    "model_benchmark_id": 548,
    "analysis_method": "Accuracy",
    "benchmark_id": "mathvista",
    "benchmark_name": "MathVista",
    "created_at": "2025-07-19T19:56:12.128984+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.567,
    "score": 0.567,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:12.128984+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab875"
    },
    "model_benchmark_id": 1301,
    "analysis_method": "Accuracy",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.720445+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.87,
    "score": 0.87,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:13.720445+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab877"
    },
    "model_benchmark_id": 128,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.335061+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.82,
    "score": 0.82,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:11.335061+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab879"
    },
    "model_benchmark_id": 598,
    "analysis_method": "Accuracy",
    "benchmark_id": "mmmu",
    "benchmark_name": "MMMU",
    "created_at": "2025-07-19T19:56:12.232157+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.594,
    "score": 0.594,
    "self_reported_source_link": "https://openai.com/blog/gpt-4o-mini-announcement",
    "updated_at": "2025-07-19T19:56:12.232157+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab87b"
    },
    "model_benchmark_id": 1363,
    "analysis_method": "Pass Rate",
    "benchmark_id": "swe-bench-verified",
    "benchmark_name": "SWE-Bench Verified",
    "created_at": "2025-07-19T19:56:13.870038+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "normalized_score": 0.087,
    "score": 0.087,
    "self_reported_source_link": "https://openai.com/index/gpt-4-1/",
    "updated_at": "2025-07-19T19:56:13.870038+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab87d"
    },
    "model_benchmark_id": 1917,
    "analysis_method": "25-shot, Grade-school multiple choice science questions (Challenge-set)",
    "benchmark_id": "ai2-reasoning-challenge-(arc)",
    "benchmark_name": "AI2 Reasoning Challenge (ARC)",
    "created_at": "2025-07-19T19:56:15.421959+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.963,
    "score": 0.963,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:15.421959+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab87f"
    },
    "model_benchmark_id": 965,
    "analysis_method": "3-shot, Reading comprehension & arithmetic (f1 score)",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.028099+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.809,
    "score": 0.809,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:13.028099+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab881"
    },
    "model_benchmark_id": 362,
    "analysis_method": "5-shot, Commonsense reasoning",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.775863+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.357,
    "score": 0.357,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:11.775863+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab883"
    },
    "model_benchmark_id": 55,
    "analysis_method": "10-shot, Commonsense reasoning around everyday events",
    "benchmark_id": "hellaswag",
    "benchmark_name": "HellaSwag",
    "created_at": "2025-07-19T19:56:11.199031+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.953,
    "score": 0.953,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:11.199031+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab885"
    },
    "model_benchmark_id": 817,
    "analysis_method": "0-shot, Python coding tasks",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.702020+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.67,
    "score": 0.67,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:12.702020+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab887"
    },
    "model_benchmark_id": 1915,
    "analysis_method": "Percentile score",
    "benchmark_id": "lsat",
    "benchmark_name": "LSAT",
    "created_at": "2025-07-19T19:56:15.413295+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.88,
    "score": 0.88,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:15.413295+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab889"
    },
    "model_benchmark_id": 432,
    "analysis_method": "Mathematics problem-solving",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.913379+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.42,
    "score": 0.42,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:11.913379+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab88b"
    },
    "model_benchmark_id": 1302,
    "analysis_method": "Mathematics problem-solving",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.721873+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.745,
    "score": 0.745,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:13.721873+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab88d"
    },
    "model_benchmark_id": 129,
    "analysis_method": "5-shot, Multiple-choice questions in 57 subjects (professional & academic)",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.336601+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.864,
    "score": 0.864,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:11.336601+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab88f"
    },
    "model_benchmark_id": 1916,
    "analysis_method": "Estimated from reported score of 710 out of 800",
    "benchmark_id": "sat-math",
    "benchmark_name": "SAT Math",
    "created_at": "2025-07-19T19:56:15.417889+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.89,
    "score": 0.89,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:15.417889+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab891"
    },
    "model_benchmark_id": 1914,
    "analysis_method": "Percentage score",
    "benchmark_id": "uniform-bar-exam",
    "benchmark_name": "Uniform Bar Exam",
    "created_at": "2025-07-19T19:56:15.408427+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.9,
    "score": 0.9,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:15.408427+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab893"
    },
    "model_benchmark_id": 156,
    "analysis_method": "5-shot, Commonsense reasoning around pronoun resolution",
    "benchmark_id": "winogrande",
    "benchmark_name": "Winogrande",
    "created_at": "2025-07-19T19:56:11.396099+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-0613",
    "normalized_score": 0.875,
    "score": 0.875,
    "self_reported_source_link": "https://openai.com/research/gpt-4",
    "updated_at": "2025-07-19T19:56:11.396099+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab895"
    },
    "model_benchmark_id": 966,
    "analysis_method": "Reading comprehension & arithmetic (f1 score)",
    "benchmark_id": "drop",
    "benchmark_name": "DROP",
    "created_at": "2025-07-19T19:56:13.030041+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.86,
    "score": 0.86,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:13.030041+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab897"
    },
    "model_benchmark_id": 363,
    "analysis_method": "General-Purpose Question Answering",
    "benchmark_id": "gpqa",
    "benchmark_name": "GPQA",
    "created_at": "2025-07-19T19:56:11.777899+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.48,
    "score": 0.48,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:11.777899+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab899"
    },
    "model_benchmark_id": 818,
    "analysis_method": "Python coding tasks",
    "benchmark_id": "humaneval",
    "benchmark_name": "HumanEval",
    "created_at": "2025-07-19T19:56:12.703615+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.871,
    "score": 0.871,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:12.703615+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab89b"
    },
    "model_benchmark_id": 433,
    "analysis_method": "Mathematics problem-solving",
    "benchmark_id": "math",
    "benchmark_name": "MATH",
    "created_at": "2025-07-19T19:56:11.916360+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.726,
    "score": 0.726,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:11.916360+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab89d"
    },
    "model_benchmark_id": 1303,
    "analysis_method": "Grade School Math Word Problems",
    "benchmark_id": "mgsm",
    "benchmark_name": "MGSM",
    "created_at": "2025-07-19T19:56:13.723556+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.885,
    "score": 0.885,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:13.723556+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  },
  {
    "_id": {
      "$oid": "692a908ca6d7100bb5dab89f"
    },
    "model_benchmark_id": 130,
    "analysis_method": "Multiple-choice questions in 57 subjects (professional & academic)",
    "benchmark_id": "mmlu",
    "benchmark_name": "MMLU",
    "created_at": "2025-07-19T19:56:11.337995+00:00",
    "is_self_reported": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "normalized_score": 0.865,
    "score": 0.865,
    "self_reported_source_link": "https://openai.com/index/hello-gpt-4o/",
    "updated_at": "2025-07-19T19:56:11.337995+00:00",
    "verification_date": null,
    "verification_hardware": null,
    "verification_notes": null,
    "verification_provider_id": null,
    "verified_by_llmstats": false
  }
]