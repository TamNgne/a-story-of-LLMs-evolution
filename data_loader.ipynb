{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115b9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1038d61",
   "metadata": {},
   "source": [
    "For loading data into mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mongo db config\n",
    "def get_mongo_client(uri=\"mongodb://127.0.0.1:27017/\"):\n",
    "\n",
    "    return MongoClient(uri)\n",
    "\n",
    "def get_database(client, db_name=\"admin\"):\n",
    "\n",
    "    return client[db_name]\n",
    "\n",
    "def get_collection(db, collection_name):\n",
    "\n",
    "    return db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"Data\"  #where the extracted root data folder\n",
    "\n",
    "#Mongo DB collections\n",
    "Collections = { 'Benchmark MD', \n",
    "                'LLM overall info',\n",
    "                'Licenses MD',\n",
    "                'Organizations',\n",
    "                'Providers'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc91942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a12ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_json_to_mongo(mongo_uri, db_name, collection_name, folder_dir, id_col):\n",
    "    \"\"\"\n",
    "    Load JSON data including only 1 DATA POINT from a folder into MongoDB.\n",
    "\n",
    "    Parameters:\n",
    "        mongo_uri (str): MongoDB connection URI\n",
    "        db_name (str): Name of the database\n",
    "        collection_name (str): Name of the collection to insert into\n",
    "        folder_dir (str): Path to the folder containing JSON files\n",
    "    \"\"\"\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    print(f\"Reading from: {folder_dir}\")\n",
    "    count = 0\n",
    "\n",
    "    for file in os.listdir(folder_dir):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        json_path = os.path.join(folder_dir, file)\n",
    "        data = load_json(json_path)\n",
    "\n",
    "        collection.update_one(\n",
    "            {id_col: data[id_col]},  # avoid duplicates\n",
    "            {\"$set\": data},\n",
    "            upsert=True\n",
    "        )\n",
    "\n",
    "        print(f\"Inserted: {file}\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"\\n{count} json files loaded into '{collection_name}' collection.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360606d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_many_json_to_mongo(mongo_uri, db_name, collection_name, folder_dir, id_col):\n",
    "    \"\"\"\n",
    "    Load JSON data including list of data points from a folder into MongoDB.\n",
    "\n",
    "    Parameters:\n",
    "        mongo_uri (str): MongoDB connection URI\n",
    "        db_name (str): Name of the database\n",
    "        collection_name (str): Name of the collection to insert into\n",
    "        folder_dir (str): Path to the folder containing JSON files\n",
    "    \"\"\"\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    print(f\"Reading from: {folder_dir}\")\n",
    "    count = 0\n",
    "\n",
    "    for file in os.listdir(folder_dir):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        json_path = os.path.join(folder_dir, file)\n",
    "        data_list = load_json(json_path)  # this is a list []\n",
    "\n",
    "        if not isinstance(data_list, list):\n",
    "            print(f\"{file} is not a list, skipping...\")\n",
    "            continue\n",
    "\n",
    "        for item in data_list:\n",
    "            collection.update_one(\n",
    "                {id_col: item[id_col]},\n",
    "                {\"$set\": item},\n",
    "                upsert=True\n",
    "            )\n",
    "            count += 1\n",
    "\n",
    "    print(f\"\\n{count} json files loaded into '{collection_name}' collection.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36496647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_child_folder_json(mongo_uri, db_name, collection_name, root_dir, child_name, id_col):\n",
    "    \"\"\"\n",
    "    Load master data from each child folder inside root_dir.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    print(f\"Scanning root directory: {root_dir}\")\n",
    "    count = 0\n",
    "\n",
    "    for child in os.listdir(root_dir):\n",
    "        child_path = os.path.join(root_dir, child)\n",
    "\n",
    "        if not os.path.isdir(child_path):\n",
    "            continue\n",
    "\n",
    "        child_file = os.path.join(child_path, child_name)\n",
    "\n",
    "        if not os.path.exists(child_file):\n",
    "            print(f\"No {child_name} in: {child_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(child_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Insert based on its unique ID\n",
    "        collection.update_one(\n",
    "            {id_col: data[id_col]},\n",
    "            {\"$set\": data},\n",
    "            upsert=True\n",
    "        )\n",
    "\n",
    "        print(f\"Inserted: {child}\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"\\nLoaded {count} {child} files into '{collection_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb76fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm_models(mongo_uri, db_name, collection_name, organizations_dir, id_col):\n",
    "    \"\"\"\n",
    "    Load benchmarks.json (a list of objects) from:\n",
    "        organizations/<org_id>/models/<model_id>/benchmarks.json\n",
    "    \"\"\"\n",
    "\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "\n",
    "    print(f\"Scanning organizations directory: {organizations_dir}\")\n",
    "    total_items = 0\n",
    "    total_files = 0\n",
    "\n",
    "    for org_folder in os.listdir(organizations_dir):\n",
    "        org_path = os.path.join(organizations_dir, org_folder)\n",
    "        if not os.path.isdir(org_path):\n",
    "            continue\n",
    "\n",
    "        models_dir = os.path.join(org_path, \"models\")\n",
    "        if not os.path.exists(models_dir):\n",
    "            print(f\"No models folder in: {org_folder}\")\n",
    "            continue\n",
    "\n",
    "        for model_folder in os.listdir(models_dir):\n",
    "            model_path = os.path.join(models_dir, model_folder)\n",
    "            if not os.path.isdir(model_path):\n",
    "                continue\n",
    "\n",
    "            json_file = os.path.join(model_path, \"benchmarks.json\")\n",
    "            if not os.path.exists(json_file):\n",
    "                print(f\"No benchmarks.json in: {model_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load list JSON\n",
    "            data_list = load_json(json_file)\n",
    "\n",
    "            if not isinstance(data_list, list):\n",
    "                print(f\"{json_file} is not a list, skipping...\")\n",
    "                continue\n",
    "\n",
    "            total_files += 1\n",
    "\n",
    "            # Insert each item\n",
    "            for item in data_list:\n",
    "\n",
    "                if id_col not in item:\n",
    "                    print(f\"Missing '{id_col}' in item inside {json_file}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Upsert each benchmark record\n",
    "                collection.update_one(\n",
    "                    {id_col: item[id_col]},\n",
    "                    {\"$set\": item},\n",
    "                    upsert=True\n",
    "                )\n",
    "\n",
    "                total_items += 1\n",
    "\n",
    "    print(f\"\\nLoaded {total_items} benchmark records from {total_files} files into '{collection_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f96be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://127.0.0.1:27017/admin2' #this matches in .env\n",
    "DB_NAME = 'admin2' #MongoDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ROOT_DIR = Path(r\"C:\\Users\\nguye\\OneDrive\\Desktop\\Data\")\n",
    "\n",
    "LICENSE_DIR = ROOT_DIR / \"licenses\"\n",
    "BENCHMARK_DIR =  ROOT_DIR / \"benchmarks\"\n",
    "OVERALL_INFO_DIR =  ROOT_DIR / \"llm_comparison_dataset.csv\"\n",
    "ORGANIZATIONS_DIR =  ROOT_DIR / \"organizations\"\n",
    "PROVIDERS_DIR =  ROOT_DIR / \"providers\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12158926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD BENCHMARK METADATA\n",
    "COLLECTION_NAME = 'Benchmark MD'\n",
    "load_single_json_to_mongo(MONGO_URI, DB_NAME, COLLECTION_NAME, BENCHMARK_DIR, 'benchmark_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LICENSES METADATA\n",
    "COLLECTION_NAME = 'Licenses MD'\n",
    "load_single_json_to_mongo(MONGO_URI, DB_NAME, COLLECTION_NAME, LICENSE_DIR, 'license_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5584f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLM OVERALL INFO\n",
    "COLLECTION_NAME = 'LLM overall info'\n",
    "df = pd.read_csv(OVERALL_INFO_DIR)\n",
    "\n",
    "data_dict = df.to_dict(orient='records')\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "\n",
    "if data_dict:\n",
    "    collection.insert_many(data_dict)\n",
    "    print(f\"Inserted {len(data_dict)} records into '{COLLECTION_NAME}' collection.\")\n",
    "else:\n",
    "    print(\"CSV file is empty. No data inserted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLMS FROM ORGANIZATION OVERALL INFO\n",
    "COLLECTION_NAME = 'LLMs in Organizations'\n",
    "load_many_json_to_mongo(MONGO_URI, DB_NAME, COLLECTION_NAME, ORGANIZATIONS_DIR, 'model_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87896b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLM SCORE FOR EACH BENCHMARK\n",
    "COLLECTION_NAME = 'LLM Performance'\n",
    "load_llm_models(MONGO_URI, DB_NAME, COLLECTION_NAME, ORGANIZATIONS_DIR, 'model_benchmark_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLMS FROM PROVIDER OVERALL INFO\n",
    "COLLECTION_NAME = 'LLMs in Providers'\n",
    "load_many_json_to_mongo(MONGO_URI, DB_NAME, COLLECTION_NAME, PROVIDERS_DIR, 'provider.json','model_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLMS FROM PROVIDER OVERALL INFO\n",
    "COLLECTION_NAME = 'Providers MD'\n",
    "load_child_folder_json(MONGO_URI, DB_NAME, COLLECTION_NAME, PROVIDERS_DIR, 'provider.json','provider_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD LLMS FROM PROVIDER OVERALL INFO\n",
    "COLLECTION_NAME = 'Organizations MD'\n",
    "load_child_folder_json(MONGO_URI, DB_NAME, COLLECTION_NAME, ORGANIZATIONS_DIR, 'organization.json', 'organization_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904a7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Organization & Provider with avg_benchmark_score successfully!\n"
     ]
    }
   ],
   "source": [
    "# MERGE ORGANIZATION & PROVIDER DATA WITH AVERAGE BENCHMARK SCORE\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"admin2\"]\n",
    "\n",
    "org_coll = db[\"LLMs wrt Organizations\"]\n",
    "prov_coll = db[\"LLMs wrt Providers\"]\n",
    "perf_coll = db[\"LLM Performance\"]\n",
    "merged_coll = db[\"LLM Merged Organization and Provider\"]\n",
    "\n",
    "# Step 1: Left join Organization -> Provider\n",
    "pipeline_org = [\n",
    "    {\n",
    "        \"$lookup\": {\n",
    "            \"from\": \"LLMs wrt Providers\",\n",
    "            \"localField\": \"model_id\",\n",
    "            \"foreignField\": \"model_id\",\n",
    "            \"as\": \"provider_data\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$addFields\": {\n",
    "            \"provider_id\": {\"$arrayElemAt\": [\"$provider_data.provider_id\", 0]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\"provider_data\": 0}  # remove temp array\n",
    "    }\n",
    "]\n",
    "\n",
    "org_docs = list(org_coll.aggregate(pipeline_org))\n",
    "\n",
    "# Step 2: Get provider-only model_ids (not in Organization)\n",
    "org_model_ids = org_coll.distinct(\"model_id\")\n",
    "prov_only_docs = list(prov_coll.find({\"model_id\": {\"$nin\": org_model_ids}}))\n",
    "\n",
    "# Step 3: Merge provider-only docs\n",
    "org_sample_fields = org_coll.find_one() or {}\n",
    "org_field_keys = [k for k in org_sample_fields.keys() if k != \"_id\"]\n",
    "\n",
    "for doc in prov_only_docs:\n",
    "    merged_doc = {\n",
    "        **{k: None for k in org_field_keys},  # all org fields as None\n",
    "        **doc  # overwrite model_id and provider_id from provider\n",
    "    }\n",
    "    org_docs.append(merged_doc)\n",
    "\n",
    "# Step 4: Compute avg_benchmark_score for each doc\n",
    "for doc in org_docs:\n",
    "    scores = list(perf_coll.find({\"model_id\": doc[\"model_id\"]}, {\"normalized_score\": 1, \"_id\": 0}))\n",
    "    if scores:\n",
    "        avg_score = sum(s[\"normalized_score\"] for s in scores) / len(scores)\n",
    "        doc[\"avg_benchmark_score\"] = avg_score\n",
    "    else:\n",
    "        doc[\"avg_benchmark_score\"] = None  # or 0\n",
    "\n",
    "# Step 5: Insert/update merged collection\n",
    "for doc in org_docs:\n",
    "    merged_coll.update_one(\n",
    "        {\"model_id\": doc[\"model_id\"]},\n",
    "        {\"$set\": doc},\n",
    "        upsert=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a0800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'admin2', 'config', 'local']\n"
     ]
    }
   ],
   "source": [
    "#change release_date from string to datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Fetch all documents\n",
    "for doc in merged_coll.find({\"release_date\": {\"$type\": \"string\"}}):\n",
    "    release_str = doc.get(\"release_date\")\n",
    "    if release_str:\n",
    "        try:\n",
    "            # Convert string to datetime object\n",
    "            release_dt = datetime.fromisoformat(release_str.replace(\"Z\", \"+00:00\"))\n",
    "            merged_coll.update_one(\n",
    "                {\"_id\": doc[\"_id\"]},\n",
    "                {\"$set\": {\"release_date\": release_dt}}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert for {doc['_id']}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
